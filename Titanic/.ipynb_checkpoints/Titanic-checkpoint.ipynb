{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "### Competition: [Titanic Kaggle](https://www.kaggle.com/c/titanic/overview)\n",
    "\n",
    "This is notebook contains a simple data science project framework, for learning and portfolio construction purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Input, Dense, BatchNormalization, Dropout, Embedding,  Flatten\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.data import Dataset\n",
    "from tensorflow import keras\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import QuantileTransformer,  KBinsDiscretizer, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import optuna\n",
    "from optuna.visualization import plot_contour, plot_edf, plot_intermediate_values, plot_optimization_history\n",
    "from optuna.visualization import plot_parallel_coordinate, plot_param_importances, plot_slice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset\n",
    "\n",
    "This step we simply get our data to our working environment. Because we are not dealing with live data, a simple pandas usage is enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "train = pd.read_csv(\"data/train.csv\")\n",
    "test = pd.read_csv(\"data/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking if Pclass has any effect on survival rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x=\"Pclass\", y=\"Survived\", data=train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that Pclass is an important variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking Sex and Embarked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x=\"Sex\", y=\"Survived\", data=train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x=\"Embarked\", y=\"Survived\", data=train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the survival rate between females and males are most discrepant, and the *Embarked* variable has some effect as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x] Pclass\n",
    "- [ ] Name\n",
    "- [x] Sex\n",
    "- [ ] Age\n",
    "- [ ] SibSp\n",
    "- [ ] Parch\n",
    "- [ ] Ticket\n",
    "- [ ] Fare\n",
    "- [ ] Cabin\n",
    "- [x] Embarked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's verify the rest of categorical variables (Cabin, Name, Ticket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, the Cabin variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x=\"Cabin\", y=\"Survived\", data=train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can't really use it this way, so let's change it a little:\n",
    "Let's test three hipothesis:\n",
    "- The letter is important;\n",
    "- The number is important;\n",
    "- Having it as missing or not is important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[train['Cabin'].isna(), 'Cabin'] = 'missing'\n",
    "cabin_letters = [s[0] for s in train['Cabin']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x= cabin_letters, y=train[\"Survived\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that the missing values don't really tell us anything, as it's mean is around the overall survival rate.\n",
    "\n",
    "Overall, most of the error bars are too big for us to consider that the letter has anything to do with the survival rate. However, we will consider the C, E, D, B letters as they are statiscally different than the overall mean.\n",
    "\n",
    "Before moving on, let's see if we can embed them in one variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for letter in range(len(cabin_letters)):\n",
    "    if cabin_letters[letter] in ['C', 'E', 'D', 'B']:\n",
    "        cabin_letters[letter] = 'group1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x = cabin_letters, y = train[\"Survived\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is the cabin number important?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cabin_numbers = [s.split()[0][1:] for s in train['Cabin']]\n",
    "for i in range(len(cabin_numbers)):\n",
    "    try:\n",
    "        cabin_numbers[i] = int(cabin_numbers[i])\n",
    "    except Exception:\n",
    "        cabin_numbers[i] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.boxplot(x = train[\"Survived\"], y = cabin_numbers);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this we can conclude that the number is not relevant!\n",
    "- [x] The letter is important (**Important**);\n",
    "- [x] The number is important (**Not Important**);\n",
    "- [x] Having it as missing or not is important (**Not Important**)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next, the *Name* variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train['Name'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that every name here is unique, so we have to transform it a bit. \n",
    "\n",
    "The hipothesis tested is that the title of each name is relevant to predict the survival rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_and_title = [name.split(\", \")[1] for name in train['Name']]\n",
    "title = [name.split(\".\")[0] for name in name_and_title]\n",
    "print(len(title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(len(np.unique(title)))\n",
    "np.unique(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(title).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's only consider the titles: Mr, Miss, Mrs and Master; as we don't have enough observations from the others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(title)):\n",
    "    if title[i] not in ['Mr', 'Miss', 'Mrs', 'Master']:\n",
    "        title[i] = 'Other'        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x = title, y = train[\"Survived\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *Mrs* title is relevant, however it is probably highly correlated with the *Sex* variable.\n",
    "\n",
    "Something intereting is the relevancy of the *Master* title, that probably has information about the economical power of the person."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lastly, the Ticket variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Ticket']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will test only one hipothesis:\n",
    "- The letters have relevant information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickets = [s.split()[0] for s in train['Ticket']]\n",
    "for i in range(len(tickets)):\n",
    "    try:\n",
    "        int(tickets[i])\n",
    "        tickets[i] = \"number\"\n",
    "    except:\n",
    "        tickets[i] = \"Letter\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x = tickets, y = train[\"Survived\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can conclude here that the ticket information most likely has not any relevant information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, for the numerical variables (*Age*,\t*SibSp*, *Parch*, *Fare*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x = train[\"Survived\"], y = train['Age']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the average age does not differ when comparing the survived and not survived people.\n",
    "\n",
    "We will try binning the age variable here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = KBinsDiscretizer(n_bins = 4, encode = 'ordinal')\n",
    "train['Age_Group'] = pd.DataFrame(bins.fit_transform(temp_df[['Age']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x = 'Age_Group', y = 'Survived', data = train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are too noisy for us to infer anything."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SibSp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.barplot(x = train['SibSp'], y = train[\"Survived\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only when SibSp = 1 that we have a relevant information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.barplot(x = train['Parch'], y = train[\"Survived\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can have better predictions when Parch = 1 or 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parch_1_2 = []\n",
    "for i in range(len(train['Parch'])):\n",
    "    if train.loc[i,'Parch'] in [1, 2]:\n",
    "        parch_1_2.append(\"1_or_2\")\n",
    "        \n",
    "    else:\n",
    "        parch_1_2.append(\"Other\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x = parch_1_2, y = train[\"Survived\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parch + SibSp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x = train['Parch'] + train['SibSp'], y = train[\"Survived\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that from 4 Parch + SipSp, the survival rate decreases, so we will create a dummy variable for <4 relatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parch_sibsp_1 = []\n",
    "for i in range(len(train)):\n",
    "    if train.loc[i, 'Parch'] + train.loc[i, 'SibSp'] < 4:\n",
    "        parch_sibsp_1.append(1)\n",
    "        \n",
    "    else:\n",
    "        parch_sibsp_1.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.barplot(x = parch_sibsp_1, y = train[\"Survived\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.histplot(multiple = 'dodge', x = train['Fare'], hue = train[\"Survived\"], bins = 7);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Higher fares -> higher survival rates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([train, pd.get_dummies(train['Name']).filter(['Miss', 'Mr', 'Mrs', 'Ms'])], axis = 1)\n",
    "train.drop('Name', axis = 1, inplace = True)\n",
    "\n",
    "test = pd.concat([test, pd.get_dummies(test['Name']).filter(['Miss', 'Mr', 'Mrs', 'Ms'])], axis = 1)\n",
    "test.drop('Name', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5.99 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train['Survived'] = train['Survived'].astype(str)\n",
    "\n",
    "train['n_missing'] = train.isna().sum(axis=1)\n",
    "test['n_missing'] = test.isna().sum(axis=1)\n",
    "\n",
    "test['Pclass']= test['Pclass'].astype(str)\n",
    "test['Pclass']= test['Pclass'].astype(str)\n",
    "\n",
    "features = [col for col in train.columns if col not in ['Survived', 'PassengerId']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with the Ticket feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           A/5 21171\n",
       "1            PC 17599\n",
       "2    STON/O2. 3101282\n",
       "3              113803\n",
       "4              373450\n",
       "Name: Ticket, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Ticket'][0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**One hypothesis we can make** is that the numbers don't contain any relevant information and the prefix may contain relevant information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A/5', 'PC', 'STON/O2.', '113803', '373450']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ticket_prefixes = [ticket.split()[0] for ticket in train['Ticket']]\n",
    "ticket_prefixes[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(ticket_prefixes)):\n",
    "    try: \n",
    "        int(ticket_prefixes[i])\n",
    "        ticket_prefixes[i] = \"number_only\"\n",
    "    \n",
    "    except Exception:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A/5', 'PC', 'STON/O2.', 'number_only', 'number_only']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ticket_prefixes[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['A./5.', 'A.5.', 'A/4', 'A/4.', 'A/5', 'A/5.', 'A/S', 'A4.', 'C',\n",
       "       'C.A.', 'C.A./SOTON', 'CA', 'CA.', 'F.C.', 'F.C.C.', 'Fa', 'LINE',\n",
       "       'P/PP', 'PC', 'PP', 'S.C./A.4.', 'S.C./PARIS', 'S.O./P.P.',\n",
       "       'S.O.C.', 'S.O.P.', 'S.P.', 'S.W./PP', 'SC', 'SC/AH', 'SC/PARIS',\n",
       "       'SC/Paris', 'SCO/W', 'SO/C', 'SOTON/O.Q.', 'SOTON/O2', 'SOTON/OQ',\n",
       "       'STON/O', 'STON/O2.', 'SW/PP', 'W./C.', 'W.E.P.', 'W/C', 'WE/P',\n",
       "       'number_only'], dtype='<U11')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(np.unique(ticket_prefixes)))\n",
    "np.unique(ticket_prefixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticket_prefixes = [s.replace(\".\", \"\") for s in ticket_prefixes]\n",
    "ticket_prefixes = [s.replace(\",\", \"\") for s in ticket_prefixes]\n",
    "ticket_prefixes = [s.upper() for s in ticket_prefixes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['A/4', 'A/5', 'A/S', 'A4', 'A5', 'C', 'CA', 'CA/SOTON', 'FA', 'FC',\n",
       "       'FCC', 'LINE', 'NUMBER_ONLY', 'P/PP', 'PC', 'PP', 'SC', 'SC/A4',\n",
       "       'SC/AH', 'SC/PARIS', 'SCO/W', 'SO/C', 'SO/PP', 'SOC', 'SOP',\n",
       "       'SOTON/O2', 'SOTON/OQ', 'SP', 'STON/O', 'STON/O2', 'SW/PP', 'W/C',\n",
       "       'WE/P', 'WEP'], dtype='<U11')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(np.unique(ticket_prefixes)))\n",
    "np.unique(ticket_prefixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ticket_prefixes = [ticket.split()[0] for ticket in test['Ticket']]\n",
    "for i in range(len(test_ticket_prefixes)):\n",
    "    try: \n",
    "        int(test_ticket_prefixes[i])\n",
    "        test_ticket_prefixes[i] = \"number_only\"\n",
    "    \n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "test_ticket_prefixes = [s.replace(\".\", \"\") for s in test_ticket_prefixes]\n",
    "test_ticket_prefixes = [s.replace(\",\", \"\") for s in test_ticket_prefixes]\n",
    "test_ticket_prefixes = [s.upper() for s in test_ticket_prefixes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Ticket'] = ticket_prefixes\n",
    "test['Ticket'] = test_ticket_prefixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([train, pd.get_dummies(train['Ticket']).filter(['PC', 'CA', 'NUMBER_ONLY'])], axis = 1)\n",
    "train.drop('Ticket', axis = 1, inplace = True)\n",
    "\n",
    "test = pd.concat([test, pd.get_dummies(test['Ticket']).filter(['PC', 'CA', 'NUMBER_ONLY'])], axis = 1)\n",
    "test.drop('Ticket', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with the Cabin feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same as the *Ticket* feature. I will assume that the number doesn't have relevant information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 'C85', 'C123', 'E46', 'G6', 'C103', 'D56', 'A6',\n",
       "       'C23 C25 C27', 'B78', 'D33', 'B30', 'C52', 'B28', 'C83', 'F33',\n",
       "       'F G73', 'E31', 'A5', 'D10 D12', 'D26', 'C110', 'B58 B60', 'E101',\n",
       "       'F E69', 'D47', 'B86', 'F2', 'C2', 'E33', 'B19', 'A7', 'C49', 'F4',\n",
       "       'A32', 'B4', 'B80', 'A31', 'D36', 'D15', 'C93', 'C78', 'D35',\n",
       "       'C87', 'B77', 'E67', 'B94', 'C125', 'C99', 'C118', 'D7', 'A19',\n",
       "       'B49', 'D', 'C22 C26', 'C106', 'C65', 'E36', 'C54',\n",
       "       'B57 B59 B63 B66', 'C7', 'E34', 'C32', 'B18', 'C124', 'C91', 'E40',\n",
       "       'T', 'C128', 'D37', 'B35', 'E50', 'C82', 'B96 B98', 'E10', 'E44',\n",
       "       'A34', 'C104', 'C111', 'C92', 'E38', 'D21', 'E12', 'E63', 'A14',\n",
       "       'B37', 'C30', 'D20', 'B79', 'E25', 'D46', 'B73', 'C95', 'B38',\n",
       "       'B39', 'B22', 'C86', 'C70', 'A16', 'C101', 'C68', 'A10', 'E68',\n",
       "       'B41', 'A20', 'D19', 'D50', 'D9', 'A23', 'B50', 'A26', 'D48',\n",
       "       'E58', 'C126', 'B71', 'B51 B53 B55', 'D49', 'B5', 'B20', 'F G63',\n",
       "       'C62 C64', 'E24', 'C90', 'C45', 'E8', 'B101', 'D45', 'C46', 'D30',\n",
       "       'E121', 'D11', 'E77', 'F38', 'B3', 'D6', 'B82 B84', 'D17', 'A36',\n",
       "       'B102', 'B69', 'E49', 'C47', 'D28', 'E17', 'A24', 'C50', 'B42',\n",
       "       'C148'], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Cabin'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cabin_prefix = []\n",
    "for i in range(len(train['Cabin'])):\n",
    "    try:\n",
    "        cabin_prefix.append(train['Cabin'][i][0: 1: 1])\n",
    "    \n",
    "    except:\n",
    "        cabin_prefix.append(train['Cabin'][i])        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['A', 'B', 'C', 'D', 'E', 'F', 'G', 'T', 'nan'], dtype='<U32')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(cabin_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cabin_test_prefix = []\n",
    "for i in range(len(test['Cabin'])):\n",
    "    try:\n",
    "        cabin_test_prefix.append(test['Cabin'][i][0: 1: 1])\n",
    "    \n",
    "    except:\n",
    "        cabin_test_prefix.append(test['Cabin'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Cabin'] = cabin_prefix\n",
    "test['Cabin'] = cabin_test_prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([train, pd.get_dummies(train['Cabin']).filter(['NaN', 'B', 'C'])], axis = 1)\n",
    "train.drop('Cabin', axis = 1, inplace = True)\n",
    "\n",
    "test = pd.concat([test, pd.get_dummies(test['Cabin']).filter(['NaN', 'B', 'C'])], axis = 1)\n",
    "test.drop('Cabin', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pclass, Sex and Embarked variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.get_dummies(train, columns = ['Pclass', 'Sex', 'Embarked'])\n",
    "test = pd.get_dummies(test, columns = ['Pclass', 'Sex', 'Embarked'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputer and Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 13 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "features = [col for col in train.columns if col not in ['Survived', 'PassengerId']]\n",
    "numerical_features = [col for col in features if col in ['Age', 'SibSp', 'Parch', 'Fare', 'n_missing']]\n",
    "\n",
    "pipe = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='mean',missing_values=np.nan)),\n",
    "        (\"scaler\", StandardScaler())\n",
    "        ])\n",
    "\n",
    "train[numerical_features] = pipe.fit_transform(train[numerical_features])\n",
    "test[numerical_features] = pipe.transform(test[numerical_features])\n",
    "\n",
    "train['Survived'] = train['Survived'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k:  2  Inertia:  5466.229288766526\n",
      "k:  3  Inertia:  4521.282674654894\n",
      "k:  4  Inertia:  4076.124018557896\n",
      "k:  5  Inertia:  3711.377256206933\n",
      "k:  6  Inertia:  3373.344400666795\n",
      "k:  7  Inertia:  3124.243299073304\n",
      "k:  8  Inertia:  2928.3450623741946\n",
      "k:  9  Inertia:  2758.049769098987\n",
      "k:  10  Inertia:  2634.961669599222\n",
      "k:  11  Inertia:  2517.689194643763\n",
      "k:  12  Inertia:  2395.8423453577175\n",
      "k:  13  Inertia:  2294.468760589003\n",
      "k:  14  Inertia:  2195.991982714791\n",
      "k:  15  Inertia:  2107.976114324885\n",
      "k:  16  Inertia:  2040.056371527247\n",
      "k:  17  Inertia:  1978.1699204810755\n",
      "k:  18  Inertia:  1932.668366946803\n",
      "k:  19  Inertia:  1876.0697010800227\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "\n",
    "best_k = float('inf')\n",
    "\n",
    "inertia_values = []\n",
    "for k in range(2, 20):\n",
    "    kmeans = KMeans(n_clusters = k, n_init = 100, max_iter = 500, copy_x = False)\n",
    "    kmeans.fit(train[features])\n",
    "    \n",
    "    if k < best_k:\n",
    "        best_k = k\n",
    "    \n",
    "    inertia_values.append(kmeans.inertia_)\n",
    "    print(\"k: \", k , \" Inertia: \", kmeans.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(2, 20), inertia_values); # K = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.45776238, 3.25188637, 2.88542032],\n",
       "       [3.75795147, 2.03421164, 4.20923063],\n",
       "       [1.89172458, 3.18355936, 3.16197695],\n",
       "       ...,\n",
       "       [3.34706176, 4.46843718, 2.42696312],\n",
       "       [2.87117162, 2.24994573, 4.07855735],\n",
       "       [1.41225138, 3.14494331, 3.59888404]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters = 3, n_init = 100, max_iter = 500, copy_x = False)\n",
    "kmeans.fit_transform(train[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters = 3, n_init = 100, max_iter = 500, copy_x = False)\n",
    "kmeans.fit_transform(train[features])\n",
    "train[['cluster_0', 'cluster_1', 'cluster_2']] =  pd.get_dummies(kmeans.labels_)\n",
    "\n",
    "kmeans.transform(test[features])\n",
    "test[['cluster_0', 'cluster_1', 'cluster_2']] =  pd.get_dummies(kmeans.predict(test[features]))\n",
    "\n",
    "features = [col for col in train.columns if col not in ['Survived', 'PassengerId']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Light GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-22 20:32:16,604]\u001b[0m A new study created in memory with name: no-name-1c93899d-52b3-42b8-9986-576f3cb2ecae\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:16,749]\u001b[0m Trial 0 finished with value: 0.7991400414286611 and parameters: {'lambda_l1': 6.392971348352724e-05, 'lambda_l2': 8.041081404686387e-06, 'num_leaves': 12, 'feature_fraction': 0.8070143672569244, 'bagging_fraction': 0.5115606779832345, 'bagging_freq': 3, 'min_child_samples': 99}. Best is trial 0 with value: 0.7991400414286611.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:17,141]\u001b[0m Trial 1 finished with value: 0.8170296905404557 and parameters: {'lambda_l1': 3.586253714155974e-06, 'lambda_l2': 1.13862644784498e-06, 'num_leaves': 26, 'feature_fraction': 0.5920360716926122, 'bagging_fraction': 0.9035854363156637, 'bagging_freq': 3, 'min_child_samples': 11}. Best is trial 1 with value: 0.8170296905404557.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:17,314]\u001b[0m Trial 2 finished with value: 0.8114242671520934 and parameters: {'lambda_l1': 5.640440536737402e-07, 'lambda_l2': 1.4548293634879116e-05, 'num_leaves': 19, 'feature_fraction': 0.8867169608076393, 'bagging_fraction': 0.586463520201019, 'bagging_freq': 3, 'min_child_samples': 57}. Best is trial 1 with value: 0.8170296905404557.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:17,482]\u001b[0m Trial 3 finished with value: 0.8092147385600402 and parameters: {'lambda_l1': 5.145664057166693, 'lambda_l2': 0.04285025198052135, 'num_leaves': 8, 'feature_fraction': 0.47580154965869104, 'bagging_fraction': 0.6848872997430882, 'bagging_freq': 4, 'min_child_samples': 37}. Best is trial 1 with value: 0.8170296905404557.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:17,639]\u001b[0m Trial 4 finished with value: 0.8148264390182662 and parameters: {'lambda_l1': 1.8048565019380442e-06, 'lambda_l2': 8.907317746244117e-08, 'num_leaves': 23, 'feature_fraction': 0.8993764115350477, 'bagging_fraction': 0.5144677594292105, 'bagging_freq': 1, 'min_child_samples': 70}. Best is trial 1 with value: 0.8170296905404557.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:17,827]\u001b[0m Trial 5 finished with value: 0.8136965664427844 and parameters: {'lambda_l1': 2.1948034573562543e-05, 'lambda_l2': 1.6264296544397045e-05, 'num_leaves': 23, 'feature_fraction': 0.6247110497277543, 'bagging_fraction': 0.9242291527962854, 'bagging_freq': 2, 'min_child_samples': 88}. Best is trial 1 with value: 0.8170296905404557.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:18,002]\u001b[0m Trial 6 finished with value: 0.8159249262444291 and parameters: {'lambda_l1': 7.01433323613055e-05, 'lambda_l2': 2.553220813612254e-08, 'num_leaves': 25, 'feature_fraction': 0.6925616649443499, 'bagging_fraction': 0.95204636215645, 'bagging_freq': 7, 'min_child_samples': 90}. Best is trial 1 with value: 0.8170296905404557.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:18,203]\u001b[0m Trial 7 finished with value: 0.8327663046889713 and parameters: {'lambda_l1': 3.759190669658613e-08, 'lambda_l2': 3.926865947476365e-05, 'num_leaves': 29, 'feature_fraction': 0.8854637063127473, 'bagging_fraction': 0.8412976001533627, 'bagging_freq': 4, 'min_child_samples': 56}. Best is trial 7 with value: 0.8327663046889713.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:18,382]\u001b[0m Trial 8 finished with value: 0.8159312033142928 and parameters: {'lambda_l1': 5.089961366262457e-06, 'lambda_l2': 2.816087716080023e-07, 'num_leaves': 18, 'feature_fraction': 0.591524869635234, 'bagging_fraction': 0.8387659433426398, 'bagging_freq': 5, 'min_child_samples': 77}. Best is trial 7 with value: 0.8327663046889713.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:18,602]\u001b[0m Trial 9 finished with value: 0.8293955181721172 and parameters: {'lambda_l1': 0.13836046768924687, 'lambda_l2': 1.5514606562871627e-06, 'num_leaves': 15, 'feature_fraction': 0.9904132752427856, 'bagging_fraction': 0.7132396751578023, 'bagging_freq': 3, 'min_child_samples': 39}. Best is trial 7 with value: 0.8327663046889713.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:19,050]\u001b[0m Trial 10 finished with value: 0.8125478626577113 and parameters: {'lambda_l1': 1.363070197785531e-08, 'lambda_l2': 0.01502831899558443, 'num_leaves': 31, 'feature_fraction': 0.771719810078132, 'bagging_fraction': 0.7680955484090313, 'bagging_freq': 6, 'min_child_samples': 10}. Best is trial 7 with value: 0.8327663046889713.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:19,235]\u001b[0m Trial 11 finished with value: 0.8204444165463561 and parameters: {'lambda_l1': 0.030636194199596505, 'lambda_l2': 0.0008040051600180818, 'num_leaves': 3, 'feature_fraction': 0.9916515493746944, 'bagging_fraction': 0.714464776070218, 'bagging_freq': 5, 'min_child_samples': 39}. Best is trial 7 with value: 0.8327663046889713.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:19,489]\u001b[0m Trial 12 finished with value: 0.8293955181721172 and parameters: {'lambda_l1': 0.008021242005701675, 'lambda_l2': 5.2128253374011395, 'num_leaves': 14, 'feature_fraction': 0.965565064023366, 'bagging_fraction': 0.8049382113407397, 'bagging_freq': 4, 'min_child_samples': 37}. Best is trial 7 with value: 0.8327663046889713.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:19,688]\u001b[0m Trial 13 finished with value: 0.8025045508756513 and parameters: {'lambda_l1': 5.185258210328382, 'lambda_l2': 0.0003761902404545979, 'num_leaves': 32, 'feature_fraction': 0.8661168641036512, 'bagging_fraction': 0.6604712994864956, 'bagging_freq': 1, 'min_child_samples': 53}. Best is trial 7 with value: 0.8327663046889713.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:19,936]\u001b[0m Trial 14 finished with value: 0.8181721172556651 and parameters: {'lambda_l1': 0.01227977868466852, 'lambda_l2': 2.0593543952935325e-06, 'num_leaves': 10, 'feature_fraction': 0.9750302959790409, 'bagging_fraction': 0.42998232879216614, 'bagging_freq': 5, 'min_child_samples': 25}. Best is trial 7 with value: 0.8327663046889713.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:20,172]\u001b[0m Trial 15 finished with value: 0.8226664992781372 and parameters: {'lambda_l1': 2.9704014637794134e-08, 'lambda_l2': 0.00013949338331817007, 'num_leaves': 16, 'feature_fraction': 0.7882234949008553, 'bagging_fraction': 0.8374531633989446, 'bagging_freq': 2, 'min_child_samples': 65}. Best is trial 7 with value: 0.8327663046889713.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:20,398]\u001b[0m Trial 16 finished with value: 0.8215303496327915 and parameters: {'lambda_l1': 0.0008880228405223604, 'lambda_l2': 1.0712315129869047e-08, 'num_leaves': 7, 'feature_fraction': 0.9136084954549114, 'bagging_fraction': 0.6224202124070706, 'bagging_freq': 2, 'min_child_samples': 46}. Best is trial 7 with value: 0.8327663046889713.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:20,676]\u001b[0m Trial 17 finished with value: 0.8226476680685456 and parameters: {'lambda_l1': 0.0013422124549187858, 'lambda_l2': 5.759000208489336, 'num_leaves': 13, 'feature_fraction': 0.40385470520464267, 'bagging_fraction': 0.8014506402835758, 'bagging_freq': 4, 'min_child_samples': 24}. Best is trial 7 with value: 0.8327663046889713.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:20,979]\u001b[0m Trial 18 finished with value: 0.8293829640323895 and parameters: {'lambda_l1': 1.827464219686375e-07, 'lambda_l2': 5.9441806487518285, 'num_leaves': 28, 'feature_fraction': 0.8347596973858491, 'bagging_fraction': 0.8675505893469363, 'bagging_freq': 6, 'min_child_samples': 23}. Best is trial 7 with value: 0.8327663046889713.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:21,198]\u001b[0m Trial 19 finished with value: 0.8204193082669009 and parameters: {'lambda_l1': 0.4579415912742467, 'lambda_l2': 0.004763860228924235, 'num_leaves': 20, 'feature_fraction': 0.7296826310005498, 'bagging_fraction': 0.7279463079795199, 'bagging_freq': 3, 'min_child_samples': 61}. Best is trial 7 with value: 0.8327663046889713.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:21,465]\u001b[0m Trial 20 finished with value: 0.8361370912058252 and parameters: {'lambda_l1': 0.4881809488596579, 'lambda_l2': 0.00010797235251577707, 'num_leaves': 22, 'feature_fraction': 0.9372736322312379, 'bagging_fraction': 0.991429544171526, 'bagging_freq': 4, 'min_child_samples': 47}. Best is trial 20 with value: 0.8361370912058252.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:21,737]\u001b[0m Trial 21 finished with value: 0.8383654510074697 and parameters: {'lambda_l1': 0.23983706945898253, 'lambda_l2': 8.622237296912371e-05, 'num_leaves': 29, 'feature_fraction': 0.9144574800999573, 'bagging_fraction': 0.9844533490969807, 'bagging_freq': 4, 'min_child_samples': 46}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-22 20:32:22,009]\u001b[0m Trial 22 finished with value: 0.8361245370660975 and parameters: {'lambda_l1': 0.4200701590618177, 'lambda_l2': 7.258153852794407e-05, 'num_leaves': 29, 'feature_fraction': 0.9288240879430438, 'bagging_fraction': 0.9823302217824006, 'bagging_freq': 4, 'min_child_samples': 47}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:22,281]\u001b[0m Trial 23 finished with value: 0.8305065595380077 and parameters: {'lambda_l1': 0.4443838703995051, 'lambda_l2': 0.22340011714082872, 'num_leaves': 22, 'feature_fraction': 0.9286377268362842, 'bagging_fraction': 0.9647155759002808, 'bagging_freq': 5, 'min_child_samples': 44}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:22,536]\u001b[0m Trial 24 finished with value: 0.8237838177138912 and parameters: {'lambda_l1': 1.2217240438298846, 'lambda_l2': 0.002463640103280921, 'num_leaves': 28, 'feature_fraction': 0.8456750101979462, 'bagging_fraction': 0.9604131326250278, 'bagging_freq': 4, 'min_child_samples': 48}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:22,859]\u001b[0m Trial 25 finished with value: 0.8293955181721173 and parameters: {'lambda_l1': 0.07354803332425636, 'lambda_l2': 5.966008184541351e-05, 'num_leaves': 26, 'feature_fraction': 0.9320643340333906, 'bagging_fraction': 0.9922348476278575, 'bagging_freq': 6, 'min_child_samples': 33}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:23,090]\u001b[0m Trial 26 finished with value: 0.8215491808423827 and parameters: {'lambda_l1': 0.0034858900982700477, 'lambda_l2': 0.0008462779375290388, 'num_leaves': 30, 'feature_fraction': 0.7254312756598025, 'bagging_fraction': 0.9963111783764703, 'bagging_freq': 5, 'min_child_samples': 73}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:23,388]\u001b[0m Trial 27 finished with value: 0.833864791915134 and parameters: {'lambda_l1': 1.069129816318471, 'lambda_l2': 0.00014642939514679075, 'num_leaves': 21, 'feature_fraction': 0.9448444132186424, 'bagging_fraction': 0.8954265349365642, 'bagging_freq': 4, 'min_child_samples': 28}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:23,645]\u001b[0m Trial 28 finished with value: 0.8316427091833531 and parameters: {'lambda_l1': 0.11410559736115755, 'lambda_l2': 0.08191587127417754, 'num_leaves': 24, 'feature_fraction': 0.8289169782866298, 'bagging_fraction': 0.9223334853626186, 'bagging_freq': 7, 'min_child_samples': 52}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:23,843]\u001b[0m Trial 29 finished with value: 0.8092461239093591 and parameters: {'lambda_l1': 7.651824150822483, 'lambda_l2': 2.534300581954528e-06, 'num_leaves': 32, 'feature_fraction': 0.8051602078356055, 'bagging_fraction': 0.9927546376132949, 'bagging_freq': 3, 'min_child_samples': 63}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:24,222]\u001b[0m Trial 30 finished with value: 0.8181595631159375 and parameters: {'lambda_l1': 0.00012800184374159312, 'lambda_l2': 6.414401512941267e-06, 'num_leaves': 27, 'feature_fraction': 0.7673453225488467, 'bagging_fraction': 0.8771251265284395, 'bagging_freq': 4, 'min_child_samples': 19}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:24,521]\u001b[0m Trial 31 finished with value: 0.8316427091833531 and parameters: {'lambda_l1': 0.8037311582034775, 'lambda_l2': 0.00010726920133604249, 'num_leaves': 21, 'feature_fraction': 0.9508116585402177, 'bagging_fraction': 0.9076414739475414, 'bagging_freq': 4, 'min_child_samples': 29}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:24,832]\u001b[0m Trial 32 finished with value: 0.8282593685267716 and parameters: {'lambda_l1': 2.1000073377783486, 'lambda_l2': 0.00028639259797591803, 'num_leaves': 25, 'feature_fraction': 0.9468078025856748, 'bagging_fraction': 0.9430928133152174, 'bagging_freq': 4, 'min_child_samples': 15}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:25,092]\u001b[0m Trial 33 finished with value: 0.8181658401858012 and parameters: {'lambda_l1': 0.2071358280846012, 'lambda_l2': 2.344274669350952e-05, 'num_leaves': 18, 'feature_fraction': 0.8659145702424096, 'bagging_fraction': 0.8861178139899989, 'bagging_freq': 3, 'min_child_samples': 46}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:25,414]\u001b[0m Trial 34 finished with value: 0.8237775406440273 and parameters: {'lambda_l1': 0.03440764841415496, 'lambda_l2': 0.0044732730791852745, 'num_leaves': 20, 'feature_fraction': 0.9133577242149757, 'bagging_fraction': 0.9994055939596402, 'bagging_freq': 5, 'min_child_samples': 31}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:25,661]\u001b[0m Trial 35 finished with value: 0.8294017952419811 and parameters: {'lambda_l1': 2.95147160413575, 'lambda_l2': 5.497219129052477e-06, 'num_leaves': 29, 'feature_fraction': 0.9013175438187269, 'bagging_fraction': 0.9594922472155742, 'bagging_freq': 3, 'min_child_samples': 41}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:26,049]\u001b[0m Trial 36 finished with value: 0.8159186491745654 and parameters: {'lambda_l1': 0.5136249403010773, 'lambda_l2': 3.56665656284802e-07, 'num_leaves': 22, 'feature_fraction': 0.9930168655214928, 'bagging_fraction': 0.9044868254482515, 'bagging_freq': 4, 'min_child_samples': 5}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:26,311]\u001b[0m Trial 37 finished with value: 0.8350072186303434 and parameters: {'lambda_l1': 0.02991650986661995, 'lambda_l2': 0.001463610028602334, 'num_leaves': 26, 'feature_fraction': 0.6365600581861739, 'bagging_fraction': 0.933055326781762, 'bagging_freq': 3, 'min_child_samples': 51}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:26,534]\u001b[0m Trial 38 finished with value: 0.8215366267026551 and parameters: {'lambda_l1': 0.03992960140943964, 'lambda_l2': 0.0016523016916056728, 'num_leaves': 26, 'feature_fraction': 0.6465347527575518, 'bagging_fraction': 0.5580319120571919, 'bagging_freq': 2, 'min_child_samples': 52}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:26,786]\u001b[0m Trial 39 finished with value: 0.8293892411022536 and parameters: {'lambda_l1': 0.010369741728542676, 'lambda_l2': 0.010299964731651389, 'num_leaves': 30, 'feature_fraction': 0.5639966959580656, 'bagging_fraction': 0.9364061339420611, 'bagging_freq': 3, 'min_child_samples': 59}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:27,011]\u001b[0m Trial 40 finished with value: 0.819295712761283 and parameters: {'lambda_l1': 0.20702541271464237, 'lambda_l2': 1.366739895927806e-05, 'num_leaves': 24, 'feature_fraction': 0.5336011739460421, 'bagging_fraction': 0.9645243829357294, 'bagging_freq': 2, 'min_child_samples': 79}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:27,255]\u001b[0m Trial 41 finished with value: 0.8204193082669011 and parameters: {'lambda_l1': 1.5265208703963267, 'lambda_l2': 0.00026992996629886674, 'num_leaves': 27, 'feature_fraction': 0.6633906813721856, 'bagging_fraction': 0.9252343583038842, 'bagging_freq': 4, 'min_child_samples': 50}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:27,486]\u001b[0m Trial 42 finished with value: 0.8249199673592367 and parameters: {'lambda_l1': 0.4805733798631014, 'lambda_l2': 6.232470148676217e-05, 'num_leaves': 24, 'feature_fraction': 0.8798729495304536, 'bagging_fraction': 0.862097460539901, 'bagging_freq': 3, 'min_child_samples': 68}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:27,721]\u001b[0m Trial 43 finished with value: 0.8238026489234824 and parameters: {'lambda_l1': 3.094965580864651, 'lambda_l2': 3.662483007635166e-05, 'num_leaves': 22, 'feature_fraction': 0.5240860229542856, 'bagging_fraction': 0.970433658317487, 'bagging_freq': 4, 'min_child_samples': 56}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:27,988]\u001b[0m Trial 44 finished with value: 0.8282593685267716 and parameters: {'lambda_l1': 0.05865161901368233, 'lambda_l2': 0.0008529639172001645, 'num_leaves': 19, 'feature_fraction': 0.6095370765839139, 'bagging_fraction': 0.895347419553127, 'bagging_freq': 5, 'min_child_samples': 42}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-22 20:32:28,289]\u001b[0m Trial 45 finished with value: 0.8316301550436258 and parameters: {'lambda_l1': 0.19788020288499356, 'lambda_l2': 0.0002915495346126681, 'num_leaves': 29, 'feature_fraction': 0.690705008742354, 'bagging_fraction': 0.9353724702785845, 'bagging_freq': 3, 'min_child_samples': 34}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:28,523]\u001b[0m Trial 46 finished with value: 0.8271608813006089 and parameters: {'lambda_l1': 0.014357787173627325, 'lambda_l2': 0.00010896688224121842, 'num_leaves': 25, 'feature_fraction': 0.9498957538318763, 'bagging_fraction': 0.7655229308337063, 'bagging_freq': 4, 'min_child_samples': 57}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:28,849]\u001b[0m Trial 47 finished with value: 0.821542903772519 and parameters: {'lambda_l1': 1.107717719258114e-05, 'lambda_l2': 1.6234388712953834e-05, 'num_leaves': 27, 'feature_fraction': 0.8529909584432215, 'bagging_fraction': 0.8456982014729227, 'bagging_freq': 5, 'min_child_samples': 27}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:29,127]\u001b[0m Trial 48 finished with value: 0.8159123721047015 and parameters: {'lambda_l1': 0.003090659313269329, 'lambda_l2': 0.025784784262653612, 'num_leaves': 31, 'feature_fraction': 0.9700189188339716, 'bagging_fraction': 0.8181716117560768, 'bagging_freq': 3, 'min_child_samples': 38}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:29,316]\u001b[0m Trial 49 finished with value: 0.7879166405122089 and parameters: {'lambda_l1': 9.444868047252871, 'lambda_l2': 0.002038013680510881, 'num_leaves': 18, 'feature_fraction': 0.8859075806466381, 'bagging_fraction': 0.401965225477051, 'bagging_freq': 4, 'min_child_samples': 35}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:29,596]\u001b[0m Trial 50 finished with value: 0.8338836231247255 and parameters: {'lambda_l1': 0.0002602131576755443, 'lambda_l2': 0.0005517365753372246, 'num_leaves': 23, 'feature_fraction': 0.9253170139520668, 'bagging_fraction': 0.9728890582469202, 'bagging_freq': 3, 'min_child_samples': 48}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:29,880]\u001b[0m Trial 51 finished with value: 0.8305128366078716 and parameters: {'lambda_l1': 0.0005269898005715146, 'lambda_l2': 0.0005462667791663872, 'num_leaves': 23, 'feature_fraction': 0.9978080336970844, 'bagging_fraction': 0.9771276912967326, 'bagging_freq': 3, 'min_child_samples': 49}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:30,139]\u001b[0m Trial 52 finished with value: 0.8271483271608814 and parameters: {'lambda_l1': 3.993341038778141e-05, 'lambda_l2': 0.00013639323586632322, 'num_leaves': 21, 'feature_fraction': 0.9225489823631787, 'bagging_fraction': 0.943422925166358, 'bagging_freq': 2, 'min_child_samples': 55}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:30,415]\u001b[0m Trial 53 finished with value: 0.8248885820099178 and parameters: {'lambda_l1': 0.00021043996955897714, 'lambda_l2': 3.6542465416112425e-05, 'num_leaves': 25, 'feature_fraction': 0.9662284178043206, 'bagging_fraction': 0.9168418946620064, 'bagging_freq': 4, 'min_child_samples': 44}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:30,639]\u001b[0m Trial 54 finished with value: 0.8181721172556651 and parameters: {'lambda_l1': 0.0035484300054095127, 'lambda_l2': 0.005264231399177587, 'num_leaves': 28, 'feature_fraction': 0.9013443630246708, 'bagging_fraction': 0.9758541978136482, 'bagging_freq': 3, 'min_child_samples': 95}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:30,912]\u001b[0m Trial 55 finished with value: 0.8271357730211537 and parameters: {'lambda_l1': 0.856553381974169, 'lambda_l2': 0.0011164615729664395, 'num_leaves': 26, 'feature_fraction': 0.8727026480531697, 'bagging_fraction': 0.9035221806694483, 'bagging_freq': 4, 'min_child_samples': 40}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:31,143]\u001b[0m Trial 56 finished with value: 0.8260561170045821 and parameters: {'lambda_l1': 7.856586585596147e-07, 'lambda_l2': 0.0001966284933053224, 'num_leaves': 30, 'feature_fraction': 0.9419263554723443, 'bagging_fraction': 0.9496190419196208, 'bagging_freq': 1, 'min_child_samples': 65}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:31,421]\u001b[0m Trial 57 finished with value: 0.8293955181721172 and parameters: {'lambda_l1': 0.020567583208542774, 'lambda_l2': 0.0005004191139469497, 'num_leaves': 16, 'feature_fraction': 0.748996284934557, 'bagging_fraction': 0.9813849178578143, 'bagging_freq': 2, 'min_child_samples': 47}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:31,676]\u001b[0m Trial 58 finished with value: 0.8338961772644529 and parameters: {'lambda_l1': 0.11304699848272576, 'lambda_l2': 9.80719553662336e-06, 'num_leaves': 23, 'feature_fraction': 0.8260291054666281, 'bagging_fraction': 0.8608126428126366, 'bagging_freq': 5, 'min_child_samples': 52}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:31,930]\u001b[0m Trial 59 finished with value: 0.8293955181721172 and parameters: {'lambda_l1': 0.07496502114753976, 'lambda_l2': 3.2426675785754083e-06, 'num_leaves': 23, 'feature_fraction': 0.8167405665229063, 'bagging_fraction': 0.9997307118581531, 'bagging_freq': 6, 'min_child_samples': 59}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:32,167]\u001b[0m Trial 60 finished with value: 0.8226664992781372 and parameters: {'lambda_l1': 0.0012742417075483313, 'lambda_l2': 1.8018162895917489, 'num_leaves': 28, 'feature_fraction': 0.7973143499446836, 'bagging_fraction': 0.7734254410595303, 'bagging_freq': 5, 'min_child_samples': 53}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:32,430]\u001b[0m Trial 61 finished with value: 0.8282781997363632 and parameters: {'lambda_l1': 0.3684128200452674, 'lambda_l2': 6.862417292674125e-07, 'num_leaves': 21, 'feature_fraction': 0.9123181435646052, 'bagging_fraction': 0.8639522191533947, 'bagging_freq': 4, 'min_child_samples': 43}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:32,667]\u001b[0m Trial 62 finished with value: 0.8148389931579938 and parameters: {'lambda_l1': 3.62781426272069, 'lambda_l2': 1.0258790767311433e-05, 'num_leaves': 20, 'feature_fraction': 0.9733613668715477, 'bagging_fraction': 0.9248270656936931, 'bagging_freq': 5, 'min_child_samples': 49}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:32,913]\u001b[0m Trial 63 finished with value: 0.8204255853367648 and parameters: {'lambda_l1': 0.12324901899909968, 'lambda_l2': 5.270127858966045e-05, 'num_leaves': 23, 'feature_fraction': 0.9310308656986981, 'bagging_fraction': 0.6661634702593455, 'bagging_freq': 4, 'min_child_samples': 46}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:33,093]\u001b[0m Trial 64 finished with value: 0.811493314920595 and parameters: {'lambda_l1': 0.9991309155323291, 'lambda_l2': 8.839605933424398e-05, 'num_leaves': 2, 'feature_fraction': 0.8538653603614574, 'bagging_fraction': 0.8880724886393485, 'bagging_freq': 3, 'min_child_samples': 36}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:33,351]\u001b[0m Trial 65 finished with value: 0.8338899001945892 and parameters: {'lambda_l1': 0.006237686630729803, 'lambda_l2': 2.581559678303125e-05, 'num_leaves': 19, 'feature_fraction': 0.8930591850339711, 'bagging_fraction': 0.9543143016475211, 'bagging_freq': 5, 'min_child_samples': 54}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:33,611]\u001b[0m Trial 66 finished with value: 0.8338899001945892 and parameters: {'lambda_l1': 0.023151849740663588, 'lambda_l2': 3.7926583782791483e-06, 'num_leaves': 17, 'feature_fraction': 0.8944978798639422, 'bagging_fraction': 0.9484389341392316, 'bagging_freq': 5, 'min_child_samples': 53}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:33,856]\u001b[0m Trial 67 finished with value: 0.829408072311845 and parameters: {'lambda_l1': 0.03091843283831423, 'lambda_l2': 1.1148764748417622e-06, 'num_leaves': 16, 'feature_fraction': 0.8915807027459327, 'bagging_fraction': 0.9451338275779183, 'bagging_freq': 6, 'min_child_samples': 63}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-22 20:32:34,113]\u001b[0m Trial 68 finished with value: 0.8237775406440274 and parameters: {'lambda_l1': 0.004670090636570892, 'lambda_l2': 1.59052769245356e-07, 'num_leaves': 18, 'feature_fraction': 0.8297637914276058, 'bagging_fraction': 0.9530282046847264, 'bagging_freq': 5, 'min_child_samples': 54}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:34,364]\u001b[0m Trial 69 finished with value: 0.832772581758835 and parameters: {'lambda_l1': 0.008095474646872571, 'lambda_l2': 5.077386409490682e-06, 'num_leaves': 14, 'feature_fraction': 0.6764838120463884, 'bagging_fraction': 0.9221408818808012, 'bagging_freq': 6, 'min_child_samples': 60}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:34,601]\u001b[0m Trial 70 finished with value: 0.8215303496327915 and parameters: {'lambda_l1': 0.019590666217987537, 'lambda_l2': 2.303774678986589e-05, 'num_leaves': 7, 'feature_fraction': 0.6369873866820246, 'bagging_fraction': 0.9833622353471669, 'bagging_freq': 5, 'min_child_samples': 51}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:34,883]\u001b[0m Trial 71 finished with value: 0.8282781997363632 and parameters: {'lambda_l1': 0.0004608540646278073, 'lambda_l2': 8.403595806011956e-06, 'num_leaves': 20, 'feature_fraction': 0.9077949826121248, 'bagging_fraction': 0.96389149993437, 'bagging_freq': 5, 'min_child_samples': 45}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:35,140]\u001b[0m Trial 72 finished with value: 0.8316364321134895 and parameters: {'lambda_l1': 0.07596571386232429, 'lambda_l2': 2.5287816079727355e-05, 'num_leaves': 19, 'feature_fraction': 0.8691794307514382, 'bagging_fraction': 0.9806843686858877, 'bagging_freq': 5, 'min_child_samples': 57}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:35,405]\u001b[0m Trial 73 finished with value: 0.8372481325717155 and parameters: {'lambda_l1': 0.22416551978356858, 'lambda_l2': 3.710815628820659e-06, 'num_leaves': 11, 'feature_fraction': 0.9259409451593181, 'bagging_fraction': 0.9995244893393281, 'bagging_freq': 5, 'min_child_samples': 49}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:35,662]\u001b[0m Trial 74 finished with value: 0.8316427091833531 and parameters: {'lambda_l1': 0.28088406069760463, 'lambda_l2': 2.8163773742061192e-06, 'num_leaves': 11, 'feature_fraction': 0.9585868693398384, 'bagging_fraction': 0.9352858352400958, 'bagging_freq': 6, 'min_child_samples': 52}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:35,915]\u001b[0m Trial 75 finished with value: 0.8282719226664993 and parameters: {'lambda_l1': 0.12967848195518827, 'lambda_l2': 9.088981616993074e-07, 'num_leaves': 8, 'feature_fraction': 0.9833762059524647, 'bagging_fraction': 0.999547618526205, 'bagging_freq': 5, 'min_child_samples': 55}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:36,138]\u001b[0m Trial 76 finished with value: 0.813684012303057 and parameters: {'lambda_l1': 0.06160129987458541, 'lambda_l2': 3.5943128511965317e-06, 'num_leaves': 17, 'feature_fraction': 0.8924163915143161, 'bagging_fraction': 0.4726012813312743, 'bagging_freq': 5, 'min_child_samples': 40}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:36,428]\u001b[0m Trial 77 finished with value: 0.8271420500910175 and parameters: {'lambda_l1': 0.04155878284419578, 'lambda_l2': 4.998651503834734e-07, 'num_leaves': 12, 'feature_fraction': 0.8450707242133666, 'bagging_fraction': 0.9564942967620326, 'bagging_freq': 5, 'min_child_samples': 43}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:36,660]\u001b[0m Trial 78 finished with value: 0.8237900947837549 and parameters: {'lambda_l1': 0.23314187152304677, 'lambda_l2': 1.4531941127256656e-06, 'num_leaves': 14, 'feature_fraction': 0.5754214777445744, 'bagging_fraction': 0.9097048395255692, 'bagging_freq': 6, 'min_child_samples': 69}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:36,873]\u001b[0m Trial 79 finished with value: 0.8148076078086749 and parameters: {'lambda_l1': 0.6164877354361878, 'lambda_l2': 4.3082161577767635e-08, 'num_leaves': 5, 'feature_fraction': 0.9378955871381447, 'bagging_fraction': 0.5953455461671947, 'bagging_freq': 7, 'min_child_samples': 50}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:37,122]\u001b[0m Trial 80 finished with value: 0.8316427091833534 and parameters: {'lambda_l1': 0.00599980951234499, 'lambda_l2': 1.3141158566421575e-05, 'num_leaves': 29, 'feature_fraction': 0.865037020870097, 'bagging_fraction': 0.8767461914134154, 'bagging_freq': 4, 'min_child_samples': 58}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:37,392]\u001b[0m Trial 81 finished with value: 0.8249011361496453 and parameters: {'lambda_l1': 0.002408903377310417, 'lambda_l2': 5.004516565943054e-05, 'num_leaves': 24, 'feature_fraction': 0.9226669610856061, 'bagging_fraction': 0.9664910881376431, 'bagging_freq': 4, 'min_child_samples': 48}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:37,671]\u001b[0m Trial 82 finished with value: 0.8237775406440274 and parameters: {'lambda_l1': 0.00011129010839353007, 'lambda_l2': 0.00021018668963745696, 'num_leaves': 22, 'feature_fraction': 0.4086782829456403, 'bagging_fraction': 0.9822584052320559, 'bagging_freq': 5, 'min_child_samples': 48}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:37,930]\u001b[0m Trial 83 finished with value: 0.8293892411022534 and parameters: {'lambda_l1': 0.1356825343487809, 'lambda_l2': 8.709431643238518e-05, 'num_leaves': 31, 'feature_fraction': 0.926267898961927, 'bagging_fraction': 0.9372454193589559, 'bagging_freq': 4, 'min_child_samples': 62}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:38,195]\u001b[0m Trial 84 finished with value: 0.8327537505492437 and parameters: {'lambda_l1': 0.019449648219400973, 'lambda_l2': 7.501127069752386e-06, 'num_leaves': 26, 'feature_fraction': 0.9001562003897604, 'bagging_fraction': 0.987317407810519, 'bagging_freq': 5, 'min_child_samples': 53}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:38,452]\u001b[0m Trial 85 finished with value: 0.8271420500910175 and parameters: {'lambda_l1': 1.8674127674448473, 'lambda_l2': 0.00041745826010195007, 'num_leaves': 27, 'feature_fraction': 0.8787305472525723, 'bagging_fraction': 0.962300663234522, 'bagging_freq': 4, 'min_child_samples': 46}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:38,748]\u001b[0m Trial 86 finished with value: 0.8248948590797814 and parameters: {'lambda_l1': 0.00198666985613899, 'lambda_l2': 0.0013173174360721959, 'num_leaves': 25, 'feature_fraction': 0.9158498796541703, 'bagging_fraction': 0.971738406182177, 'bagging_freq': 3, 'min_child_samples': 41}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:39,019]\u001b[0m Trial 87 finished with value: 0.8282781997363632 and parameters: {'lambda_l1': 0.3783830321250681, 'lambda_l2': 1.926168562970548e-06, 'num_leaves': 24, 'feature_fraction': 0.7746428304909834, 'bagging_fraction': 0.9333178101753618, 'bagging_freq': 5, 'min_child_samples': 51}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:39,280]\u001b[0m Trial 88 finished with value: 0.8294017952419811 and parameters: {'lambda_l1': 0.09458648373436777, 'lambda_l2': 0.0037807645918339064, 'num_leaves': 9, 'feature_fraction': 0.9572011507488654, 'bagging_fraction': 0.9907529677425011, 'bagging_freq': 3, 'min_child_samples': 38}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:39,541]\u001b[0m Trial 89 finished with value: 0.8350134957002071 and parameters: {'lambda_l1': 4.119795472650435e-05, 'lambda_l2': 2.5680453821214703e-05, 'num_leaves': 21, 'feature_fraction': 0.6133138369649708, 'bagging_fraction': 0.950905373314695, 'bagging_freq': 4, 'min_child_samples': 55}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:39,791]\u001b[0m Trial 90 finished with value: 0.828278199736363 and parameters: {'lambda_l1': 4.916193990240879e-06, 'lambda_l2': 2.2788577596221363e-05, 'num_leaves': 32, 'feature_fraction': 0.6044217131136912, 'bagging_fraction': 0.851672348694522, 'bagging_freq': 4, 'min_child_samples': 55}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-22 20:32:40,058]\u001b[0m Trial 91 finished with value: 0.8305128366078716 and parameters: {'lambda_l1': 2.3928233696775014e-05, 'lambda_l2': 3.9209572322883005e-05, 'num_leaves': 21, 'feature_fraction': 0.6265413254410475, 'bagging_fraction': 0.9559185973390645, 'bagging_freq': 4, 'min_child_samples': 50}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:40,334]\u001b[0m Trial 92 finished with value: 0.8271608813006088 and parameters: {'lambda_l1': 5.9256661053465985e-05, 'lambda_l2': 4.598110065403515e-06, 'num_leaves': 23, 'feature_fraction': 0.5448188151503046, 'bagging_fraction': 0.9151544655549616, 'bagging_freq': 4, 'min_child_samples': 45}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:40,576]\u001b[0m Trial 93 finished with value: 0.8305191136777352 and parameters: {'lambda_l1': 1.1184839855199119e-05, 'lambda_l2': 0.0006297518332193255, 'num_leaves': 22, 'feature_fraction': 0.6628553775433524, 'bagging_fraction': 0.944231428821731, 'bagging_freq': 4, 'min_child_samples': 66}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:40,818]\u001b[0m Trial 94 finished with value: 0.8215491808423827 and parameters: {'lambda_l1': 0.00019879101759773677, 'lambda_l2': 0.000174516030352372, 'num_leaves': 17, 'feature_fraction': 0.729959233626181, 'bagging_fraction': 0.8235402570707996, 'bagging_freq': 5, 'min_child_samples': 60}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:41,083]\u001b[0m Trial 95 finished with value: 0.8316489862532169 and parameters: {'lambda_l1': 0.052187531741085584, 'lambda_l2': 7.776804852362085e-05, 'num_leaves': 19, 'feature_fraction': 0.9361931918229928, 'bagging_fraction': 0.9724440941749355, 'bagging_freq': 3, 'min_child_samples': 57}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:41,359]\u001b[0m Trial 96 finished with value: 0.8271608813006089 and parameters: {'lambda_l1': 0.0006486123282817797, 'lambda_l2': 1.2863906028688283e-05, 'num_leaves': 28, 'feature_fraction': 0.7072393160530069, 'bagging_fraction': 0.8938432910313799, 'bagging_freq': 2, 'min_child_samples': 48}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:41,597]\u001b[0m Trial 97 finished with value: 0.8193082669010107 and parameters: {'lambda_l1': 0.16726939353103037, 'lambda_l2': 2.2975592041257744e-05, 'num_leaves': 20, 'feature_fraction': 0.5969574403456124, 'bagging_fraction': 0.9996025864558219, 'bagging_freq': 4, 'min_child_samples': 72}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:41,867]\u001b[0m Trial 98 finished with value: 0.8282719226664993 and parameters: {'lambda_l1': 0.0003192354759693718, 'lambda_l2': 0.00030468662476624176, 'num_leaves': 22, 'feature_fraction': 0.9808412586224187, 'bagging_fraction': 0.9473818682492193, 'bagging_freq': 5, 'min_child_samples': 53}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:42,129]\u001b[0m Trial 99 finished with value: 0.8316364321134895 and parameters: {'lambda_l1': 0.010180353444753643, 'lambda_l2': 3.5899079223482446e-05, 'num_leaves': 15, 'feature_fraction': 0.8878356853345102, 'bagging_fraction': 0.9256491224065487, 'bagging_freq': 4, 'min_child_samples': 55}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:42,415]\u001b[0m Trial 100 finished with value: 0.8316364321134895 and parameters: {'lambda_l1': 2.441420481933406e-06, 'lambda_l2': 0.002711733808481383, 'num_leaves': 21, 'feature_fraction': 0.9480338193552813, 'bagging_fraction': 0.9722797707812918, 'bagging_freq': 5, 'min_child_samples': 43}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:42,671]\u001b[0m Trial 101 finished with value: 0.8305128366078713 and parameters: {'lambda_l1': 0.6879992924681196, 'lambda_l2': 0.0001317794619557778, 'num_leaves': 21, 'feature_fraction': 0.90916459932836, 'bagging_fraction': 0.9012663784533421, 'bagging_freq': 4, 'min_child_samples': 51}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:43,001]\u001b[0m Trial 102 finished with value: 0.8226413909986817 and parameters: {'lambda_l1': 1.4972629307611849, 'lambda_l2': 0.00881716976422724, 'num_leaves': 19, 'feature_fraction': 0.9590454135218269, 'bagging_fraction': 0.954688270185467, 'bagging_freq': 4, 'min_child_samples': 20}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:43,232]\u001b[0m Trial 103 finished with value: 0.8181972255351202 and parameters: {'lambda_l1': 5.505681306080477, 'lambda_l2': 0.0008313945827959195, 'num_leaves': 23, 'feature_fraction': 0.9449456660427578, 'bagging_fraction': 0.8828622365428727, 'bagging_freq': 3, 'min_child_samples': 32}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:43,606]\u001b[0m Trial 104 finished with value: 0.8271357730211537 and parameters: {'lambda_l1': 1.0022731840009542, 'lambda_l2': 6.270156828482039e-05, 'num_leaves': 25, 'feature_fraction': 0.5766561250510195, 'bagging_fraction': 0.9836662748118168, 'bagging_freq': 4, 'min_child_samples': 11}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:43,881]\u001b[0m Trial 105 finished with value: 0.8215303496327915 and parameters: {'lambda_l1': 0.28539843618977667, 'lambda_l2': 0.00015727681123211504, 'num_leaves': 18, 'feature_fraction': 0.9245317218345654, 'bagging_fraction': 0.9294775378601928, 'bagging_freq': 3, 'min_child_samples': 48}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:44,210]\u001b[0m Trial 106 finished with value: 0.8215303496327915 and parameters: {'lambda_l1': 0.03176743975904893, 'lambda_l2': 1.156874601394538e-05, 'num_leaves': 30, 'feature_fraction': 0.8989631990501604, 'bagging_fraction': 0.9191926415725702, 'bagging_freq': 4, 'min_child_samples': 28}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:44,482]\u001b[0m Trial 107 finished with value: 0.8305191136777352 and parameters: {'lambda_l1': 0.40292144083855697, 'lambda_l2': 6.308030119355047e-06, 'num_leaves': 20, 'feature_fraction': 0.8150353413388918, 'bagging_fraction': 0.9623308384609592, 'bagging_freq': 5, 'min_child_samples': 45}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:44,742]\u001b[0m Trial 108 finished with value: 0.8316427091833531 and parameters: {'lambda_l1': 1.0337664411115462e-07, 'lambda_l2': 0.000260165740633857, 'num_leaves': 24, 'feature_fraction': 0.935534042395944, 'bagging_fraction': 0.9890472342656226, 'bagging_freq': 5, 'min_child_samples': 58}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:45,003]\u001b[0m Trial 109 finished with value: 0.8260372857949909 and parameters: {'lambda_l1': 0.014807136289159107, 'lambda_l2': 2.817721713890005e-05, 'num_leaves': 29, 'feature_fraction': 0.6504748508296276, 'bagging_fraction': 0.9109110610157991, 'bagging_freq': 4, 'min_child_samples': 54}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:45,257]\u001b[0m Trial 110 finished with value: 0.8316364321134895 and parameters: {'lambda_l1': 0.08220124525385654, 'lambda_l2': 1.9273046382777803e-05, 'num_leaves': 27, 'feature_fraction': 0.9992748269741919, 'bagging_fraction': 0.9455598583548168, 'bagging_freq': 4, 'min_child_samples': 62}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:45,515]\u001b[0m Trial 111 finished with value: 0.8316427091833531 and parameters: {'lambda_l1': 0.005221870139631687, 'lambda_l2': 3.622614255538926e-06, 'num_leaves': 12, 'feature_fraction': 0.6665868992699322, 'bagging_fraction': 0.9734683792864095, 'bagging_freq': 6, 'min_child_samples': 60}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:45,761]\u001b[0m Trial 112 finished with value: 0.8283033080158184 and parameters: {'lambda_l1': 0.007346089818596443, 'lambda_l2': 1.753290302817956e-06, 'num_leaves': 14, 'feature_fraction': 0.6862716266053164, 'bagging_fraction': 0.9240851469455091, 'bagging_freq': 6, 'min_child_samples': 64}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:45,987]\u001b[0m Trial 113 finished with value: 0.812560416797439 and parameters: {'lambda_l1': 0.024068474675433875, 'lambda_l2': 5.240859644241836e-06, 'num_leaves': 15, 'feature_fraction': 0.6145109736846287, 'bagging_fraction': 0.7303411753693254, 'bagging_freq': 7, 'min_child_samples': 67}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-22 20:32:46,244]\u001b[0m Trial 114 finished with value: 0.8260498399347185 and parameters: {'lambda_l1': 0.0009969959000598687, 'lambda_l2': 9.007014884141505e-05, 'num_leaves': 13, 'feature_fraction': 0.676586223051265, 'bagging_fraction': 0.8975084824279764, 'bagging_freq': 6, 'min_child_samples': 56}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:46,500]\u001b[0m Trial 115 finished with value: 0.826037285794991 and parameters: {'lambda_l1': 0.1740600076616413, 'lambda_l2': 4.970639135883205e-05, 'num_leaves': 13, 'feature_fraction': 0.6237990809016247, 'bagging_fraction': 0.8692541414343299, 'bagging_freq': 7, 'min_child_samples': 52}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:46,773]\u001b[0m Trial 116 finished with value: 0.8338899001945892 and parameters: {'lambda_l1': 0.04913897716242935, 'lambda_l2': 9.635858888110788e-06, 'num_leaves': 11, 'feature_fraction': 0.7024436131963749, 'bagging_fraction': 0.955184610086501, 'bagging_freq': 6, 'min_child_samples': 50}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:47,027]\u001b[0m Trial 117 finished with value: 0.8237838177138912 and parameters: {'lambda_l1': 2.3125155971024736, 'lambda_l2': 1.4352992780430793e-05, 'num_leaves': 10, 'feature_fraction': 0.8605133674397691, 'bagging_fraction': 0.9526508547919396, 'bagging_freq': 3, 'min_child_samples': 47}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:47,273]\u001b[0m Trial 118 finished with value: 0.8226727763480008 and parameters: {'lambda_l1': 0.04938757498755415, 'lambda_l2': 0.00011217131390889392, 'num_leaves': 11, 'feature_fraction': 0.8394989779041699, 'bagging_fraction': 0.9895130083734557, 'bagging_freq': 2, 'min_child_samples': 79}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:47,557]\u001b[0m Trial 119 finished with value: 0.8305002824681438 and parameters: {'lambda_l1': 0.6138326299318246, 'lambda_l2': 0.0003818689732188472, 'num_leaves': 22, 'feature_fraction': 0.9708298503619099, 'bagging_fraction': 0.9683716089474699, 'bagging_freq': 4, 'min_child_samples': 42}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:47,827]\u001b[0m Trial 120 finished with value: 0.8350009415604795 and parameters: {'lambda_l1': 0.3013717147462133, 'lambda_l2': 0.0012183514767938068, 'num_leaves': 23, 'feature_fraction': 0.9137531576269602, 'bagging_fraction': 0.9393023695965079, 'bagging_freq': 5, 'min_child_samples': 50}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:48,094]\u001b[0m Trial 121 finished with value: 0.8237775406440273 and parameters: {'lambda_l1': 0.30906462216995684, 'lambda_l2': 0.001771367459301979, 'num_leaves': 23, 'feature_fraction': 0.4947622600452487, 'bagging_fraction': 0.9385322042238998, 'bagging_freq': 5, 'min_child_samples': 50}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:48,326]\u001b[0m Trial 122 finished with value: 0.8260310087251271 and parameters: {'lambda_l1': 0.10368371346831166, 'lambda_l2': 0.00063699910711572, 'num_leaves': 6, 'feature_fraction': 0.9177845330762011, 'bagging_fraction': 0.9570139281701294, 'bagging_freq': 5, 'min_child_samples': 49}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:48,589]\u001b[0m Trial 123 finished with value: 0.8294080723118448 and parameters: {'lambda_l1': 1.278462817058691, 'lambda_l2': 9.785042076089061e-06, 'num_leaves': 24, 'feature_fraction': 0.8796018407419175, 'bagging_fraction': 0.9802786377894558, 'bagging_freq': 5, 'min_child_samples': 53}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:48,871]\u001b[0m Trial 124 finished with value: 0.8305191136777352 and parameters: {'lambda_l1': 0.20897282674777376, 'lambda_l2': 0.0011266563803284072, 'num_leaves': 26, 'feature_fraction': 0.896535235703315, 'bagging_fraction': 0.9999636511943943, 'bagging_freq': 5, 'min_child_samples': 46}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:49,129]\u001b[0m Trial 125 finished with value: 0.8271420500910175 and parameters: {'lambda_l1': 0.47040608828090597, 'lambda_l2': 3.70446617648971e-05, 'num_leaves': 21, 'feature_fraction': 0.9090556302771828, 'bagging_fraction': 0.938587624675898, 'bagging_freq': 4, 'min_child_samples': 51}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:49,415]\u001b[0m Trial 126 finished with value: 0.8316364321134895 and parameters: {'lambda_l1': 0.00010235475331934884, 'lambda_l2': 0.00022592192901775386, 'num_leaves': 22, 'feature_fraction': 0.9548406035687362, 'bagging_fraction': 0.970545620467604, 'bagging_freq': 5, 'min_child_samples': 44}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:49,703]\u001b[0m Trial 127 finished with value: 0.8260184545853996 and parameters: {'lambda_l1': 0.10677762680664625, 'lambda_l2': 6.405488895726675e-05, 'num_leaves': 31, 'feature_fraction': 0.9310708407064494, 'bagging_fraction': 0.9080742490540691, 'bagging_freq': 6, 'min_child_samples': 40}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:49,927]\u001b[0m Trial 128 finished with value: 0.8181595631159375 and parameters: {'lambda_l1': 0.04854113121014185, 'lambda_l2': 7.906906793513228e-06, 'num_leaves': 19, 'feature_fraction': 0.7500988778060339, 'bagging_fraction': 0.5322455722848536, 'bagging_freq': 3, 'min_child_samples': 54}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:50,191]\u001b[0m Trial 129 finished with value: 0.8282719226664993 and parameters: {'lambda_l1': 0.2601758860250101, 'lambda_l2': 0.0004672594422110194, 'num_leaves': 20, 'feature_fraction': 0.9417040774499512, 'bagging_fraction': 0.9502307429420435, 'bagging_freq': 4, 'min_child_samples': 57}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:50,458]\u001b[0m Trial 130 finished with value: 0.8293955181721172 and parameters: {'lambda_l1': 4.156093994534992e-05, 'lambda_l2': 0.002957160787169478, 'num_leaves': 10, 'feature_fraction': 0.9184026729346768, 'bagging_fraction': 0.932271966016139, 'bagging_freq': 6, 'min_child_samples': 47}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:50,705]\u001b[0m Trial 131 finished with value: 0.8271671583704727 and parameters: {'lambda_l1': 0.015419003308441478, 'lambda_l2': 2.4798486590998685e-06, 'num_leaves': 11, 'feature_fraction': 0.6441367884829354, 'bagging_fraction': 0.9162667837272143, 'bagging_freq': 6, 'min_child_samples': 60}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:50,977]\u001b[0m Trial 132 finished with value: 0.8260247316552635 and parameters: {'lambda_l1': 0.011435044141010762, 'lambda_l2': 4.428027564219167e-06, 'num_leaves': 16, 'feature_fraction': 0.6363941122496738, 'bagging_fraction': 0.9619128901942636, 'bagging_freq': 6, 'min_child_samples': 49}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:51,326]\u001b[0m Trial 133 finished with value: 0.8226476680685456 and parameters: {'lambda_l1': 0.025305849666525233, 'lambda_l2': 1.2209631604991112e-06, 'num_leaves': 17, 'feature_fraction': 0.7015361912774168, 'bagging_fraction': 0.982757774982424, 'bagging_freq': 6, 'min_child_samples': 6}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:51,593]\u001b[0m Trial 134 finished with value: 0.8305191136777352 and parameters: {'lambda_l1': 0.001630749433758015, 'lambda_l2': 1.9115639254539357e-05, 'num_leaves': 25, 'feature_fraction': 0.8891410413930292, 'bagging_fraction': 0.9273976735847572, 'bagging_freq': 5, 'min_child_samples': 52}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:51,864]\u001b[0m Trial 135 finished with value: 0.8249199673592369 and parameters: {'lambda_l1': 0.06790021815846708, 'lambda_l2': 6.720533140494584e-06, 'num_leaves': 22, 'feature_fraction': 0.7176806264668425, 'bagging_fraction': 0.8910391389882653, 'bagging_freq': 6, 'min_child_samples': 56}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:52,113]\u001b[0m Trial 136 finished with value: 0.8305128366078713 and parameters: {'lambda_l1': 0.7700950230731654, 'lambda_l2': 0.0063685910852309905, 'num_leaves': 14, 'feature_fraction': 0.5850664957225613, 'bagging_fraction': 0.9457196248013503, 'bagging_freq': 5, 'min_child_samples': 58}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-22 20:32:52,388]\u001b[0m Trial 137 finished with value: 0.8237775406440274 and parameters: {'lambda_l1': 0.17120683692142855, 'lambda_l2': 0.00013957222508214373, 'num_leaves': 21, 'feature_fraction': 0.9658824185986019, 'bagging_fraction': 0.9909543629928306, 'bagging_freq': 4, 'min_child_samples': 50}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:52,655]\u001b[0m Trial 138 finished with value: 0.8305128366078713 and parameters: {'lambda_l1': 0.008854407588337906, 'lambda_l2': 9.68911327558091e-06, 'num_leaves': 23, 'feature_fraction': 0.6581268399725917, 'bagging_fraction': 0.9630387641829684, 'bagging_freq': 4, 'min_child_samples': 54}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:52,928]\u001b[0m Trial 139 finished with value: 0.8293892411022536 and parameters: {'lambda_l1': 0.5137074884367819, 'lambda_l2': 2.940767346465521e-06, 'num_leaves': 12, 'feature_fraction': 0.9032246145161328, 'bagging_fraction': 0.9773495069450313, 'bagging_freq': 5, 'min_child_samples': 45}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:53,196]\u001b[0m Trial 140 finished with value: 0.8226476680685456 and parameters: {'lambda_l1': 0.0031884764861565447, 'lambda_l2': 2.8997278806337565e-05, 'num_leaves': 18, 'feature_fraction': 0.8750475602472105, 'bagging_fraction': 0.854993317460407, 'bagging_freq': 4, 'min_child_samples': 47}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:53,455]\u001b[0m Trial 141 finished with value: 0.827154604230745 and parameters: {'lambda_l1': 2.2274017001384287e-08, 'lambda_l2': 4.448276595633576e-05, 'num_leaves': 29, 'feature_fraction': 0.9239993051868411, 'bagging_fraction': 0.8360961131375221, 'bagging_freq': 4, 'min_child_samples': 52}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:53,706]\u001b[0m Trial 142 finished with value: 0.8282719226664993 and parameters: {'lambda_l1': 1.1345554472498186e-07, 'lambda_l2': 1.59189712226354e-05, 'num_leaves': 28, 'feature_fraction': 0.8558885390961687, 'bagging_fraction': 0.8744992155888697, 'bagging_freq': 4, 'min_child_samples': 61}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:53,969]\u001b[0m Trial 143 finished with value: 0.8338961772644529 and parameters: {'lambda_l1': 0.041376698122367224, 'lambda_l2': 7.061036880724973e-05, 'num_leaves': 10, 'feature_fraction': 0.9098421061161583, 'bagging_fraction': 0.9176344442396581, 'bagging_freq': 3, 'min_child_samples': 59}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:54,233]\u001b[0m Trial 144 finished with value: 0.830525390747599 and parameters: {'lambda_l1': 0.04118223792982928, 'lambda_l2': 6.85323842909166e-05, 'num_leaves': 9, 'feature_fraction': 0.9475078791520715, 'bagging_fraction': 0.9176146256842153, 'bagging_freq': 3, 'min_child_samples': 55}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:54,502]\u001b[0m Trial 145 finished with value: 0.8271357730211537 and parameters: {'lambda_l1': 0.0951006899361754, 'lambda_l2': 9.972523065763664e-05, 'num_leaves': 9, 'feature_fraction': 0.9069180387044024, 'bagging_fraction': 0.8991551801733263, 'bagging_freq': 3, 'min_child_samples': 22}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:54,775]\u001b[0m Trial 146 finished with value: 0.8282719226664993 and parameters: {'lambda_l1': 1.7157710641445434e-05, 'lambda_l2': 0.00021097288881997823, 'num_leaves': 12, 'feature_fraction': 0.9324739274596608, 'bagging_fraction': 0.9353051976105876, 'bagging_freq': 3, 'min_child_samples': 49}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:55,004]\u001b[0m Trial 147 finished with value: 0.8148076078086749 and parameters: {'lambda_l1': 0.028506563386250374, 'lambda_l2': 0.0008395946475257677, 'num_leaves': 10, 'feature_fraction': 0.9827523162028197, 'bagging_fraction': 0.952405082992364, 'bagging_freq': 3, 'min_child_samples': 85}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:55,227]\u001b[0m Trial 148 finished with value: 0.819295712761283 and parameters: {'lambda_l1': 0.1466859830704831, 'lambda_l2': 0.0014250390502436366, 'num_leaves': 20, 'feature_fraction': 0.6748962467056514, 'bagging_fraction': 0.6254290016146619, 'bagging_freq': 5, 'min_child_samples': 59}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:55,475]\u001b[0m Trial 149 finished with value: 0.8249074132195092 and parameters: {'lambda_l1': 0.3355906428761672, 'lambda_l2': 0.3343192361410845, 'num_leaves': 11, 'feature_fraction': 0.8895940119752143, 'bagging_fraction': 0.9238374740819135, 'bagging_freq': 3, 'min_child_samples': 64}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:55,886]\u001b[0m Trial 150 finished with value: 0.8159186491745652 and parameters: {'lambda_l1': 0.000197445510637263, 'lambda_l2': 7.059102333979809e-07, 'num_leaves': 23, 'feature_fraction': 0.9149359257676426, 'bagging_fraction': 0.9730447505907351, 'bagging_freq': 2, 'min_child_samples': 15}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:56,129]\u001b[0m Trial 151 finished with value: 0.8316552633230808 and parameters: {'lambda_l1': 0.019816276467270383, 'lambda_l2': 3.872014681278919e-05, 'num_leaves': 8, 'feature_fraction': 0.8725129968864749, 'bagging_fraction': 0.9031676345855512, 'bagging_freq': 1, 'min_child_samples': 53}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:56,376]\u001b[0m Trial 152 finished with value: 0.826037285794991 and parameters: {'lambda_l1': 0.9077347299931102, 'lambda_l2': 2.7276468192584848e-05, 'num_leaves': 30, 'feature_fraction': 0.9351961974533229, 'bagging_fraction': 0.8846920312763566, 'bagging_freq': 5, 'min_child_samples': 58}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:56,626]\u001b[0m Trial 153 finished with value: 0.8305191136777352 and parameters: {'lambda_l1': 0.03085164344417351, 'lambda_l2': 1.5839187999308743e-05, 'num_leaves': 29, 'feature_fraction': 0.7872793263238796, 'bagging_fraction': 0.8089394509821175, 'bagging_freq': 3, 'min_child_samples': 56}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:56,897]\u001b[0m Trial 154 finished with value: 0.8305128366078713 and parameters: {'lambda_l1': 0.06573094300326432, 'lambda_l2': 6.705509279921592e-05, 'num_leaves': 24, 'feature_fraction': 0.8935700970601523, 'bagging_fraction': 0.9424187096853462, 'bagging_freq': 7, 'min_child_samples': 51}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:57,158]\u001b[0m Trial 155 finished with value: 0.8327663046889713 and parameters: {'lambda_l1': 1.7968304855072559e-06, 'lambda_l2': 0.0003360084484414806, 'num_leaves': 27, 'feature_fraction': 0.9132834148540865, 'bagging_fraction': 0.9882612081256744, 'bagging_freq': 4, 'min_child_samples': 62}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:57,419]\u001b[0m Trial 156 finished with value: 0.829408072311845 and parameters: {'lambda_l1': 2.738790751919351e-07, 'lambda_l2': 0.00011674866990229978, 'num_leaves': 21, 'feature_fraction': 0.6228665509276652, 'bagging_fraction': 0.7945444304370258, 'bagging_freq': 4, 'min_child_samples': 48}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:57,711]\u001b[0m Trial 157 finished with value: 0.8305128366078713 and parameters: {'lambda_l1': 8.048423137371471e-07, 'lambda_l2': 4.5675796686807e-06, 'num_leaves': 31, 'feature_fraction': 0.949073359232516, 'bagging_fraction': 0.9617138166435377, 'bagging_freq': 3, 'min_child_samples': 42}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:57,980]\u001b[0m Trial 158 finished with value: 0.8305128366078716 and parameters: {'lambda_l1': 4.5013910689759165e-08, 'lambda_l2': 0.00019057107890513113, 'num_leaves': 19, 'feature_fraction': 0.9268490140929626, 'bagging_fraction': 0.9996062653837385, 'bagging_freq': 5, 'min_child_samples': 54}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:58,250]\u001b[0m Trial 159 finished with value: 0.836137091205825 and parameters: {'lambda_l1': 0.13276347180122647, 'lambda_l2': 9.89710139141616e-06, 'num_leaves': 28, 'feature_fraction': 0.8981279767866908, 'bagging_fraction': 0.9092282983973848, 'bagging_freq': 6, 'min_child_samples': 50}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-22 20:32:58,521]\u001b[0m Trial 160 finished with value: 0.8237775406440273 and parameters: {'lambda_l1': 0.21590426350745634, 'lambda_l2': 7.591097993379233e-06, 'num_leaves': 28, 'feature_fraction': 0.6014419067186153, 'bagging_fraction': 0.9087818666412456, 'bagging_freq': 6, 'min_child_samples': 44}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:58,779]\u001b[0m Trial 161 finished with value: 0.8316489862532169 and parameters: {'lambda_l1': 0.12372634120992791, 'lambda_l2': 1.2877944491999885e-05, 'num_leaves': 30, 'feature_fraction': 0.9076549183932004, 'bagging_fraction': 0.8345111561561149, 'bagging_freq': 6, 'min_child_samples': 51}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:59,039]\u001b[0m Trial 162 finished with value: 0.8271671583704727 and parameters: {'lambda_l1': 0.3729002193740656, 'lambda_l2': 2.1432900337803034e-05, 'num_leaves': 28, 'feature_fraction': 0.8792503698264691, 'bagging_fraction': 0.8665102264359231, 'bagging_freq': 6, 'min_child_samples': 49}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:59,298]\u001b[0m Trial 163 finished with value: 0.8294080723118448 and parameters: {'lambda_l1': 0.05110284038380089, 'lambda_l2': 2.0747137617622755e-06, 'num_leaves': 26, 'feature_fraction': 0.8994274626427586, 'bagging_fraction': 0.9293834389742592, 'bagging_freq': 6, 'min_child_samples': 56}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:59,558]\u001b[0m Trial 164 finished with value: 0.8293955181721172 and parameters: {'lambda_l1': 0.006531595534836801, 'lambda_l2': 0.00036275439426542615, 'num_leaves': 10, 'feature_fraction': 0.9170143806163679, 'bagging_fraction': 0.9848165559215974, 'bagging_freq': 4, 'min_child_samples': 63}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:32:59,839]\u001b[0m Trial 165 finished with value: 0.8237775406440273 and parameters: {'lambda_l1': 0.2589117049111863, 'lambda_l2': 5.641126702570795e-06, 'num_leaves': 22, 'feature_fraction': 0.8651019993668496, 'bagging_fraction': 0.9551417061921584, 'bagging_freq': 5, 'min_child_samples': 46}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:33:00,101]\u001b[0m Trial 166 finished with value: 0.8372481325717155 and parameters: {'lambda_l1': 0.015458947929397561, 'lambda_l2': 0.00048377325993273837, 'num_leaves': 26, 'feature_fraction': 0.9363876051608453, 'bagging_fraction': 0.9751150721105847, 'bagging_freq': 4, 'min_child_samples': 61}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:33:00,372]\u001b[0m Trial 167 finished with value: 0.831648986253217 and parameters: {'lambda_l1': 0.016257860708057147, 'lambda_l2': 0.0005977857627803021, 'num_leaves': 27, 'feature_fraction': 0.9472996820408734, 'bagging_fraction': 0.9682392967698904, 'bagging_freq': 6, 'min_child_samples': 53}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:33:00,630]\u001b[0m Trial 168 finished with value: 0.830525390747599 and parameters: {'lambda_l1': 0.004402845517478327, 'lambda_l2': 0.0010499026798587061, 'num_leaves': 23, 'feature_fraction': 0.9587995203941538, 'bagging_fraction': 0.9366579551861546, 'bagging_freq': 5, 'min_child_samples': 60}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:33:00,904]\u001b[0m Trial 169 finished with value: 0.8237775406440274 and parameters: {'lambda_l1': 0.08209969367318203, 'lambda_l2': 0.0020641415783070444, 'num_leaves': 25, 'feature_fraction': 0.9369389200403896, 'bagging_fraction': 0.9520638797905584, 'bagging_freq': 4, 'min_child_samples': 50}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:33:01,269]\u001b[0m Trial 170 finished with value: 0.8237775406440274 and parameters: {'lambda_l1': 0.040195275957788594, 'lambda_l2': 3.3784099222947703e-06, 'num_leaves': 24, 'feature_fraction': 0.9251946635113388, 'bagging_fraction': 0.9784629022012583, 'bagging_freq': 4, 'min_child_samples': 26}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:33:01,529]\u001b[0m Trial 171 finished with value: 0.8293955181721173 and parameters: {'lambda_l1': 0.01182528042026445, 'lambda_l2': 0.00028528800672665637, 'num_leaves': 27, 'feature_fraction': 0.9139898227501715, 'bagging_fraction': 0.9895409752835023, 'bagging_freq': 4, 'min_child_samples': 66}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:33:01,783]\u001b[0m Trial 172 finished with value: 0.8350009415604795 and parameters: {'lambda_l1': 0.5769228499837792, 'lambda_l2': 0.00040655438594695283, 'num_leaves': 27, 'feature_fraction': 0.9053552485606218, 'bagging_fraction': 0.9667750915922655, 'bagging_freq': 4, 'min_child_samples': 62}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:33:02,032]\u001b[0m Trial 173 finished with value: 0.8327663046889711 and parameters: {'lambda_l1': 0.529636448421276, 'lambda_l2': 0.00015502105568806286, 'num_leaves': 29, 'feature_fraction': 0.8965150033225846, 'bagging_fraction': 0.9646162822088644, 'bagging_freq': 4, 'min_child_samples': 70}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:33:02,283]\u001b[0m Trial 174 finished with value: 0.8249074132195091 and parameters: {'lambda_l1': 1.2987769325265506, 'lambda_l2': 0.0007241946622378306, 'num_leaves': 26, 'feature_fraction': 0.929063453255582, 'bagging_fraction': 0.9176742409264921, 'bagging_freq': 4, 'min_child_samples': 58}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:33:02,563]\u001b[0m Trial 175 finished with value: 0.8271483271608814 and parameters: {'lambda_l1': 0.1472331558196383, 'lambda_l2': 0.0005209805603162842, 'num_leaves': 28, 'feature_fraction': 0.9401732590099232, 'bagging_fraction': 0.9457053168719673, 'bagging_freq': 4, 'min_child_samples': 47}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:33:02,827]\u001b[0m Trial 176 finished with value: 0.8327663046889713 and parameters: {'lambda_l1': 0.7061610355624647, 'lambda_l2': 4.827455063610207e-05, 'num_leaves': 25, 'feature_fraction': 0.8848806771654484, 'bagging_fraction': 0.9756201338387883, 'bagging_freq': 3, 'min_child_samples': 60}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:33:03,078]\u001b[0m Trial 177 finished with value: 0.8282907538760906 and parameters: {'lambda_l1': 2.2454981672340733, 'lambda_l2': 9.58737416074636e-06, 'num_leaves': 13, 'feature_fraction': 0.9562982393534398, 'bagging_fraction': 0.961208857737644, 'bagging_freq': 6, 'min_child_samples': 55}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:33:03,343]\u001b[0m Trial 178 finished with value: 0.830525390747599 and parameters: {'lambda_l1': 0.3221443782469561, 'lambda_l2': 0.00011207727421089956, 'num_leaves': 22, 'feature_fraction': 0.9045256523961719, 'bagging_fraction': 0.9379528037100416, 'bagging_freq': 5, 'min_child_samples': 52}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:33:03,606]\u001b[0m Trial 179 finished with value: 0.8327600276191076 and parameters: {'lambda_l1': 0.02440030329070183, 'lambda_l2': 7.484720212006665e-05, 'num_leaves': 29, 'feature_fraction': 0.9675328036862104, 'bagging_fraction': 0.9996932860873987, 'bagging_freq': 4, 'min_child_samples': 62}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:33:03,889]\u001b[0m Trial 180 finished with value: 0.8361308141359614 and parameters: {'lambda_l1': 0.10486590515105447, 'lambda_l2': 0.0014491237579528989, 'num_leaves': 26, 'feature_fraction': 0.688690795834287, 'bagging_fraction': 0.9722329180862063, 'bagging_freq': 3, 'min_child_samples': 50}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:33:04,171]\u001b[0m Trial 181 finished with value: 0.8293892411022534 and parameters: {'lambda_l1': 0.10298831499467012, 'lambda_l2': 0.002549855595031155, 'num_leaves': 26, 'feature_fraction': 0.7212753260188247, 'bagging_fraction': 0.9712381816869154, 'bagging_freq': 3, 'min_child_samples': 49}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:33:04,441]\u001b[0m Trial 182 finished with value: 0.8293955181721173 and parameters: {'lambda_l1': 0.1930340340719086, 'lambda_l2': 0.0014045696428521708, 'num_leaves': 26, 'feature_fraction': 0.6872306899139627, 'bagging_fraction': 0.9516942590505904, 'bagging_freq': 3, 'min_child_samples': 51}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-22 20:33:04,675]\u001b[0m Trial 183 finished with value: 0.8137028435126483 and parameters: {'lambda_l1': 0.058339653020666175, 'lambda_l2': 0.00039692050612386714, 'num_leaves': 27, 'feature_fraction': 0.7406393110276931, 'bagging_fraction': 0.9792801936172691, 'bagging_freq': 3, 'min_child_samples': 99}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:33:04,956]\u001b[0m Trial 184 finished with value: 0.8293892411022534 and parameters: {'lambda_l1': 0.5272388142667611, 'lambda_l2': 0.0038844727261595057, 'num_leaves': 24, 'feature_fraction': 0.9219223547583201, 'bagging_fraction': 0.9275668995157118, 'bagging_freq': 3, 'min_child_samples': 46}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:33:05,232]\u001b[0m Trial 185 finished with value: 0.8372606867114432 and parameters: {'lambda_l1': 0.03927538584025035, 'lambda_l2': 0.0008060611578088183, 'num_leaves': 23, 'feature_fraction': 0.7041819762119532, 'bagging_fraction': 0.9874678077120393, 'bagging_freq': 3, 'min_child_samples': 53}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:33:05,448]\u001b[0m Trial 186 finished with value: 0.8226790534178645 and parameters: {'lambda_l1': 0.08389158480569785, 'lambda_l2': 0.0009608910403038803, 'num_leaves': 4, 'feature_fraction': 0.736420868057379, 'bagging_fraction': 0.9858447628844617, 'bagging_freq': 3, 'min_child_samples': 53}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:33:05,729]\u001b[0m Trial 187 finished with value: 0.8327663046889713 and parameters: {'lambda_l1': 0.042507938865536776, 'lambda_l2': 0.0015845671964053046, 'num_leaves': 23, 'feature_fraction': 0.7075420513213868, 'bagging_fraction': 0.9668824389970319, 'bagging_freq': 3, 'min_child_samples': 49}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:33:06,006]\u001b[0m Trial 188 finished with value: 0.8260247316552632 and parameters: {'lambda_l1': 0.1422709452184247, 'lambda_l2': 0.0005752217946882857, 'num_leaves': 25, 'feature_fraction': 0.5652274626249567, 'bagging_fraction': 0.9916449739473728, 'bagging_freq': 3, 'min_child_samples': 55}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:33:06,340]\u001b[0m Trial 189 finished with value: 0.8316427091833531 and parameters: {'lambda_l1': 0.03043472528014409, 'lambda_l2': 0.00019923824476608993, 'num_leaves': 22, 'feature_fraction': 0.611095919694432, 'bagging_fraction': 0.978175877182217, 'bagging_freq': 3, 'min_child_samples': 30}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:33:06,618]\u001b[0m Trial 190 finished with value: 0.8271483271608812 and parameters: {'lambda_l1': 0.23354663765735437, 'lambda_l2': 0.0008951187710732063, 'num_leaves': 21, 'feature_fraction': 0.8979838525046407, 'bagging_fraction': 0.9593832078343243, 'bagging_freq': 4, 'min_child_samples': 51}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:33:06,887]\u001b[0m Trial 191 finished with value: 0.8350134957002073 and parameters: {'lambda_l1': 0.016982651434014787, 'lambda_l2': 5.019761605604869e-06, 'num_leaves': 16, 'feature_fraction': 0.6802769892890806, 'bagging_fraction': 0.9447332717964526, 'bagging_freq': 4, 'min_child_samples': 57}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:33:07,159]\u001b[0m Trial 192 finished with value: 0.8327600276191074 and parameters: {'lambda_l1': 0.015927265741714786, 'lambda_l2': 0.00025589364362687113, 'num_leaves': 18, 'feature_fraction': 0.6980380988171961, 'bagging_fraction': 0.9535627219515876, 'bagging_freq': 4, 'min_child_samples': 57}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:33:07,400]\u001b[0m Trial 193 finished with value: 0.827154604230745 and parameters: {'lambda_l1': 0.07054785283778309, 'lambda_l2': 3.123316992486882e-05, 'num_leaves': 28, 'feature_fraction': 0.7134797432066202, 'bagging_fraction': 0.6908358496105276, 'bagging_freq': 4, 'min_child_samples': 53}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:33:07,664]\u001b[0m Trial 194 finished with value: 0.8260310087251271 and parameters: {'lambda_l1': 1.0351636264438873, 'lambda_l2': 1.130683937742722e-05, 'num_leaves': 16, 'feature_fraction': 0.6684827179497824, 'bagging_fraction': 0.9382899073991662, 'bagging_freq': 4, 'min_child_samples': 50}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:33:07,950]\u001b[0m Trial 195 finished with value: 0.8372544096415794 and parameters: {'lambda_l1': 0.039812108859202895, 'lambda_l2': 0.0019558319053693666, 'num_leaves': 20, 'feature_fraction': 0.6525228828929484, 'bagging_fraction': 0.9705884841739005, 'bagging_freq': 4, 'min_child_samples': 48}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:33:08,245]\u001b[0m Trial 196 finished with value: 0.8305065595380077 and parameters: {'lambda_l1': 0.03649272953918776, 'lambda_l2': 0.0018790434649149268, 'num_leaves': 20, 'feature_fraction': 0.6394206295107017, 'bagging_fraction': 0.9701291443331537, 'bagging_freq': 4, 'min_child_samples': 44}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:33:08,538]\u001b[0m Trial 197 finished with value: 0.8305191136777352 and parameters: {'lambda_l1': 0.02194164124650664, 'lambda_l2': 0.0008294533293802422, 'num_leaves': 20, 'feature_fraction': 0.6844072641730907, 'bagging_fraction': 0.9824139888015821, 'bagging_freq': 3, 'min_child_samples': 46}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:33:08,810]\u001b[0m Trial 198 finished with value: 0.8271608813006088 and parameters: {'lambda_l1': 0.011601497383664899, 'lambda_l2': 0.0021818283893941786, 'num_leaves': 17, 'feature_fraction': 0.6524339879088339, 'bagging_fraction': 0.9988412897049158, 'bagging_freq': 2, 'min_child_samples': 48}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:33:09,078]\u001b[0m Trial 199 finished with value: 0.824913690289373 and parameters: {'lambda_l1': 0.052620770534473685, 'lambda_l2': 0.003055135020023809, 'num_leaves': 19, 'feature_fraction': 0.631545079292905, 'bagging_fraction': 0.9469744976659645, 'bagging_freq': 5, 'min_child_samples': 48}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:33:09,349]\u001b[0m Trial 200 finished with value: 0.8350072186303434 and parameters: {'lambda_l1': 0.12881971280715548, 'lambda_l2': 0.001327261081724601, 'num_leaves': 15, 'feature_fraction': 0.6946111846168417, 'bagging_fraction': 0.9667101857809698, 'bagging_freq': 4, 'min_child_samples': 54}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:33:09,620]\u001b[0m Trial 201 finished with value: 0.8338836231247255 and parameters: {'lambda_l1': 0.11575946098621255, 'lambda_l2': 0.0012687713748129352, 'num_leaves': 17, 'feature_fraction': 0.6953926880088436, 'bagging_fraction': 0.9676385536050676, 'bagging_freq': 4, 'min_child_samples': 52}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:33:09,891]\u001b[0m Trial 202 finished with value: 0.8305128366078713 and parameters: {'lambda_l1': 0.1213233181676627, 'lambda_l2': 0.005178719056262875, 'num_leaves': 16, 'feature_fraction': 0.6974346081175804, 'bagging_fraction': 0.9608305892207868, 'bagging_freq': 4, 'min_child_samples': 54}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:33:10,160]\u001b[0m Trial 203 finished with value: 0.8338899001945892 and parameters: {'lambda_l1': 0.0003684473065697443, 'lambda_l2': 0.0004934167279315607, 'num_leaves': 11, 'feature_fraction': 0.6755480248894579, 'bagging_fraction': 0.9850274510319682, 'bagging_freq': 4, 'min_child_samples': 56}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:33:10,429]\u001b[0m Trial 204 finished with value: 0.8249011361496453 and parameters: {'lambda_l1': 0.030389141736480964, 'lambda_l2': 0.0010903533168287432, 'num_leaves': 11, 'feature_fraction': 0.6715231741255484, 'bagging_fraction': 0.9850150190863778, 'bagging_freq': 4, 'min_child_samples': 56}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:33:10,692]\u001b[0m Trial 205 finished with value: 0.8249074132195091 and parameters: {'lambda_l1': 0.20057570943591466, 'lambda_l2': 6.479279893654452e-06, 'num_leaves': 9, 'feature_fraction': 0.6522053009433653, 'bagging_fraction': 0.9766728911397398, 'bagging_freq': 4, 'min_child_samples': 58}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-22 20:33:10,974]\u001b[0m Trial 206 finished with value: 0.8260184545853996 and parameters: {'lambda_l1': 0.06465715004150269, 'lambda_l2': 0.0005284502993165734, 'num_leaves': 11, 'feature_fraction': 0.6831882005812279, 'bagging_fraction': 0.9876937628975584, 'bagging_freq': 4, 'min_child_samples': 54}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:33:11,245]\u001b[0m Trial 207 finished with value: 0.8282593685267716 and parameters: {'lambda_l1': 0.31088185809295593, 'lambda_l2': 0.0013600416900314157, 'num_leaves': 12, 'feature_fraction': 0.6588323325368437, 'bagging_fraction': 0.9451329962974294, 'bagging_freq': 4, 'min_child_samples': 51}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:33:11,542]\u001b[0m Trial 208 finished with value: 0.8338773460548616 and parameters: {'lambda_l1': 0.016547771712497095, 'lambda_l2': 3.5887417727481244e-06, 'num_leaves': 27, 'feature_fraction': 0.663093791645384, 'bagging_fraction': 0.9572180411515862, 'bagging_freq': 4, 'min_child_samples': 56}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:33:11,831]\u001b[0m Trial 209 finished with value: 0.8350009415604797 and parameters: {'lambda_l1': 0.08683618024399356, 'lambda_l2': 1.8389605439391397e-05, 'num_leaves': 15, 'feature_fraction': 0.6847885335754653, 'bagging_fraction': 0.9700249614306424, 'bagging_freq': 5, 'min_child_samples': 58}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:33:12,096]\u001b[0m Trial 210 finished with value: 0.8327663046889713 and parameters: {'lambda_l1': 0.1615434617274231, 'lambda_l2': 2.327524738314343e-05, 'num_leaves': 16, 'feature_fraction': 0.684854750091449, 'bagging_fraction': 0.9925748341734213, 'bagging_freq': 5, 'min_child_samples': 59}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:33:12,366]\u001b[0m Trial 211 finished with value: 0.832772581758835 and parameters: {'lambda_l1': 0.07428750177797379, 'lambda_l2': 1.561140351853872e-05, 'num_leaves': 15, 'feature_fraction': 0.7124569485697683, 'bagging_fraction': 0.9696991852707546, 'bagging_freq': 5, 'min_child_samples': 57}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:33:12,634]\u001b[0m Trial 212 finished with value: 0.8305128366078716 and parameters: {'lambda_l1': 0.05036978786839717, 'lambda_l2': 9.2277329953238e-06, 'num_leaves': 15, 'feature_fraction': 0.694795521077232, 'bagging_fraction': 0.976944332379459, 'bagging_freq': 4, 'min_child_samples': 61}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:33:12,917]\u001b[0m Trial 213 finished with value: 0.8327663046889713 and parameters: {'lambda_l1': 0.03521432918279548, 'lambda_l2': 5.180162021303876e-06, 'num_leaves': 15, 'feature_fraction': 0.6724556788522392, 'bagging_fraction': 0.9595522774559774, 'bagging_freq': 4, 'min_child_samples': 54}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:33:13,182]\u001b[0m Trial 214 finished with value: 0.8282719226664994 and parameters: {'lambda_l1': 0.38508380260965436, 'lambda_l2': 0.0018294589716366092, 'num_leaves': 10, 'feature_fraction': 0.6774666220874964, 'bagging_fraction': 0.9491870626355637, 'bagging_freq': 5, 'min_child_samples': 52}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:33:13,466]\u001b[0m Trial 215 finished with value: 0.8361308141359614 and parameters: {'lambda_l1': 0.02184206832437231, 'lambda_l2': 5.176421210850784e-05, 'num_leaves': 13, 'feature_fraction': 0.7057556160506733, 'bagging_fraction': 0.9715425081855453, 'bagging_freq': 4, 'min_child_samples': 49}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:33:13,741]\u001b[0m Trial 216 finished with value: 0.8316364321134895 and parameters: {'lambda_l1': 0.02061580204302799, 'lambda_l2': 4.070860585532761e-05, 'num_leaves': 14, 'feature_fraction': 0.7037163502531255, 'bagging_fraction': 0.9428339661570054, 'bagging_freq': 4, 'min_child_samples': 50}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:33:14,027]\u001b[0m Trial 217 finished with value: 0.8316301550436258 and parameters: {'lambda_l1': 0.13146309607581255, 'lambda_l2': 5.58013723418722e-05, 'num_leaves': 13, 'feature_fraction': 0.7229957451795003, 'bagging_fraction': 0.9991415644519036, 'bagging_freq': 4, 'min_child_samples': 47}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:33:14,290]\u001b[0m Trial 218 finished with value: 0.8294017952419811 and parameters: {'lambda_l1': 0.010193699721343001, 'lambda_l2': 0.0004613780720397152, 'num_leaves': 14, 'feature_fraction': 0.6471225452182615, 'bagging_fraction': 0.977368588066164, 'bagging_freq': 5, 'min_child_samples': 64}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:33:14,575]\u001b[0m Trial 219 finished with value: 0.8305065595380077 and parameters: {'lambda_l1': 0.07725418830400371, 'lambda_l2': 0.0006949386227868508, 'num_leaves': 12, 'feature_fraction': 0.6889808883482373, 'bagging_fraction': 0.9683831763274019, 'bagging_freq': 4, 'min_child_samples': 49}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:33:14,859]\u001b[0m Trial 220 finished with value: 0.8249011361496453 and parameters: {'lambda_l1': 0.02595927524224868, 'lambda_l2': 1.9931852848326624e-05, 'num_leaves': 30, 'feature_fraction': 0.7675190843628517, 'bagging_fraction': 0.9319016715645208, 'bagging_freq': 5, 'min_child_samples': 47}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:33:15,134]\u001b[0m Trial 221 finished with value: 0.8294017952419811 and parameters: {'lambda_l1': 0.04832982149548671, 'lambda_l2': 3.178377744634552e-05, 'num_leaves': 16, 'feature_fraction': 0.7053424990585399, 'bagging_fraction': 0.9880096952419042, 'bagging_freq': 4, 'min_child_samples': 52}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:33:15,398]\u001b[0m Trial 222 finished with value: 0.8327663046889711 and parameters: {'lambda_l1': 0.20573647832184058, 'lambda_l2': 8.653187608790426e-05, 'num_leaves': 10, 'feature_fraction': 0.6637309743250113, 'bagging_fraction': 0.9599439297804464, 'bagging_freq': 4, 'min_child_samples': 55}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:33:15,680]\u001b[0m Trial 223 finished with value: 0.8271483271608814 and parameters: {'lambda_l1': 0.08940914670270175, 'lambda_l2': 2.301761944884682e-06, 'num_leaves': 13, 'feature_fraction': 0.6191596158353199, 'bagging_fraction': 0.9733038165485044, 'bagging_freq': 4, 'min_child_samples': 50}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:33:15,951]\u001b[0m Trial 224 finished with value: 0.8327600276191074 and parameters: {'lambda_l1': 0.03895704540928672, 'lambda_l2': 1.6657566705265105e-05, 'num_leaves': 15, 'feature_fraction': 0.6807092130034055, 'bagging_fraction': 0.9848767990349919, 'bagging_freq': 4, 'min_child_samples': 59}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:33:16,248]\u001b[0m Trial 225 finished with value: 0.8305128366078713 and parameters: {'lambda_l1': 0.00039022948266366893, 'lambda_l2': 4.76904193897119e-05, 'num_leaves': 26, 'feature_fraction': 0.6317586542355493, 'bagging_fraction': 0.9513150173267871, 'bagging_freq': 4, 'min_child_samples': 45}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:33:16,520]\u001b[0m Trial 226 finished with value: 0.8305191136777352 and parameters: {'lambda_l1': 0.018270622309609283, 'lambda_l2': 7.732128745389085e-06, 'num_leaves': 28, 'feature_fraction': 0.9088794941203371, 'bagging_fraction': 0.9641797818736095, 'bagging_freq': 4, 'min_child_samples': 57}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:33:16,784]\u001b[0m Trial 227 finished with value: 0.8316427091833531 and parameters: {'lambda_l1': 0.4528227215434554, 'lambda_l2': 0.00109293811057382, 'num_leaves': 11, 'feature_fraction': 0.6911195506492755, 'bagging_fraction': 0.9398036208037361, 'bagging_freq': 5, 'min_child_samples': 53}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:33:17,032]\u001b[0m Trial 228 finished with value: 0.8192894356914191 and parameters: {'lambda_l1': 7.2371534867229265e-06, 'lambda_l2': 0.0003361918359889578, 'num_leaves': 11, 'feature_fraction': 0.9266864492984757, 'bagging_fraction': 0.7295297784631476, 'bagging_freq': 4, 'min_child_samples': 50}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-22 20:33:17,321]\u001b[0m Trial 229 finished with value: 0.8350072186303434 and parameters: {'lambda_l1': 0.2733063160217703, 'lambda_l2': 0.0032611009957854947, 'num_leaves': 27, 'feature_fraction': 0.754778875837993, 'bagging_fraction': 0.989528897201257, 'bagging_freq': 5, 'min_child_samples': 48}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:33:17,604]\u001b[0m Trial 230 finished with value: 0.8316427091833531 and parameters: {'lambda_l1': 0.28653263580316085, 'lambda_l2': 0.003155863386592761, 'num_leaves': 27, 'feature_fraction': 0.7986080232967202, 'bagging_fraction': 0.973280301352641, 'bagging_freq': 5, 'min_child_samples': 48}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:33:17,887]\u001b[0m Trial 231 finished with value: 0.8316364321134893 and parameters: {'lambda_l1': 0.20471229009701405, 'lambda_l2': 0.0022423771306299815, 'num_leaves': 26, 'feature_fraction': 0.7467206740343227, 'bagging_fraction': 0.9864631850625143, 'bagging_freq': 5, 'min_child_samples': 51}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:33:18,183]\u001b[0m Trial 232 finished with value: 0.8271483271608814 and parameters: {'lambda_l1': 7.520180683167833e-05, 'lambda_l2': 0.01621837053167579, 'num_leaves': 28, 'feature_fraction': 0.7147966225662766, 'bagging_fraction': 0.9995035423352431, 'bagging_freq': 5, 'min_child_samples': 44}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:33:18,472]\u001b[0m Trial 233 finished with value: 0.8327600276191074 and parameters: {'lambda_l1': 0.10215284149631355, 'lambda_l2': 0.007302071995787376, 'num_leaves': 29, 'feature_fraction': 0.7025740355546768, 'bagging_fraction': 0.9821083469430207, 'bagging_freq': 5, 'min_child_samples': 48}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:33:18,734]\u001b[0m Trial 234 finished with value: 0.8294017952419811 and parameters: {'lambda_l1': 0.7379366660129568, 'lambda_l2': 1.3107830559423009e-05, 'num_leaves': 27, 'feature_fraction': 0.7301240109995167, 'bagging_fraction': 0.958346741720756, 'bagging_freq': 5, 'min_child_samples': 55}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:33:19,012]\u001b[0m Trial 235 finished with value: 0.8294017952419811 and parameters: {'lambda_l1': 0.0272084976170564, 'lambda_l2': 0.004762952514581099, 'num_leaves': 21, 'feature_fraction': 0.7791644739284467, 'bagging_fraction': 0.9699519301578394, 'bagging_freq': 5, 'min_child_samples': 53}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:33:19,306]\u001b[0m Trial 236 finished with value: 0.824913690289373 and parameters: {'lambda_l1': 0.00796924485586818, 'lambda_l2': 0.0017894003313914453, 'num_leaves': 17, 'feature_fraction': 0.8872976290404333, 'bagging_fraction': 0.9904637635072004, 'bagging_freq': 5, 'min_child_samples': 46}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:33:19,586]\u001b[0m Trial 237 finished with value: 0.8271483271608814 and parameters: {'lambda_l1': 0.3865285560733026, 'lambda_l2': 0.0008338929284787533, 'num_leaves': 15, 'feature_fraction': 0.9145974274037751, 'bagging_fraction': 0.9543546940470927, 'bagging_freq': 4, 'min_child_samples': 50}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:33:19,861]\u001b[0m Trial 238 finished with value: 0.8294080723118448 and parameters: {'lambda_l1': 0.15158170808425037, 'lambda_l2': 0.0033980032316601617, 'num_leaves': 10, 'feature_fraction': 0.8143677961857356, 'bagging_fraction': 0.9774734831750441, 'bagging_freq': 4, 'min_child_samples': 58}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:33:20,124]\u001b[0m Trial 239 finished with value: 0.8249011361496453 and parameters: {'lambda_l1': 0.0008125342164749824, 'lambda_l2': 4.437639526784414e-06, 'num_leaves': 22, 'feature_fraction': 0.6719518619727191, 'bagging_fraction': 0.9240608185507303, 'bagging_freq': 5, 'min_child_samples': 61}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:33:20,401]\u001b[0m Trial 240 finished with value: 0.8271608813006089 and parameters: {'lambda_l1': 0.06605517167687211, 'lambda_l2': 2.6199221289284305e-05, 'num_leaves': 27, 'feature_fraction': 0.7605565503105377, 'bagging_fraction': 0.9620794104411434, 'bagging_freq': 7, 'min_child_samples': 52}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:33:20,677]\u001b[0m Trial 241 finished with value: 0.8316364321134895 and parameters: {'lambda_l1': 0.09734458444727408, 'lambda_l2': 0.0013009074730557621, 'num_leaves': 17, 'feature_fraction': 0.6975424862408013, 'bagging_fraction': 0.9684885612791161, 'bagging_freq': 4, 'min_child_samples': 52}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:33:20,955]\u001b[0m Trial 242 finished with value: 0.8293892411022533 and parameters: {'lambda_l1': 0.13096949751285933, 'lambda_l2': 0.0012049752628536922, 'num_leaves': 18, 'feature_fraction': 0.693114451690096, 'bagging_fraction': 0.9462634376092591, 'bagging_freq': 4, 'min_child_samples': 54}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:33:21,238]\u001b[0m Trial 243 finished with value: 0.8327600276191074 and parameters: {'lambda_l1': 0.2645374422546907, 'lambda_l2': 0.0007235375138936632, 'num_leaves': 16, 'feature_fraction': 0.6807017430037117, 'bagging_fraction': 0.9795679725630044, 'bagging_freq': 4, 'min_child_samples': 49}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:33:21,511]\u001b[0m Trial 244 finished with value: 0.8350009415604795 and parameters: {'lambda_l1': 0.04162616640237966, 'lambda_l2': 0.002531307869354052, 'num_leaves': 17, 'feature_fraction': 0.7149845245907417, 'bagging_fraction': 0.966626473041031, 'bagging_freq': 4, 'min_child_samples': 56}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:33:21,782]\u001b[0m Trial 245 finished with value: 0.8282719226664993 and parameters: {'lambda_l1': 0.04468195106633933, 'lambda_l2': 8.234960972377858e-05, 'num_leaves': 18, 'feature_fraction': 0.7193475560119071, 'bagging_fraction': 0.9916765290464985, 'bagging_freq': 4, 'min_child_samples': 56}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:33:22,050]\u001b[0m Trial 246 finished with value: 0.8282656455966355 and parameters: {'lambda_l1': 0.022667548691250632, 'lambda_l2': 0.002247736153670459, 'num_leaves': 12, 'feature_fraction': 0.7094776565445066, 'bagging_fraction': 0.9324894348725641, 'bagging_freq': 4, 'min_child_samples': 59}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:33:22,326]\u001b[0m Trial 247 finished with value: 0.8271608813006088 and parameters: {'lambda_l1': 0.03792108531413598, 'lambda_l2': 0.002978770084515126, 'num_leaves': 17, 'feature_fraction': 0.4320550493349507, 'bagging_fraction': 0.9530024780890834, 'bagging_freq': 3, 'min_child_samples': 56}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:33:22,619]\u001b[0m Trial 248 finished with value: 0.8294017952419811 and parameters: {'lambda_l1': 0.011838949846014303, 'lambda_l2': 9.893711471711046e-06, 'num_leaves': 19, 'feature_fraction': 0.7308527874434009, 'bagging_fraction': 0.9687246450487476, 'bagging_freq': 4, 'min_child_samples': 47}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 20:33:22,901]\u001b[0m Trial 249 finished with value: 0.8293829640323898 and parameters: {'lambda_l1': 0.0594884314713258, 'lambda_l2': 5.55763290454946e-05, 'num_leaves': 28, 'feature_fraction': 0.9018566987483643, 'bagging_fraction': 0.9989893701359785, 'bagging_freq': 3, 'min_child_samples': 51}. Best is trial 21 with value: 0.8383654510074697.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "def objective(trial):\n",
    "    \n",
    "    param = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'binary_logloss',\n",
    "        'verbosity': -1,\n",
    "        'boosting_type': 'gbdt',\n",
    "        'lambda_l1': trial.suggest_float('lambda_l1', 1e-8, 10.0, log=True),\n",
    "        'lambda_l2': trial.suggest_float('lambda_l2', 1e-8, 10.0, log=True),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 2, 32),\n",
    "        'feature_fraction': trial.suggest_float('feature_fraction', 0.4, 1.0),\n",
    "        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.4, 1.0),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "    }\n",
    "    \n",
    "    kf = KFold(5, shuffle = True, random_state = 0)\n",
    "    kf.split(train)\n",
    "    \n",
    "    accuracy_scores = []\n",
    "    \n",
    "    for train_ix, test_ix in kf.split(train):\n",
    "        dtrain = lgb.Dataset(train.loc[train_ix, features], label = train.loc[train_ix, 'Survived'])\n",
    "        \n",
    "        gbm = lgb.train(param, dtrain)\n",
    "        preds = np.rint(gbm.predict(train.loc[test_idx, features]))\n",
    "        \n",
    "        accuracy_scores.append(metrics.accuracy_score(train.loc[test_idx, 'Survived'], preds))\n",
    "        \n",
    "    return np.mean(accuracy_scores)\n",
    "    \n",
    "\n",
    "# # 3. Create a study object and optimize the objective function.\n",
    "# study = optuna.create_study(direction='maximize')\n",
    "# study.optimize(objective, n_trials=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "markers",
         "name": "Objective Value",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249
         ],
         "y": [
          0.7991400414286611,
          0.8170296905404557,
          0.8114242671520934,
          0.8092147385600402,
          0.8148264390182662,
          0.8136965664427844,
          0.8159249262444291,
          0.8327663046889713,
          0.8159312033142928,
          0.8293955181721172,
          0.8125478626577113,
          0.8204444165463561,
          0.8293955181721172,
          0.8025045508756513,
          0.8181721172556651,
          0.8226664992781372,
          0.8215303496327915,
          0.8226476680685456,
          0.8293829640323895,
          0.8204193082669009,
          0.8361370912058252,
          0.8383654510074697,
          0.8361245370660975,
          0.8305065595380077,
          0.8237838177138912,
          0.8293955181721173,
          0.8215491808423827,
          0.833864791915134,
          0.8316427091833531,
          0.8092461239093591,
          0.8181595631159375,
          0.8316427091833531,
          0.8282593685267716,
          0.8181658401858012,
          0.8237775406440273,
          0.8294017952419811,
          0.8159186491745654,
          0.8350072186303434,
          0.8215366267026551,
          0.8293892411022536,
          0.819295712761283,
          0.8204193082669011,
          0.8249199673592367,
          0.8238026489234824,
          0.8282593685267716,
          0.8316301550436258,
          0.8271608813006089,
          0.821542903772519,
          0.8159123721047015,
          0.7879166405122089,
          0.8338836231247255,
          0.8305128366078716,
          0.8271483271608814,
          0.8248885820099178,
          0.8181721172556651,
          0.8271357730211537,
          0.8260561170045821,
          0.8293955181721172,
          0.8338961772644529,
          0.8293955181721172,
          0.8226664992781372,
          0.8282781997363632,
          0.8148389931579938,
          0.8204255853367648,
          0.811493314920595,
          0.8338899001945892,
          0.8338899001945892,
          0.829408072311845,
          0.8237775406440274,
          0.832772581758835,
          0.8215303496327915,
          0.8282781997363632,
          0.8316364321134895,
          0.8372481325717155,
          0.8316427091833531,
          0.8282719226664993,
          0.813684012303057,
          0.8271420500910175,
          0.8237900947837549,
          0.8148076078086749,
          0.8316427091833534,
          0.8249011361496453,
          0.8237775406440274,
          0.8293892411022534,
          0.8327537505492437,
          0.8271420500910175,
          0.8248948590797814,
          0.8282781997363632,
          0.8294017952419811,
          0.8350134957002071,
          0.828278199736363,
          0.8305128366078716,
          0.8271608813006088,
          0.8305191136777352,
          0.8215491808423827,
          0.8316489862532169,
          0.8271608813006089,
          0.8193082669010107,
          0.8282719226664993,
          0.8316364321134895,
          0.8316364321134895,
          0.8305128366078713,
          0.8226413909986817,
          0.8181972255351202,
          0.8271357730211537,
          0.8215303496327915,
          0.8215303496327915,
          0.8305191136777352,
          0.8316427091833531,
          0.8260372857949909,
          0.8316364321134895,
          0.8316427091833531,
          0.8283033080158184,
          0.812560416797439,
          0.8260498399347185,
          0.826037285794991,
          0.8338899001945892,
          0.8237838177138912,
          0.8226727763480008,
          0.8305002824681438,
          0.8350009415604795,
          0.8237775406440273,
          0.8260310087251271,
          0.8294080723118448,
          0.8305191136777352,
          0.8271420500910175,
          0.8316364321134895,
          0.8260184545853996,
          0.8181595631159375,
          0.8282719226664993,
          0.8293955181721172,
          0.8271671583704727,
          0.8260247316552635,
          0.8226476680685456,
          0.8305191136777352,
          0.8249199673592369,
          0.8305128366078713,
          0.8237775406440274,
          0.8305128366078713,
          0.8293892411022536,
          0.8226476680685456,
          0.827154604230745,
          0.8282719226664993,
          0.8338961772644529,
          0.830525390747599,
          0.8271357730211537,
          0.8282719226664993,
          0.8148076078086749,
          0.819295712761283,
          0.8249074132195092,
          0.8159186491745652,
          0.8316552633230808,
          0.826037285794991,
          0.8305191136777352,
          0.8305128366078713,
          0.8327663046889713,
          0.829408072311845,
          0.8305128366078713,
          0.8305128366078716,
          0.836137091205825,
          0.8237775406440273,
          0.8316489862532169,
          0.8271671583704727,
          0.8294080723118448,
          0.8293955181721172,
          0.8237775406440273,
          0.8372481325717155,
          0.831648986253217,
          0.830525390747599,
          0.8237775406440274,
          0.8237775406440274,
          0.8293955181721173,
          0.8350009415604795,
          0.8327663046889711,
          0.8249074132195091,
          0.8271483271608814,
          0.8327663046889713,
          0.8282907538760906,
          0.830525390747599,
          0.8327600276191076,
          0.8361308141359614,
          0.8293892411022534,
          0.8293955181721173,
          0.8137028435126483,
          0.8293892411022534,
          0.8372606867114432,
          0.8226790534178645,
          0.8327663046889713,
          0.8260247316552632,
          0.8316427091833531,
          0.8271483271608812,
          0.8350134957002073,
          0.8327600276191074,
          0.827154604230745,
          0.8260310087251271,
          0.8372544096415794,
          0.8305065595380077,
          0.8305191136777352,
          0.8271608813006088,
          0.824913690289373,
          0.8350072186303434,
          0.8338836231247255,
          0.8305128366078713,
          0.8338899001945892,
          0.8249011361496453,
          0.8249074132195091,
          0.8260184545853996,
          0.8282593685267716,
          0.8338773460548616,
          0.8350009415604797,
          0.8327663046889713,
          0.832772581758835,
          0.8305128366078716,
          0.8327663046889713,
          0.8282719226664994,
          0.8361308141359614,
          0.8316364321134895,
          0.8316301550436258,
          0.8294017952419811,
          0.8305065595380077,
          0.8249011361496453,
          0.8294017952419811,
          0.8327663046889711,
          0.8271483271608814,
          0.8327600276191074,
          0.8305128366078713,
          0.8305191136777352,
          0.8316427091833531,
          0.8192894356914191,
          0.8350072186303434,
          0.8316427091833531,
          0.8316364321134893,
          0.8271483271608814,
          0.8327600276191074,
          0.8294017952419811,
          0.8294017952419811,
          0.824913690289373,
          0.8271483271608814,
          0.8294080723118448,
          0.8249011361496453,
          0.8271608813006089,
          0.8316364321134895,
          0.8293892411022533,
          0.8327600276191074,
          0.8350009415604795,
          0.8282719226664993,
          0.8282656455966355,
          0.8271608813006088,
          0.8294017952419811,
          0.8293829640323898
         ]
        },
        {
         "name": "Best Value",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249
         ],
         "y": [
          0.7991400414286611,
          0.8170296905404557,
          0.8170296905404557,
          0.8170296905404557,
          0.8170296905404557,
          0.8170296905404557,
          0.8170296905404557,
          0.8327663046889713,
          0.8327663046889713,
          0.8327663046889713,
          0.8327663046889713,
          0.8327663046889713,
          0.8327663046889713,
          0.8327663046889713,
          0.8327663046889713,
          0.8327663046889713,
          0.8327663046889713,
          0.8327663046889713,
          0.8327663046889713,
          0.8327663046889713,
          0.8361370912058252,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697,
          0.8383654510074697
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Optimization History Plot"
        },
        "xaxis": {
         "title": {
          "text": "#Trials"
         }
        },
        "yaxis": {
         "title": {
          "text": "Objective Value"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"d645f24c-991c-4d5e-b461-5f9e2b3793d7\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"d645f24c-991c-4d5e-b461-5f9e2b3793d7\")) {                    Plotly.newPlot(                        \"d645f24c-991c-4d5e-b461-5f9e2b3793d7\",                        [{\"mode\":\"markers\",\"name\":\"Objective Value\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249],\"y\":[0.7991400414286611,0.8170296905404557,0.8114242671520934,0.8092147385600402,0.8148264390182662,0.8136965664427844,0.8159249262444291,0.8327663046889713,0.8159312033142928,0.8293955181721172,0.8125478626577113,0.8204444165463561,0.8293955181721172,0.8025045508756513,0.8181721172556651,0.8226664992781372,0.8215303496327915,0.8226476680685456,0.8293829640323895,0.8204193082669009,0.8361370912058252,0.8383654510074697,0.8361245370660975,0.8305065595380077,0.8237838177138912,0.8293955181721173,0.8215491808423827,0.833864791915134,0.8316427091833531,0.8092461239093591,0.8181595631159375,0.8316427091833531,0.8282593685267716,0.8181658401858012,0.8237775406440273,0.8294017952419811,0.8159186491745654,0.8350072186303434,0.8215366267026551,0.8293892411022536,0.819295712761283,0.8204193082669011,0.8249199673592367,0.8238026489234824,0.8282593685267716,0.8316301550436258,0.8271608813006089,0.821542903772519,0.8159123721047015,0.7879166405122089,0.8338836231247255,0.8305128366078716,0.8271483271608814,0.8248885820099178,0.8181721172556651,0.8271357730211537,0.8260561170045821,0.8293955181721172,0.8338961772644529,0.8293955181721172,0.8226664992781372,0.8282781997363632,0.8148389931579938,0.8204255853367648,0.811493314920595,0.8338899001945892,0.8338899001945892,0.829408072311845,0.8237775406440274,0.832772581758835,0.8215303496327915,0.8282781997363632,0.8316364321134895,0.8372481325717155,0.8316427091833531,0.8282719226664993,0.813684012303057,0.8271420500910175,0.8237900947837549,0.8148076078086749,0.8316427091833534,0.8249011361496453,0.8237775406440274,0.8293892411022534,0.8327537505492437,0.8271420500910175,0.8248948590797814,0.8282781997363632,0.8294017952419811,0.8350134957002071,0.828278199736363,0.8305128366078716,0.8271608813006088,0.8305191136777352,0.8215491808423827,0.8316489862532169,0.8271608813006089,0.8193082669010107,0.8282719226664993,0.8316364321134895,0.8316364321134895,0.8305128366078713,0.8226413909986817,0.8181972255351202,0.8271357730211537,0.8215303496327915,0.8215303496327915,0.8305191136777352,0.8316427091833531,0.8260372857949909,0.8316364321134895,0.8316427091833531,0.8283033080158184,0.812560416797439,0.8260498399347185,0.826037285794991,0.8338899001945892,0.8237838177138912,0.8226727763480008,0.8305002824681438,0.8350009415604795,0.8237775406440273,0.8260310087251271,0.8294080723118448,0.8305191136777352,0.8271420500910175,0.8316364321134895,0.8260184545853996,0.8181595631159375,0.8282719226664993,0.8293955181721172,0.8271671583704727,0.8260247316552635,0.8226476680685456,0.8305191136777352,0.8249199673592369,0.8305128366078713,0.8237775406440274,0.8305128366078713,0.8293892411022536,0.8226476680685456,0.827154604230745,0.8282719226664993,0.8338961772644529,0.830525390747599,0.8271357730211537,0.8282719226664993,0.8148076078086749,0.819295712761283,0.8249074132195092,0.8159186491745652,0.8316552633230808,0.826037285794991,0.8305191136777352,0.8305128366078713,0.8327663046889713,0.829408072311845,0.8305128366078713,0.8305128366078716,0.836137091205825,0.8237775406440273,0.8316489862532169,0.8271671583704727,0.8294080723118448,0.8293955181721172,0.8237775406440273,0.8372481325717155,0.831648986253217,0.830525390747599,0.8237775406440274,0.8237775406440274,0.8293955181721173,0.8350009415604795,0.8327663046889711,0.8249074132195091,0.8271483271608814,0.8327663046889713,0.8282907538760906,0.830525390747599,0.8327600276191076,0.8361308141359614,0.8293892411022534,0.8293955181721173,0.8137028435126483,0.8293892411022534,0.8372606867114432,0.8226790534178645,0.8327663046889713,0.8260247316552632,0.8316427091833531,0.8271483271608812,0.8350134957002073,0.8327600276191074,0.827154604230745,0.8260310087251271,0.8372544096415794,0.8305065595380077,0.8305191136777352,0.8271608813006088,0.824913690289373,0.8350072186303434,0.8338836231247255,0.8305128366078713,0.8338899001945892,0.8249011361496453,0.8249074132195091,0.8260184545853996,0.8282593685267716,0.8338773460548616,0.8350009415604797,0.8327663046889713,0.832772581758835,0.8305128366078716,0.8327663046889713,0.8282719226664994,0.8361308141359614,0.8316364321134895,0.8316301550436258,0.8294017952419811,0.8305065595380077,0.8249011361496453,0.8294017952419811,0.8327663046889711,0.8271483271608814,0.8327600276191074,0.8305128366078713,0.8305191136777352,0.8316427091833531,0.8192894356914191,0.8350072186303434,0.8316427091833531,0.8316364321134893,0.8271483271608814,0.8327600276191074,0.8294017952419811,0.8294017952419811,0.824913690289373,0.8271483271608814,0.8294080723118448,0.8249011361496453,0.8271608813006089,0.8316364321134895,0.8293892411022533,0.8327600276191074,0.8350009415604795,0.8282719226664993,0.8282656455966355,0.8271608813006088,0.8294017952419811,0.8293829640323898],\"type\":\"scatter\"},{\"name\":\"Best Value\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249],\"y\":[0.7991400414286611,0.8170296905404557,0.8170296905404557,0.8170296905404557,0.8170296905404557,0.8170296905404557,0.8170296905404557,0.8327663046889713,0.8327663046889713,0.8327663046889713,0.8327663046889713,0.8327663046889713,0.8327663046889713,0.8327663046889713,0.8327663046889713,0.8327663046889713,0.8327663046889713,0.8327663046889713,0.8327663046889713,0.8327663046889713,0.8361370912058252,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697,0.8383654510074697],\"type\":\"scatter\"}],                        {\"title\":{\"text\":\"Optimization History Plot\"},\"xaxis\":{\"title\":{\"text\":\"#Trials\"}},\"yaxis\":{\"title\":{\"text\":\"Objective Value\"}},\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('d645f24c-991c-4d5e-b461-5f9e2b3793d7');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "dimensions": [
          {
           "label": "Objective Value",
           "range": [
            0.7879166405122089,
            0.8383654510074697
           ],
           "values": [
            0.7991400414286611,
            0.8170296905404557,
            0.8114242671520934,
            0.8092147385600402,
            0.8148264390182662,
            0.8136965664427844,
            0.8159249262444291,
            0.8327663046889713,
            0.8159312033142928,
            0.8293955181721172,
            0.8125478626577113,
            0.8204444165463561,
            0.8293955181721172,
            0.8025045508756513,
            0.8181721172556651,
            0.8226664992781372,
            0.8215303496327915,
            0.8226476680685456,
            0.8293829640323895,
            0.8204193082669009,
            0.8361370912058252,
            0.8383654510074697,
            0.8361245370660975,
            0.8305065595380077,
            0.8237838177138912,
            0.8293955181721173,
            0.8215491808423827,
            0.833864791915134,
            0.8316427091833531,
            0.8092461239093591,
            0.8181595631159375,
            0.8316427091833531,
            0.8282593685267716,
            0.8181658401858012,
            0.8237775406440273,
            0.8294017952419811,
            0.8159186491745654,
            0.8350072186303434,
            0.8215366267026551,
            0.8293892411022536,
            0.819295712761283,
            0.8204193082669011,
            0.8249199673592367,
            0.8238026489234824,
            0.8282593685267716,
            0.8316301550436258,
            0.8271608813006089,
            0.821542903772519,
            0.8159123721047015,
            0.7879166405122089,
            0.8338836231247255,
            0.8305128366078716,
            0.8271483271608814,
            0.8248885820099178,
            0.8181721172556651,
            0.8271357730211537,
            0.8260561170045821,
            0.8293955181721172,
            0.8338961772644529,
            0.8293955181721172,
            0.8226664992781372,
            0.8282781997363632,
            0.8148389931579938,
            0.8204255853367648,
            0.811493314920595,
            0.8338899001945892,
            0.8338899001945892,
            0.829408072311845,
            0.8237775406440274,
            0.832772581758835,
            0.8215303496327915,
            0.8282781997363632,
            0.8316364321134895,
            0.8372481325717155,
            0.8316427091833531,
            0.8282719226664993,
            0.813684012303057,
            0.8271420500910175,
            0.8237900947837549,
            0.8148076078086749,
            0.8316427091833534,
            0.8249011361496453,
            0.8237775406440274,
            0.8293892411022534,
            0.8327537505492437,
            0.8271420500910175,
            0.8248948590797814,
            0.8282781997363632,
            0.8294017952419811,
            0.8350134957002071,
            0.828278199736363,
            0.8305128366078716,
            0.8271608813006088,
            0.8305191136777352,
            0.8215491808423827,
            0.8316489862532169,
            0.8271608813006089,
            0.8193082669010107,
            0.8282719226664993,
            0.8316364321134895,
            0.8316364321134895,
            0.8305128366078713,
            0.8226413909986817,
            0.8181972255351202,
            0.8271357730211537,
            0.8215303496327915,
            0.8215303496327915,
            0.8305191136777352,
            0.8316427091833531,
            0.8260372857949909,
            0.8316364321134895,
            0.8316427091833531,
            0.8283033080158184,
            0.812560416797439,
            0.8260498399347185,
            0.826037285794991,
            0.8338899001945892,
            0.8237838177138912,
            0.8226727763480008,
            0.8305002824681438,
            0.8350009415604795,
            0.8237775406440273,
            0.8260310087251271,
            0.8294080723118448,
            0.8305191136777352,
            0.8271420500910175,
            0.8316364321134895,
            0.8260184545853996,
            0.8181595631159375,
            0.8282719226664993,
            0.8293955181721172,
            0.8271671583704727,
            0.8260247316552635,
            0.8226476680685456,
            0.8305191136777352,
            0.8249199673592369,
            0.8305128366078713,
            0.8237775406440274,
            0.8305128366078713,
            0.8293892411022536,
            0.8226476680685456,
            0.827154604230745,
            0.8282719226664993,
            0.8338961772644529,
            0.830525390747599,
            0.8271357730211537,
            0.8282719226664993,
            0.8148076078086749,
            0.819295712761283,
            0.8249074132195092,
            0.8159186491745652,
            0.8316552633230808,
            0.826037285794991,
            0.8305191136777352,
            0.8305128366078713,
            0.8327663046889713,
            0.829408072311845,
            0.8305128366078713,
            0.8305128366078716,
            0.836137091205825,
            0.8237775406440273,
            0.8316489862532169,
            0.8271671583704727,
            0.8294080723118448,
            0.8293955181721172,
            0.8237775406440273,
            0.8372481325717155,
            0.831648986253217,
            0.830525390747599,
            0.8237775406440274,
            0.8237775406440274,
            0.8293955181721173,
            0.8350009415604795,
            0.8327663046889711,
            0.8249074132195091,
            0.8271483271608814,
            0.8327663046889713,
            0.8282907538760906,
            0.830525390747599,
            0.8327600276191076,
            0.8361308141359614,
            0.8293892411022534,
            0.8293955181721173,
            0.8137028435126483,
            0.8293892411022534,
            0.8372606867114432,
            0.8226790534178645,
            0.8327663046889713,
            0.8260247316552632,
            0.8316427091833531,
            0.8271483271608812,
            0.8350134957002073,
            0.8327600276191074,
            0.827154604230745,
            0.8260310087251271,
            0.8372544096415794,
            0.8305065595380077,
            0.8305191136777352,
            0.8271608813006088,
            0.824913690289373,
            0.8350072186303434,
            0.8338836231247255,
            0.8305128366078713,
            0.8338899001945892,
            0.8249011361496453,
            0.8249074132195091,
            0.8260184545853996,
            0.8282593685267716,
            0.8338773460548616,
            0.8350009415604797,
            0.8327663046889713,
            0.832772581758835,
            0.8305128366078716,
            0.8327663046889713,
            0.8282719226664994,
            0.8361308141359614,
            0.8316364321134895,
            0.8316301550436258,
            0.8294017952419811,
            0.8305065595380077,
            0.8249011361496453,
            0.8294017952419811,
            0.8327663046889711,
            0.8271483271608814,
            0.8327600276191074,
            0.8305128366078713,
            0.8305191136777352,
            0.8316427091833531,
            0.8192894356914191,
            0.8350072186303434,
            0.8316427091833531,
            0.8316364321134893,
            0.8271483271608814,
            0.8327600276191074,
            0.8294017952419811,
            0.8294017952419811,
            0.824913690289373,
            0.8271483271608814,
            0.8294080723118448,
            0.8249011361496453,
            0.8271608813006089,
            0.8316364321134895,
            0.8293892411022533,
            0.8327600276191074,
            0.8350009415604795,
            0.8282719226664993,
            0.8282656455966355,
            0.8271608813006088,
            0.8294017952419811,
            0.8293829640323898
           ]
          },
          {
           "label": "bagging_fraction",
           "range": [
            0.401965225477051,
            0.9999636511943943
           ],
           "values": [
            0.5115606779832345,
            0.9035854363156637,
            0.586463520201019,
            0.6848872997430882,
            0.5144677594292105,
            0.9242291527962854,
            0.95204636215645,
            0.8412976001533627,
            0.8387659433426398,
            0.7132396751578023,
            0.7680955484090313,
            0.714464776070218,
            0.8049382113407397,
            0.6604712994864956,
            0.42998232879216614,
            0.8374531633989446,
            0.6224202124070706,
            0.8014506402835758,
            0.8675505893469363,
            0.7279463079795199,
            0.991429544171526,
            0.9844533490969807,
            0.9823302217824006,
            0.9647155759002808,
            0.9604131326250278,
            0.9922348476278575,
            0.9963111783764703,
            0.8954265349365642,
            0.9223334853626186,
            0.9927546376132949,
            0.8771251265284395,
            0.9076414739475414,
            0.9430928133152174,
            0.8861178139899989,
            0.9994055939596402,
            0.9594922472155742,
            0.9044868254482515,
            0.933055326781762,
            0.5580319120571919,
            0.9364061339420611,
            0.9645243829357294,
            0.9252343583038842,
            0.862097460539901,
            0.970433658317487,
            0.895347419553127,
            0.9353724702785845,
            0.7655229308337063,
            0.8456982014729227,
            0.8181716117560768,
            0.401965225477051,
            0.9728890582469202,
            0.9771276912967326,
            0.943422925166358,
            0.9168418946620064,
            0.9758541978136482,
            0.9035221806694483,
            0.9496190419196208,
            0.9813849178578143,
            0.8608126428126366,
            0.9997307118581531,
            0.7734254410595303,
            0.8639522191533947,
            0.9248270656936931,
            0.6661634702593455,
            0.8880724886393485,
            0.9543143016475211,
            0.9484389341392316,
            0.9451338275779183,
            0.9530282046847264,
            0.9221408818808012,
            0.9833622353471669,
            0.96389149993437,
            0.9806843686858877,
            0.9995244893393281,
            0.9352858352400958,
            0.999547618526205,
            0.4726012813312743,
            0.9564942967620326,
            0.9097048395255692,
            0.5953455461671947,
            0.8767461914134154,
            0.9664910881376431,
            0.9822584052320559,
            0.9372454193589559,
            0.987317407810519,
            0.962300663234522,
            0.971738406182177,
            0.9333178101753618,
            0.9907529677425011,
            0.950905373314695,
            0.851672348694522,
            0.9559185973390645,
            0.9151544655549616,
            0.944231428821731,
            0.8235402570707996,
            0.9724440941749355,
            0.8938432910313799,
            0.9996025864558219,
            0.9473818682492193,
            0.9256491224065487,
            0.9722797707812918,
            0.9012663784533421,
            0.954688270185467,
            0.8828622365428727,
            0.9836662748118168,
            0.9294775378601928,
            0.9191926415725702,
            0.9623308384609592,
            0.9890472342656226,
            0.9109110610157991,
            0.9455598583548168,
            0.9734683792864095,
            0.9240851469455091,
            0.7303411753693254,
            0.8975084824279764,
            0.8692541414343299,
            0.955184610086501,
            0.9526508547919396,
            0.9895130083734557,
            0.9683716089474699,
            0.9393023695965079,
            0.9385322042238998,
            0.9570139281701294,
            0.9802786377894558,
            0.9999636511943943,
            0.938587624675898,
            0.970545620467604,
            0.9080742490540691,
            0.5322455722848536,
            0.9502307429420435,
            0.932271966016139,
            0.9162667837272143,
            0.9619128901942636,
            0.982757774982424,
            0.9273976735847572,
            0.8910391389882653,
            0.9457196248013503,
            0.9909543629928306,
            0.9630387641829684,
            0.9773495069450313,
            0.854993317460407,
            0.8360961131375221,
            0.8744992155888697,
            0.9176344442396581,
            0.9176146256842153,
            0.8991551801733263,
            0.9353051976105876,
            0.952405082992364,
            0.6254290016146619,
            0.9238374740819135,
            0.9730447505907351,
            0.9031676345855512,
            0.8846920312763566,
            0.8089394509821175,
            0.9424187096853462,
            0.9882612081256744,
            0.7945444304370258,
            0.9617138166435377,
            0.9996062653837385,
            0.9092282983973848,
            0.9087818666412456,
            0.8345111561561149,
            0.8665102264359231,
            0.9293834389742592,
            0.9848165559215974,
            0.9551417061921584,
            0.9751150721105847,
            0.9682392967698904,
            0.9366579551861546,
            0.9520638797905584,
            0.9784629022012583,
            0.9895409752835023,
            0.9667750915922655,
            0.9646162822088644,
            0.9176742409264921,
            0.9457053168719673,
            0.9756201338387883,
            0.961208857737644,
            0.9379528037100416,
            0.9996932860873987,
            0.9722329180862063,
            0.9712381816869154,
            0.9516942590505904,
            0.9792801936172691,
            0.9275668995157118,
            0.9874678077120393,
            0.9858447628844617,
            0.9668824389970319,
            0.9916449739473728,
            0.978175877182217,
            0.9593832078343243,
            0.9447332717964526,
            0.9535627219515876,
            0.6908358496105276,
            0.9382899073991662,
            0.9705884841739005,
            0.9701291443331537,
            0.9824139888015821,
            0.9988412897049158,
            0.9469744976659645,
            0.9667101857809698,
            0.9676385536050676,
            0.9608305892207868,
            0.9850274510319682,
            0.9850150190863778,
            0.9766728911397398,
            0.9876937628975584,
            0.9451329962974294,
            0.9572180411515862,
            0.9700249614306424,
            0.9925748341734213,
            0.9696991852707546,
            0.976944332379459,
            0.9595522774559774,
            0.9491870626355637,
            0.9715425081855453,
            0.9428339661570054,
            0.9991415644519036,
            0.977368588066164,
            0.9683831763274019,
            0.9319016715645208,
            0.9880096952419042,
            0.9599439297804464,
            0.9733038165485044,
            0.9848767990349919,
            0.9513150173267871,
            0.9641797818736095,
            0.9398036208037361,
            0.7295297784631476,
            0.989528897201257,
            0.973280301352641,
            0.9864631850625143,
            0.9995035423352431,
            0.9821083469430207,
            0.958346741720756,
            0.9699519301578394,
            0.9904637635072004,
            0.9543546940470927,
            0.9774734831750441,
            0.9240608185507303,
            0.9620794104411434,
            0.9684885612791161,
            0.9462634376092591,
            0.9795679725630044,
            0.966626473041031,
            0.9916765290464985,
            0.9324894348725641,
            0.9530024780890834,
            0.9687246450487476,
            0.9989893701359785
           ]
          },
          {
           "label": "bagging_freq",
           "range": [
            1,
            7
           ],
           "values": [
            3,
            3,
            3,
            4,
            1,
            2,
            7,
            4,
            5,
            3,
            6,
            5,
            4,
            1,
            5,
            2,
            2,
            4,
            6,
            3,
            4,
            4,
            4,
            5,
            4,
            6,
            5,
            4,
            7,
            3,
            4,
            4,
            4,
            3,
            5,
            3,
            4,
            3,
            2,
            3,
            2,
            4,
            3,
            4,
            5,
            3,
            4,
            5,
            3,
            4,
            3,
            3,
            2,
            4,
            3,
            4,
            1,
            2,
            5,
            6,
            5,
            4,
            5,
            4,
            3,
            5,
            5,
            6,
            5,
            6,
            5,
            5,
            5,
            5,
            6,
            5,
            5,
            5,
            6,
            7,
            4,
            4,
            5,
            4,
            5,
            4,
            3,
            5,
            3,
            4,
            4,
            4,
            4,
            4,
            5,
            3,
            2,
            4,
            5,
            4,
            5,
            4,
            4,
            3,
            4,
            3,
            4,
            5,
            5,
            4,
            4,
            6,
            6,
            7,
            6,
            7,
            6,
            3,
            2,
            4,
            5,
            5,
            5,
            5,
            5,
            4,
            5,
            6,
            3,
            4,
            6,
            6,
            6,
            6,
            5,
            6,
            5,
            4,
            4,
            5,
            4,
            4,
            4,
            3,
            3,
            3,
            3,
            3,
            5,
            3,
            2,
            1,
            5,
            3,
            7,
            4,
            4,
            3,
            5,
            6,
            6,
            6,
            6,
            6,
            4,
            5,
            4,
            6,
            5,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            3,
            6,
            5,
            4,
            3,
            3,
            3,
            3,
            3,
            3,
            3,
            3,
            3,
            3,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            3,
            2,
            5,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            5,
            5,
            5,
            4,
            4,
            5,
            4,
            4,
            4,
            5,
            4,
            5,
            4,
            4,
            4,
            4,
            4,
            4,
            5,
            4,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            4,
            4,
            5,
            7,
            4,
            4,
            4,
            4,
            4,
            4,
            3,
            4,
            3
           ]
          },
          {
           "label": "feature_fraction",
           "range": [
            0.40385470520464267,
            0.9992748269741919
           ],
           "values": [
            0.8070143672569244,
            0.5920360716926122,
            0.8867169608076393,
            0.47580154965869104,
            0.8993764115350477,
            0.6247110497277543,
            0.6925616649443499,
            0.8854637063127473,
            0.591524869635234,
            0.9904132752427856,
            0.771719810078132,
            0.9916515493746944,
            0.965565064023366,
            0.8661168641036512,
            0.9750302959790409,
            0.7882234949008553,
            0.9136084954549114,
            0.40385470520464267,
            0.8347596973858491,
            0.7296826310005498,
            0.9372736322312379,
            0.9144574800999573,
            0.9288240879430438,
            0.9286377268362842,
            0.8456750101979462,
            0.9320643340333906,
            0.7254312756598025,
            0.9448444132186424,
            0.8289169782866298,
            0.8051602078356055,
            0.7673453225488467,
            0.9508116585402177,
            0.9468078025856748,
            0.8659145702424096,
            0.9133577242149757,
            0.9013175438187269,
            0.9930168655214928,
            0.6365600581861739,
            0.6465347527575518,
            0.5639966959580656,
            0.5336011739460421,
            0.6633906813721856,
            0.8798729495304536,
            0.5240860229542856,
            0.6095370765839139,
            0.690705008742354,
            0.9498957538318763,
            0.8529909584432215,
            0.9700189188339716,
            0.8859075806466381,
            0.9253170139520668,
            0.9978080336970844,
            0.9225489823631787,
            0.9662284178043206,
            0.9013443630246708,
            0.8727026480531697,
            0.9419263554723443,
            0.748996284934557,
            0.8260291054666281,
            0.8167405665229063,
            0.7973143499446836,
            0.9123181435646052,
            0.9733613668715477,
            0.9310308656986981,
            0.8538653603614574,
            0.8930591850339711,
            0.8944978798639422,
            0.8915807027459327,
            0.8297637914276058,
            0.6764838120463884,
            0.6369873866820246,
            0.9077949826121248,
            0.8691794307514382,
            0.9259409451593181,
            0.9585868693398384,
            0.9833762059524647,
            0.8924163915143161,
            0.8450707242133666,
            0.5754214777445744,
            0.9378955871381447,
            0.865037020870097,
            0.9226669610856061,
            0.4086782829456403,
            0.926267898961927,
            0.9001562003897604,
            0.8787305472525723,
            0.9158498796541703,
            0.7746428304909834,
            0.9572011507488654,
            0.6133138369649708,
            0.6044217131136912,
            0.6265413254410475,
            0.5448188151503046,
            0.6628553775433524,
            0.729959233626181,
            0.9361931918229928,
            0.7072393160530069,
            0.5969574403456124,
            0.9808412586224187,
            0.8878356853345102,
            0.9480338193552813,
            0.90916459932836,
            0.9590454135218269,
            0.9449456660427578,
            0.5766561250510195,
            0.9245317218345654,
            0.8989631990501604,
            0.8150353413388918,
            0.935534042395944,
            0.6504748508296276,
            0.9992748269741919,
            0.6665868992699322,
            0.6862716266053164,
            0.6145109736846287,
            0.676586223051265,
            0.6237990809016247,
            0.7024436131963749,
            0.8605133674397691,
            0.8394989779041699,
            0.9708298503619099,
            0.9137531576269602,
            0.4947622600452487,
            0.9177845330762011,
            0.8796018407419175,
            0.896535235703315,
            0.9090556302771828,
            0.9548406035687362,
            0.9310708407064494,
            0.7500988778060339,
            0.9417040774499512,
            0.9184026729346768,
            0.6441367884829354,
            0.6363941122496738,
            0.7015361912774168,
            0.8891410413930292,
            0.7176806264668425,
            0.5850664957225613,
            0.9658824185986019,
            0.6581268399725917,
            0.9032246145161328,
            0.8750475602472105,
            0.9239993051868411,
            0.8558885390961687,
            0.9098421061161583,
            0.9475078791520715,
            0.9069180387044024,
            0.9324739274596608,
            0.9827523162028197,
            0.6748962467056514,
            0.8895940119752143,
            0.9149359257676426,
            0.8725129968864749,
            0.9351961974533229,
            0.7872793263238796,
            0.8935700970601523,
            0.9132834148540865,
            0.6228665509276652,
            0.949073359232516,
            0.9268490140929626,
            0.8981279767866908,
            0.6014419067186153,
            0.9076549183932004,
            0.8792503698264691,
            0.8994274626427586,
            0.9170143806163679,
            0.8651019993668496,
            0.9363876051608453,
            0.9472996820408734,
            0.9587995203941538,
            0.9369389200403896,
            0.9251946635113388,
            0.9139898227501715,
            0.9053552485606218,
            0.8965150033225846,
            0.929063453255582,
            0.9401732590099232,
            0.8848806771654484,
            0.9562982393534398,
            0.9045256523961719,
            0.9675328036862104,
            0.688690795834287,
            0.7212753260188247,
            0.6872306899139627,
            0.7406393110276931,
            0.9219223547583201,
            0.7041819762119532,
            0.736420868057379,
            0.7075420513213868,
            0.5652274626249567,
            0.611095919694432,
            0.8979838525046407,
            0.6802769892890806,
            0.6980380988171961,
            0.7134797432066202,
            0.6684827179497824,
            0.6525228828929484,
            0.6394206295107017,
            0.6844072641730907,
            0.6524339879088339,
            0.631545079292905,
            0.6946111846168417,
            0.6953926880088436,
            0.6974346081175804,
            0.6755480248894579,
            0.6715231741255484,
            0.6522053009433653,
            0.6831882005812279,
            0.6588323325368437,
            0.663093791645384,
            0.6847885335754653,
            0.684854750091449,
            0.7124569485697683,
            0.694795521077232,
            0.6724556788522392,
            0.6774666220874964,
            0.7057556160506733,
            0.7037163502531255,
            0.7229957451795003,
            0.6471225452182615,
            0.6889808883482373,
            0.7675190843628517,
            0.7053424990585399,
            0.6637309743250113,
            0.6191596158353199,
            0.6807092130034055,
            0.6317586542355493,
            0.9088794941203371,
            0.6911195506492755,
            0.9266864492984757,
            0.754778875837993,
            0.7986080232967202,
            0.7467206740343227,
            0.7147966225662766,
            0.7025740355546768,
            0.7301240109995167,
            0.7791644739284467,
            0.8872976290404333,
            0.9145974274037751,
            0.8143677961857356,
            0.6719518619727191,
            0.7605565503105377,
            0.6975424862408013,
            0.693114451690096,
            0.6807017430037117,
            0.7149845245907417,
            0.7193475560119071,
            0.7094776565445066,
            0.4320550493349507,
            0.7308527874434009,
            0.9018566987483643
           ]
          },
          {
           "label": "lambda_l1",
           "range": [
            -7.865481777528598,
            0.9751958948412026
           ],
           "ticktext": [
            "1.36e-08",
            "1e-07",
            "1e-06",
            "1e-05",
            "0.0001",
            "0.001",
            "0.01",
            "0.1",
            "1",
            "9.44"
           ],
           "tickvals": [
            -7.865481777528598,
            -7,
            -6,
            -5,
            -4,
            -3,
            -2,
            -1,
            0,
            0.9751958948412026
           ],
           "values": [
            -4.194297241957531,
            -5.445358988962297,
            -6.248686974881467,
            0.7114414291962804,
            -5.743557321677353,
            -4.6586043643545985,
            -4.15401360555248,
            -7.424905645906153,
            -5.293285514025266,
            -0.8589879786429618,
            -7.865481777528598,
            -1.5137651861925876,
            -2.0957583805362066,
            0.7147703878279796,
            -1.9108094603034305,
            -7.527184849766558,
            -3.0515758637425074,
            -2.8721787355112296,
            -6.738151117431601,
            -0.3391899110898584,
            -0.3114191728224845,
            -0.6200836910567049,
            -0.3766781687716817,
            -0.35224171283561934,
            0.08697312098345233,
            -1.1334289358235021,
            -2.457686309270565,
            0.02903044149299421,
            -0.9426930510818735,
            0.8837649808005036,
            -3.8927837747190606,
            -0.09488919507446922,
            0.32222081223443294,
            -0.6837447751110476,
            -1.4633450081595136,
            0.4700386092660139,
            -0.28935389620836716,
            -1.524089073711317,
            -1.398705025055973,
            -1.9842320601264416,
            -0.6839763408989711,
            0.18370274629337652,
            -0.31824028950122424,
            0.49065582359081455,
            -1.2317199951596416,
            -0.7035976530289602,
            -1.842912488529336,
            -4.955570897177501,
            -2.5099488650504753,
            0.9751958948412026,
            -3.5846707471233596,
            -3.278197790097462,
            -4.398663598662464,
            -3.6768717696973896,
            -2.4499637570306194,
            -0.06724556582820719,
            -6.1047660988747126,
            -1.686816737029529,
            -0.9467409641429877,
            -1.125141332157129,
            -2.8947481840117435,
            -0.4336652656140482,
            0.5596450438951158,
            -0.9092165288050795,
            -0.0003776026967141372,
            -2.2049764471427338,
            -1.6354143048589536,
            -1.509782527267332,
            -2.3306746906157683,
            -2.091757682985409,
            -1.7079507947415584,
            -3.3364365777788447,
            -1.1193823766686848,
            -0.6494311879914252,
            -0.5514729049688847,
            -0.8871320820764433,
            -1.2104101235108442,
            -1.3813371803590873,
            -0.6323797215958311,
            -0.21007555894719346,
            -2.2218625377914707,
            -2.6181806194879487,
            -3.9535434345962224,
            -0.8674760530339165,
            -1.7110882492356823,
            0.2712403237392787,
            -2.7018742977466483,
            -0.4220683469522633,
            -1.0241709191898556,
            -4.385124343992143,
            -5.308370988432262,
            -4.621089358388465,
            -4.227262823441666,
            -4.951370229761472,
            -3.7016032431573658,
            -1.2824332430291059,
            -3.1880148008775624,
            -0.7765835177142097,
            -3.4958888524039153,
            -1.9922371437633546,
            -5.612357416298934,
            -0.16241200838854308,
            0.17529807245518092,
            0.7408110688414739,
            0.0009861108863711487,
            -0.5445484108850418,
            -1.4980177849626524,
            -0.39477962169051,
            -6.985577570327193,
            -1.8295289262238188,
            -1.0851216033506779,
            -2.282173932655287,
            -2.1339437659604585,
            -1.6185514319947083,
            -3.0013066276312093,
            -0.759301001697247,
            -1.3085738876877648,
            0.36408467058412736,
            -1.3063822978995885,
            -0.21195002919406136,
            -0.5208975108338769,
            -0.5099507046607239,
            -0.9842894567867947,
            0.10668810148158832,
            -0.6799101826005877,
            -0.3275270659929493,
            -3.989891984047596,
            -0.9715197358121752,
            -1.31389010701937,
            -0.5847329577804902,
            -4.3813146389670585,
            -1.81194369837545,
            -1.9417621546111987,
            -1.5967790762849128,
            -2.787612763604685,
            -1.1681288303606436,
            -0.1134556833337943,
            -0.7664788963296452,
            -2.0528404903431867,
            -0.28928410341510524,
            -2.496416781427272,
            -7.652201453185347,
            -6.945174274705266,
            -1.383244169166918,
            -1.385290056596881,
            -1.0218163323329652,
            -4.765540660666586,
            -1.5450551359823226,
            -0.8336113842206898,
            -0.4741901569133623,
            -3.704552736465949,
            -1.7029779473097657,
            -0.042041048100016305,
            -1.5107216964694634,
            -1.1822301371068775,
            -5.745492892663615,
            -6.562441147285358,
            -6.094289199112853,
            -7.34665325506408,
            -0.8769213991950375,
            -0.6657387814754979,
            -0.9075378296815775,
            -0.4284073611468233,
            -1.2915549603598313,
            -2.184980716529845,
            -0.5868483154846619,
            -1.8108200656573115,
            -1.7889366016576942,
            -2.3562665523519,
            -1.0856584632982802,
            -1.395824985373763,
            -1.9271885517715908,
            -0.2388822597498772,
            -0.2760221353441284,
            0.11353456655282809,
            -0.8319943790741172,
            -0.15109624954135023,
            0.35131270492959377,
            -0.49194944314001204,
            -1.6126047754375163,
            -0.9793656901821949,
            -0.9872120473454424,
            -0.7143661132381407,
            -1.2340361582046553,
            -0.2779926253461871,
            -1.4058795397706492,
            -1.0762816012183103,
            -1.3715299526904954,
            -0.8468837831180378,
            -1.5166306140639534,
            -0.6316263808162272,
            -1.7699945041234404,
            -1.7978587738038414,
            -1.151516199696919,
            0.015009003363035019,
            -1.3999848170992064,
            -1.437793651585384,
            -1.6587308900866364,
            -1.9354859535752975,
            -1.278842796759249,
            -0.890017673402485,
            -0.9364435041009969,
            -0.9160557203346729,
            -3.43362461391707,
            -1.517281565282802,
            -0.6977216630239687,
            -1.1893834421390432,
            -0.5074046210253462,
            -1.7812604791160633,
            -1.061299288573688,
            -0.7917106148246963,
            -1.129084246339466,
            -1.2978298781631055,
            -1.4532805803082862,
            -0.4144447482824558,
            -1.6607062387085965,
            -1.6857997646178693,
            -0.8811961439040654,
            -1.991668163692622,
            -1.1120779661683777,
            -1.5857074367825292,
            -1.315784808909708,
            -0.6866886984397892,
            -1.0486180498918403,
            -1.4094139884233197,
            -3.4086799218342727,
            -1.7382466600351698,
            -0.3440717894316076,
            -5.140432216688586,
            -0.5633503317844447,
            -0.542825905138066,
            -0.6888560832725678,
            -4.123771724732815,
            -0.9907495484734722,
            -0.13198091023847713,
            -1.565295438177457,
            -2.0985828292271074,
            -0.4128184156216228,
            -0.8193532034359878,
            -3.0901583414710734,
            -1.1800931743734377,
            -1.011688204494096,
            -0.8828298387284687,
            -0.5775128498527238,
            -1.3806335839956554,
            -1.3498678713924859,
            -1.6445954427065013,
            -1.4211192415028722,
            -1.9266868192607567,
            -1.2255674819462479
           ]
          },
          {
           "label": "lambda_l2",
           "range": [
            -7.9701166599364734,
            0.7740919995351427
           ],
           "ticktext": [
            "1.07e-08",
            "1e-07",
            "1e-06",
            "1e-05",
            "0.0001",
            "0.001",
            "0.01",
            "0.1",
            "1",
            "5.94"
           ],
           "tickvals": [
            -7.9701166599364734,
            -7,
            -6,
            -5,
            -4,
            -3,
            -2,
            -1,
            0,
            0.7740919995351427
           ],
           "values": [
            -5.09468554123833,
            -5.943618732679984,
            -4.837187941964263,
            -1.3680466198684795,
            -7.050253055040405,
            -4.78876471587388,
            -7.592911623900658,
            -4.405953924109005,
            -6.550353821825297,
            -5.809259233276099,
            -1.82308959504652,
            -3.0947411639876328,
            0.7170731735604975,
            -3.4245924755897166,
            -5.686268909003025,
            -3.8554463920789757,
            -7.9701166599364734,
            0.7603470942523871,
            0.7740919995351427,
            -2.3220409891492553,
            -3.9666874360592113,
            -4.0643800288816365,
            -4.139173830195609,
            -0.6509166034961386,
            -2.608422735052698,
            -4.224316155181347,
            -3.0724869810371667,
            -3.8343717315523396,
            -1.0866319451381263,
            -5.596141876689176,
            -5.192843858658101,
            -3.9695249528691634,
            -3.543038210874503,
            -4.629991505113427,
            -2.349374588712379,
            -5.259856950929206,
            -6.447738707325733,
            -2.8345746234053446,
            -2.781910652513704,
            -1.9871642623701105,
            -4.864314128088696,
            -3.5687488995271144,
            -4.2053397929359,
            -4.436224381575008,
            -3.0690693403357714,
            -3.5352876474870167,
            -3.962705474952273,
            -4.789564059584274,
            -1.588636497917574,
            -2.690792905044782,
            -3.2582682251402884,
            -3.2625952099987185,
            -3.8652071670605674,
            -4.437202155382679,
            -2.278665028744941,
            -2.952156220139187,
            -3.706353548616599,
            -3.300666110403174,
            -5.008455165616666,
            -5.489097570657919,
            0.25571050890509667,
            -6.163522876720605,
            -4.988903827726541,
            -4.27817884820874,
            -4.053567095253209,
            -4.588117830849894,
            -5.421056274383945,
            -5.9527732485498275,
            -6.798458765050756,
            -5.294359783783955,
            -4.637559999405952,
            -5.07553484434796,
            -4.59708867581487,
            -5.430530622955163,
            -5.5503091533102165,
            -6.04148477496254,
            -5.444384124323579,
            -6.301147140350296,
            -5.83767637024776,
            -7.365702514804282,
            -4.881366344302638,
            -4.300637868810765,
            -3.677394789735148,
            -4.060010185090959,
            -5.124873477488392,
            -3.3793869412908215,
            -2.880309559796821,
            -5.71530570954551,
            -2.4224203630104677,
            -4.590397305746961,
            -4.642282781506356,
            -4.406607894726697,
            -5.337420637193472,
            -3.200830559588677,
            -3.7581646742989427,
            -4.109198798898245,
            -4.89062714112137,
            -4.638733288780219,
            -3.5161466101610204,
            -4.44491669051051,
            -2.5667529442967005,
            -3.8801522699719224,
            -2.0546707972980798,
            -3.080192809598272,
            -4.202721596506992,
            -3.803335304689555,
            -4.9367137135407795,
            -5.200106241684532,
            -3.5847498931443718,
            -4.5501019012514705,
            -4.715049633416011,
            -5.440977908198383,
            -5.756146169203588,
            -5.280597471006717,
            -4.045419119581636,
            -4.303587765121596,
            -5.016109568632552,
            -4.843057533598262,
            -3.9501181930258205,
            -3.418085626536978,
            -2.914227405946088,
            -2.7516913377407506,
            -3.1958611764165923,
            -5.009437302517578,
            -2.948208519519231,
            -4.431274366175386,
            -3.646041612421007,
            -4.193447717345785,
            -5.1019933806285085,
            -3.3304419137935186,
            -2.5291250613101846,
            -5.605574822610623,
            -5.353789684326507,
            -5.913297439604108,
            -4.718611173968425,
            -5.172596272959479,
            -2.195956635417834,
            -3.855200997856846,
            -5.0137159667204765,
            -5.531539332562947,
            -4.5376427557162815,
            -4.351808215980265,
            -4.798085002350198,
            -4.151131520122058,
            -4.164104158502531,
            -4.001194950523534,
            -3.6757733503533787,
            -3.075930338738319,
            -2.84617323455164,
            -0.4758386341475453,
            -6.151250522203962,
            -4.412063004672959,
            -4.5642118636258875,
            -4.800267086411844,
            -4.173568232121059,
            -3.4736498027726914,
            -3.9327480585766867,
            -5.340313868854098,
            -3.7199430072912825,
            -5.004491980557769,
            -5.119695402236588,
            -4.8901534511859746,
            -4.668919055487617,
            -5.683041812331214,
            -3.440387317984182,
            -5.248634145690423,
            -3.3153581404896446,
            -3.223454432588111,
            -2.9788509557483236,
            -2.6852605180095597,
            -5.471287656070617,
            -3.5447164853422732,
            -3.390881349364479,
            -3.809609309906517,
            -3.14014468052591,
            -3.2831784815083007,
            -4.316281760162126,
            -5.018300323345661,
            -3.9504824399060823,
            -4.125824429476264,
            -2.8388945233618794,
            -2.593484414098175,
            -2.8524567222818713,
            -3.4012964635357967,
            -2.410667923493759,
            -3.093632005972496,
            -3.0173258561166985,
            -2.8000893390491055,
            -3.2401646672469777,
            -3.700627292937242,
            -3.048119335410978,
            -5.299316907522061,
            -3.5919405018113695,
            -4.5053839360062735,
            -4.946658777282622,
            -2.708668473529781,
            -2.7260631739418444,
            -3.081208045278977,
            -2.6611794116166543,
            -2.514969591589833,
            -2.877043639909011,
            -2.8966166281830157,
            -2.2857776486701273,
            -3.306786131041618,
            -2.9624327509717014,
            -5.18847325888102,
            -3.2769958517767024,
            -2.866447778781923,
            -5.445057790121822,
            -4.735427588724584,
            -4.633105694382574,
            -4.806558050623943,
            -5.034904980290426,
            -5.285656656498435,
            -2.7376773257737788,
            -4.285970391901677,
            -4.39031377061755,
            -4.253355120181176,
            -3.3359430500803184,
            -3.1580535507510006,
            -4.700452327772085,
            -4.497794488921812,
            -4.06282388029292,
            -5.637939594419969,
            -4.778388438923068,
            -4.321568858362174,
            -5.111700923274299,
            -2.96140442999657,
            -3.473412837083328,
            -2.4866357509538926,
            -2.5008818051245534,
            -2.649291344471749,
            -1.7899927817309291,
            -2.1365538893787543,
            -4.882469181234063,
            -2.3221237482717814,
            -2.7472924865627064,
            -3.078889709021789,
            -2.4687762124323918,
            -5.352847978779684,
            -4.58171161687845,
            -2.885753591501685,
            -2.9190218687043936,
            -3.140538946708523,
            -2.596655030728623,
            -4.084338454723869,
            -2.6482546689615254,
            -2.52596301638206,
            -5.004640759028527,
            -4.255110142839985
           ]
          },
          {
           "label": "min_child_samples",
           "range": [
            5,
            99
           ],
           "values": [
            99,
            11,
            57,
            37,
            70,
            88,
            90,
            56,
            77,
            39,
            10,
            39,
            37,
            53,
            25,
            65,
            46,
            24,
            23,
            61,
            47,
            46,
            47,
            44,
            48,
            33,
            73,
            28,
            52,
            63,
            19,
            29,
            15,
            46,
            31,
            41,
            5,
            51,
            52,
            59,
            79,
            50,
            68,
            56,
            42,
            34,
            57,
            27,
            38,
            35,
            48,
            49,
            55,
            44,
            95,
            40,
            65,
            47,
            52,
            59,
            53,
            43,
            49,
            46,
            36,
            54,
            53,
            63,
            54,
            60,
            51,
            45,
            57,
            49,
            52,
            55,
            40,
            43,
            69,
            50,
            58,
            48,
            48,
            62,
            53,
            46,
            41,
            51,
            38,
            55,
            55,
            50,
            45,
            66,
            60,
            57,
            48,
            72,
            53,
            55,
            43,
            51,
            20,
            32,
            11,
            48,
            28,
            45,
            58,
            54,
            62,
            60,
            64,
            67,
            56,
            52,
            50,
            47,
            79,
            42,
            50,
            50,
            49,
            53,
            46,
            51,
            44,
            40,
            54,
            57,
            47,
            60,
            49,
            6,
            52,
            56,
            58,
            50,
            54,
            45,
            47,
            52,
            61,
            59,
            55,
            22,
            49,
            85,
            59,
            64,
            15,
            53,
            58,
            56,
            51,
            62,
            48,
            42,
            54,
            50,
            44,
            51,
            49,
            56,
            63,
            46,
            61,
            53,
            60,
            50,
            26,
            66,
            62,
            70,
            58,
            47,
            60,
            55,
            52,
            62,
            50,
            49,
            51,
            99,
            46,
            53,
            53,
            49,
            55,
            30,
            51,
            57,
            57,
            53,
            50,
            48,
            44,
            46,
            48,
            48,
            54,
            52,
            54,
            56,
            56,
            58,
            54,
            51,
            56,
            58,
            59,
            57,
            61,
            54,
            52,
            49,
            50,
            47,
            64,
            49,
            47,
            52,
            55,
            50,
            59,
            45,
            57,
            53,
            50,
            48,
            48,
            51,
            44,
            48,
            55,
            53,
            46,
            50,
            58,
            61,
            52,
            52,
            54,
            49,
            56,
            56,
            59,
            56,
            47,
            51
           ]
          },
          {
           "label": "num_leaves",
           "range": [
            2,
            32
           ],
           "values": [
            12,
            26,
            19,
            8,
            23,
            23,
            25,
            29,
            18,
            15,
            31,
            3,
            14,
            32,
            10,
            16,
            7,
            13,
            28,
            20,
            22,
            29,
            29,
            22,
            28,
            26,
            30,
            21,
            24,
            32,
            27,
            21,
            25,
            18,
            20,
            29,
            22,
            26,
            26,
            30,
            24,
            27,
            24,
            22,
            19,
            29,
            25,
            27,
            31,
            18,
            23,
            23,
            21,
            25,
            28,
            26,
            30,
            16,
            23,
            23,
            28,
            21,
            20,
            23,
            2,
            19,
            17,
            16,
            18,
            14,
            7,
            20,
            19,
            11,
            11,
            8,
            17,
            12,
            14,
            5,
            29,
            24,
            22,
            31,
            26,
            27,
            25,
            24,
            9,
            21,
            32,
            21,
            23,
            22,
            17,
            19,
            28,
            20,
            22,
            15,
            21,
            21,
            19,
            23,
            25,
            18,
            30,
            20,
            24,
            29,
            27,
            12,
            14,
            15,
            13,
            13,
            11,
            10,
            11,
            22,
            23,
            23,
            6,
            24,
            26,
            21,
            22,
            31,
            19,
            20,
            10,
            11,
            16,
            17,
            25,
            22,
            14,
            21,
            23,
            12,
            18,
            29,
            28,
            10,
            9,
            9,
            12,
            10,
            20,
            11,
            23,
            8,
            30,
            29,
            24,
            27,
            21,
            31,
            19,
            28,
            28,
            30,
            28,
            26,
            10,
            22,
            26,
            27,
            23,
            25,
            24,
            27,
            27,
            29,
            26,
            28,
            25,
            13,
            22,
            29,
            26,
            26,
            26,
            27,
            24,
            23,
            4,
            23,
            25,
            22,
            21,
            16,
            18,
            28,
            16,
            20,
            20,
            20,
            17,
            19,
            15,
            17,
            16,
            11,
            11,
            9,
            11,
            12,
            27,
            15,
            16,
            15,
            15,
            15,
            10,
            13,
            14,
            13,
            14,
            12,
            30,
            16,
            10,
            13,
            15,
            26,
            28,
            11,
            11,
            27,
            27,
            26,
            28,
            29,
            27,
            21,
            17,
            15,
            10,
            22,
            27,
            17,
            18,
            16,
            17,
            18,
            12,
            17,
            19,
            28
           ]
          }
         ],
         "labelangle": 30,
         "labelside": "bottom",
         "line": {
          "color": [
           0.7991400414286611,
           0.8170296905404557,
           0.8114242671520934,
           0.8092147385600402,
           0.8148264390182662,
           0.8136965664427844,
           0.8159249262444291,
           0.8327663046889713,
           0.8159312033142928,
           0.8293955181721172,
           0.8125478626577113,
           0.8204444165463561,
           0.8293955181721172,
           0.8025045508756513,
           0.8181721172556651,
           0.8226664992781372,
           0.8215303496327915,
           0.8226476680685456,
           0.8293829640323895,
           0.8204193082669009,
           0.8361370912058252,
           0.8383654510074697,
           0.8361245370660975,
           0.8305065595380077,
           0.8237838177138912,
           0.8293955181721173,
           0.8215491808423827,
           0.833864791915134,
           0.8316427091833531,
           0.8092461239093591,
           0.8181595631159375,
           0.8316427091833531,
           0.8282593685267716,
           0.8181658401858012,
           0.8237775406440273,
           0.8294017952419811,
           0.8159186491745654,
           0.8350072186303434,
           0.8215366267026551,
           0.8293892411022536,
           0.819295712761283,
           0.8204193082669011,
           0.8249199673592367,
           0.8238026489234824,
           0.8282593685267716,
           0.8316301550436258,
           0.8271608813006089,
           0.821542903772519,
           0.8159123721047015,
           0.7879166405122089,
           0.8338836231247255,
           0.8305128366078716,
           0.8271483271608814,
           0.8248885820099178,
           0.8181721172556651,
           0.8271357730211537,
           0.8260561170045821,
           0.8293955181721172,
           0.8338961772644529,
           0.8293955181721172,
           0.8226664992781372,
           0.8282781997363632,
           0.8148389931579938,
           0.8204255853367648,
           0.811493314920595,
           0.8338899001945892,
           0.8338899001945892,
           0.829408072311845,
           0.8237775406440274,
           0.832772581758835,
           0.8215303496327915,
           0.8282781997363632,
           0.8316364321134895,
           0.8372481325717155,
           0.8316427091833531,
           0.8282719226664993,
           0.813684012303057,
           0.8271420500910175,
           0.8237900947837549,
           0.8148076078086749,
           0.8316427091833534,
           0.8249011361496453,
           0.8237775406440274,
           0.8293892411022534,
           0.8327537505492437,
           0.8271420500910175,
           0.8248948590797814,
           0.8282781997363632,
           0.8294017952419811,
           0.8350134957002071,
           0.828278199736363,
           0.8305128366078716,
           0.8271608813006088,
           0.8305191136777352,
           0.8215491808423827,
           0.8316489862532169,
           0.8271608813006089,
           0.8193082669010107,
           0.8282719226664993,
           0.8316364321134895,
           0.8316364321134895,
           0.8305128366078713,
           0.8226413909986817,
           0.8181972255351202,
           0.8271357730211537,
           0.8215303496327915,
           0.8215303496327915,
           0.8305191136777352,
           0.8316427091833531,
           0.8260372857949909,
           0.8316364321134895,
           0.8316427091833531,
           0.8283033080158184,
           0.812560416797439,
           0.8260498399347185,
           0.826037285794991,
           0.8338899001945892,
           0.8237838177138912,
           0.8226727763480008,
           0.8305002824681438,
           0.8350009415604795,
           0.8237775406440273,
           0.8260310087251271,
           0.8294080723118448,
           0.8305191136777352,
           0.8271420500910175,
           0.8316364321134895,
           0.8260184545853996,
           0.8181595631159375,
           0.8282719226664993,
           0.8293955181721172,
           0.8271671583704727,
           0.8260247316552635,
           0.8226476680685456,
           0.8305191136777352,
           0.8249199673592369,
           0.8305128366078713,
           0.8237775406440274,
           0.8305128366078713,
           0.8293892411022536,
           0.8226476680685456,
           0.827154604230745,
           0.8282719226664993,
           0.8338961772644529,
           0.830525390747599,
           0.8271357730211537,
           0.8282719226664993,
           0.8148076078086749,
           0.819295712761283,
           0.8249074132195092,
           0.8159186491745652,
           0.8316552633230808,
           0.826037285794991,
           0.8305191136777352,
           0.8305128366078713,
           0.8327663046889713,
           0.829408072311845,
           0.8305128366078713,
           0.8305128366078716,
           0.836137091205825,
           0.8237775406440273,
           0.8316489862532169,
           0.8271671583704727,
           0.8294080723118448,
           0.8293955181721172,
           0.8237775406440273,
           0.8372481325717155,
           0.831648986253217,
           0.830525390747599,
           0.8237775406440274,
           0.8237775406440274,
           0.8293955181721173,
           0.8350009415604795,
           0.8327663046889711,
           0.8249074132195091,
           0.8271483271608814,
           0.8327663046889713,
           0.8282907538760906,
           0.830525390747599,
           0.8327600276191076,
           0.8361308141359614,
           0.8293892411022534,
           0.8293955181721173,
           0.8137028435126483,
           0.8293892411022534,
           0.8372606867114432,
           0.8226790534178645,
           0.8327663046889713,
           0.8260247316552632,
           0.8316427091833531,
           0.8271483271608812,
           0.8350134957002073,
           0.8327600276191074,
           0.827154604230745,
           0.8260310087251271,
           0.8372544096415794,
           0.8305065595380077,
           0.8305191136777352,
           0.8271608813006088,
           0.824913690289373,
           0.8350072186303434,
           0.8338836231247255,
           0.8305128366078713,
           0.8338899001945892,
           0.8249011361496453,
           0.8249074132195091,
           0.8260184545853996,
           0.8282593685267716,
           0.8338773460548616,
           0.8350009415604797,
           0.8327663046889713,
           0.832772581758835,
           0.8305128366078716,
           0.8327663046889713,
           0.8282719226664994,
           0.8361308141359614,
           0.8316364321134895,
           0.8316301550436258,
           0.8294017952419811,
           0.8305065595380077,
           0.8249011361496453,
           0.8294017952419811,
           0.8327663046889711,
           0.8271483271608814,
           0.8327600276191074,
           0.8305128366078713,
           0.8305191136777352,
           0.8316427091833531,
           0.8192894356914191,
           0.8350072186303434,
           0.8316427091833531,
           0.8316364321134893,
           0.8271483271608814,
           0.8327600276191074,
           0.8294017952419811,
           0.8294017952419811,
           0.824913690289373,
           0.8271483271608814,
           0.8294080723118448,
           0.8249011361496453,
           0.8271608813006089,
           0.8316364321134895,
           0.8293892411022533,
           0.8327600276191074,
           0.8350009415604795,
           0.8282719226664993,
           0.8282656455966355,
           0.8271608813006088,
           0.8294017952419811,
           0.8293829640323898
          ],
          "colorbar": {
           "title": {
            "text": "Objective Value"
           }
          },
          "colorscale": [
           [
            0,
            "rgb(247,251,255)"
           ],
           [
            0.125,
            "rgb(222,235,247)"
           ],
           [
            0.25,
            "rgb(198,219,239)"
           ],
           [
            0.375,
            "rgb(158,202,225)"
           ],
           [
            0.5,
            "rgb(107,174,214)"
           ],
           [
            0.625,
            "rgb(66,146,198)"
           ],
           [
            0.75,
            "rgb(33,113,181)"
           ],
           [
            0.875,
            "rgb(8,81,156)"
           ],
           [
            1,
            "rgb(8,48,107)"
           ]
          ],
          "reversescale": false,
          "showscale": true
         },
         "type": "parcoords"
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Parallel Coordinate Plot"
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"571ac649-bc10-4a15-b25a-c6925aca3258\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"571ac649-bc10-4a15-b25a-c6925aca3258\")) {                    Plotly.newPlot(                        \"571ac649-bc10-4a15-b25a-c6925aca3258\",                        [{\"dimensions\":[{\"label\":\"Objective Value\",\"range\":[0.7879166405122089,0.8383654510074697],\"values\":[0.7991400414286611,0.8170296905404557,0.8114242671520934,0.8092147385600402,0.8148264390182662,0.8136965664427844,0.8159249262444291,0.8327663046889713,0.8159312033142928,0.8293955181721172,0.8125478626577113,0.8204444165463561,0.8293955181721172,0.8025045508756513,0.8181721172556651,0.8226664992781372,0.8215303496327915,0.8226476680685456,0.8293829640323895,0.8204193082669009,0.8361370912058252,0.8383654510074697,0.8361245370660975,0.8305065595380077,0.8237838177138912,0.8293955181721173,0.8215491808423827,0.833864791915134,0.8316427091833531,0.8092461239093591,0.8181595631159375,0.8316427091833531,0.8282593685267716,0.8181658401858012,0.8237775406440273,0.8294017952419811,0.8159186491745654,0.8350072186303434,0.8215366267026551,0.8293892411022536,0.819295712761283,0.8204193082669011,0.8249199673592367,0.8238026489234824,0.8282593685267716,0.8316301550436258,0.8271608813006089,0.821542903772519,0.8159123721047015,0.7879166405122089,0.8338836231247255,0.8305128366078716,0.8271483271608814,0.8248885820099178,0.8181721172556651,0.8271357730211537,0.8260561170045821,0.8293955181721172,0.8338961772644529,0.8293955181721172,0.8226664992781372,0.8282781997363632,0.8148389931579938,0.8204255853367648,0.811493314920595,0.8338899001945892,0.8338899001945892,0.829408072311845,0.8237775406440274,0.832772581758835,0.8215303496327915,0.8282781997363632,0.8316364321134895,0.8372481325717155,0.8316427091833531,0.8282719226664993,0.813684012303057,0.8271420500910175,0.8237900947837549,0.8148076078086749,0.8316427091833534,0.8249011361496453,0.8237775406440274,0.8293892411022534,0.8327537505492437,0.8271420500910175,0.8248948590797814,0.8282781997363632,0.8294017952419811,0.8350134957002071,0.828278199736363,0.8305128366078716,0.8271608813006088,0.8305191136777352,0.8215491808423827,0.8316489862532169,0.8271608813006089,0.8193082669010107,0.8282719226664993,0.8316364321134895,0.8316364321134895,0.8305128366078713,0.8226413909986817,0.8181972255351202,0.8271357730211537,0.8215303496327915,0.8215303496327915,0.8305191136777352,0.8316427091833531,0.8260372857949909,0.8316364321134895,0.8316427091833531,0.8283033080158184,0.812560416797439,0.8260498399347185,0.826037285794991,0.8338899001945892,0.8237838177138912,0.8226727763480008,0.8305002824681438,0.8350009415604795,0.8237775406440273,0.8260310087251271,0.8294080723118448,0.8305191136777352,0.8271420500910175,0.8316364321134895,0.8260184545853996,0.8181595631159375,0.8282719226664993,0.8293955181721172,0.8271671583704727,0.8260247316552635,0.8226476680685456,0.8305191136777352,0.8249199673592369,0.8305128366078713,0.8237775406440274,0.8305128366078713,0.8293892411022536,0.8226476680685456,0.827154604230745,0.8282719226664993,0.8338961772644529,0.830525390747599,0.8271357730211537,0.8282719226664993,0.8148076078086749,0.819295712761283,0.8249074132195092,0.8159186491745652,0.8316552633230808,0.826037285794991,0.8305191136777352,0.8305128366078713,0.8327663046889713,0.829408072311845,0.8305128366078713,0.8305128366078716,0.836137091205825,0.8237775406440273,0.8316489862532169,0.8271671583704727,0.8294080723118448,0.8293955181721172,0.8237775406440273,0.8372481325717155,0.831648986253217,0.830525390747599,0.8237775406440274,0.8237775406440274,0.8293955181721173,0.8350009415604795,0.8327663046889711,0.8249074132195091,0.8271483271608814,0.8327663046889713,0.8282907538760906,0.830525390747599,0.8327600276191076,0.8361308141359614,0.8293892411022534,0.8293955181721173,0.8137028435126483,0.8293892411022534,0.8372606867114432,0.8226790534178645,0.8327663046889713,0.8260247316552632,0.8316427091833531,0.8271483271608812,0.8350134957002073,0.8327600276191074,0.827154604230745,0.8260310087251271,0.8372544096415794,0.8305065595380077,0.8305191136777352,0.8271608813006088,0.824913690289373,0.8350072186303434,0.8338836231247255,0.8305128366078713,0.8338899001945892,0.8249011361496453,0.8249074132195091,0.8260184545853996,0.8282593685267716,0.8338773460548616,0.8350009415604797,0.8327663046889713,0.832772581758835,0.8305128366078716,0.8327663046889713,0.8282719226664994,0.8361308141359614,0.8316364321134895,0.8316301550436258,0.8294017952419811,0.8305065595380077,0.8249011361496453,0.8294017952419811,0.8327663046889711,0.8271483271608814,0.8327600276191074,0.8305128366078713,0.8305191136777352,0.8316427091833531,0.8192894356914191,0.8350072186303434,0.8316427091833531,0.8316364321134893,0.8271483271608814,0.8327600276191074,0.8294017952419811,0.8294017952419811,0.824913690289373,0.8271483271608814,0.8294080723118448,0.8249011361496453,0.8271608813006089,0.8316364321134895,0.8293892411022533,0.8327600276191074,0.8350009415604795,0.8282719226664993,0.8282656455966355,0.8271608813006088,0.8294017952419811,0.8293829640323898]},{\"label\":\"bagging_fraction\",\"range\":[0.401965225477051,0.9999636511943943],\"values\":[0.5115606779832345,0.9035854363156637,0.586463520201019,0.6848872997430882,0.5144677594292105,0.9242291527962854,0.95204636215645,0.8412976001533627,0.8387659433426398,0.7132396751578023,0.7680955484090313,0.714464776070218,0.8049382113407397,0.6604712994864956,0.42998232879216614,0.8374531633989446,0.6224202124070706,0.8014506402835758,0.8675505893469363,0.7279463079795199,0.991429544171526,0.9844533490969807,0.9823302217824006,0.9647155759002808,0.9604131326250278,0.9922348476278575,0.9963111783764703,0.8954265349365642,0.9223334853626186,0.9927546376132949,0.8771251265284395,0.9076414739475414,0.9430928133152174,0.8861178139899989,0.9994055939596402,0.9594922472155742,0.9044868254482515,0.933055326781762,0.5580319120571919,0.9364061339420611,0.9645243829357294,0.9252343583038842,0.862097460539901,0.970433658317487,0.895347419553127,0.9353724702785845,0.7655229308337063,0.8456982014729227,0.8181716117560768,0.401965225477051,0.9728890582469202,0.9771276912967326,0.943422925166358,0.9168418946620064,0.9758541978136482,0.9035221806694483,0.9496190419196208,0.9813849178578143,0.8608126428126366,0.9997307118581531,0.7734254410595303,0.8639522191533947,0.9248270656936931,0.6661634702593455,0.8880724886393485,0.9543143016475211,0.9484389341392316,0.9451338275779183,0.9530282046847264,0.9221408818808012,0.9833622353471669,0.96389149993437,0.9806843686858877,0.9995244893393281,0.9352858352400958,0.999547618526205,0.4726012813312743,0.9564942967620326,0.9097048395255692,0.5953455461671947,0.8767461914134154,0.9664910881376431,0.9822584052320559,0.9372454193589559,0.987317407810519,0.962300663234522,0.971738406182177,0.9333178101753618,0.9907529677425011,0.950905373314695,0.851672348694522,0.9559185973390645,0.9151544655549616,0.944231428821731,0.8235402570707996,0.9724440941749355,0.8938432910313799,0.9996025864558219,0.9473818682492193,0.9256491224065487,0.9722797707812918,0.9012663784533421,0.954688270185467,0.8828622365428727,0.9836662748118168,0.9294775378601928,0.9191926415725702,0.9623308384609592,0.9890472342656226,0.9109110610157991,0.9455598583548168,0.9734683792864095,0.9240851469455091,0.7303411753693254,0.8975084824279764,0.8692541414343299,0.955184610086501,0.9526508547919396,0.9895130083734557,0.9683716089474699,0.9393023695965079,0.9385322042238998,0.9570139281701294,0.9802786377894558,0.9999636511943943,0.938587624675898,0.970545620467604,0.9080742490540691,0.5322455722848536,0.9502307429420435,0.932271966016139,0.9162667837272143,0.9619128901942636,0.982757774982424,0.9273976735847572,0.8910391389882653,0.9457196248013503,0.9909543629928306,0.9630387641829684,0.9773495069450313,0.854993317460407,0.8360961131375221,0.8744992155888697,0.9176344442396581,0.9176146256842153,0.8991551801733263,0.9353051976105876,0.952405082992364,0.6254290016146619,0.9238374740819135,0.9730447505907351,0.9031676345855512,0.8846920312763566,0.8089394509821175,0.9424187096853462,0.9882612081256744,0.7945444304370258,0.9617138166435377,0.9996062653837385,0.9092282983973848,0.9087818666412456,0.8345111561561149,0.8665102264359231,0.9293834389742592,0.9848165559215974,0.9551417061921584,0.9751150721105847,0.9682392967698904,0.9366579551861546,0.9520638797905584,0.9784629022012583,0.9895409752835023,0.9667750915922655,0.9646162822088644,0.9176742409264921,0.9457053168719673,0.9756201338387883,0.961208857737644,0.9379528037100416,0.9996932860873987,0.9722329180862063,0.9712381816869154,0.9516942590505904,0.9792801936172691,0.9275668995157118,0.9874678077120393,0.9858447628844617,0.9668824389970319,0.9916449739473728,0.978175877182217,0.9593832078343243,0.9447332717964526,0.9535627219515876,0.6908358496105276,0.9382899073991662,0.9705884841739005,0.9701291443331537,0.9824139888015821,0.9988412897049158,0.9469744976659645,0.9667101857809698,0.9676385536050676,0.9608305892207868,0.9850274510319682,0.9850150190863778,0.9766728911397398,0.9876937628975584,0.9451329962974294,0.9572180411515862,0.9700249614306424,0.9925748341734213,0.9696991852707546,0.976944332379459,0.9595522774559774,0.9491870626355637,0.9715425081855453,0.9428339661570054,0.9991415644519036,0.977368588066164,0.9683831763274019,0.9319016715645208,0.9880096952419042,0.9599439297804464,0.9733038165485044,0.9848767990349919,0.9513150173267871,0.9641797818736095,0.9398036208037361,0.7295297784631476,0.989528897201257,0.973280301352641,0.9864631850625143,0.9995035423352431,0.9821083469430207,0.958346741720756,0.9699519301578394,0.9904637635072004,0.9543546940470927,0.9774734831750441,0.9240608185507303,0.9620794104411434,0.9684885612791161,0.9462634376092591,0.9795679725630044,0.966626473041031,0.9916765290464985,0.9324894348725641,0.9530024780890834,0.9687246450487476,0.9989893701359785]},{\"label\":\"bagging_freq\",\"range\":[1,7],\"values\":[3,3,3,4,1,2,7,4,5,3,6,5,4,1,5,2,2,4,6,3,4,4,4,5,4,6,5,4,7,3,4,4,4,3,5,3,4,3,2,3,2,4,3,4,5,3,4,5,3,4,3,3,2,4,3,4,1,2,5,6,5,4,5,4,3,5,5,6,5,6,5,5,5,5,6,5,5,5,6,7,4,4,5,4,5,4,3,5,3,4,4,4,4,4,5,3,2,4,5,4,5,4,4,3,4,3,4,5,5,4,4,6,6,7,6,7,6,3,2,4,5,5,5,5,5,4,5,6,3,4,6,6,6,6,5,6,5,4,4,5,4,4,4,3,3,3,3,3,5,3,2,1,5,3,7,4,4,3,5,6,6,6,6,6,4,5,4,6,5,4,4,4,4,4,4,4,3,6,5,4,3,3,3,3,3,3,3,3,3,3,4,4,4,4,4,4,4,3,2,5,4,4,4,4,4,4,4,4,4,5,5,5,4,4,5,4,4,4,5,4,5,4,4,4,4,4,4,5,4,5,5,5,5,5,5,5,5,4,4,5,7,4,4,4,4,4,4,3,4,3]},{\"label\":\"feature_fraction\",\"range\":[0.40385470520464267,0.9992748269741919],\"values\":[0.8070143672569244,0.5920360716926122,0.8867169608076393,0.47580154965869104,0.8993764115350477,0.6247110497277543,0.6925616649443499,0.8854637063127473,0.591524869635234,0.9904132752427856,0.771719810078132,0.9916515493746944,0.965565064023366,0.8661168641036512,0.9750302959790409,0.7882234949008553,0.9136084954549114,0.40385470520464267,0.8347596973858491,0.7296826310005498,0.9372736322312379,0.9144574800999573,0.9288240879430438,0.9286377268362842,0.8456750101979462,0.9320643340333906,0.7254312756598025,0.9448444132186424,0.8289169782866298,0.8051602078356055,0.7673453225488467,0.9508116585402177,0.9468078025856748,0.8659145702424096,0.9133577242149757,0.9013175438187269,0.9930168655214928,0.6365600581861739,0.6465347527575518,0.5639966959580656,0.5336011739460421,0.6633906813721856,0.8798729495304536,0.5240860229542856,0.6095370765839139,0.690705008742354,0.9498957538318763,0.8529909584432215,0.9700189188339716,0.8859075806466381,0.9253170139520668,0.9978080336970844,0.9225489823631787,0.9662284178043206,0.9013443630246708,0.8727026480531697,0.9419263554723443,0.748996284934557,0.8260291054666281,0.8167405665229063,0.7973143499446836,0.9123181435646052,0.9733613668715477,0.9310308656986981,0.8538653603614574,0.8930591850339711,0.8944978798639422,0.8915807027459327,0.8297637914276058,0.6764838120463884,0.6369873866820246,0.9077949826121248,0.8691794307514382,0.9259409451593181,0.9585868693398384,0.9833762059524647,0.8924163915143161,0.8450707242133666,0.5754214777445744,0.9378955871381447,0.865037020870097,0.9226669610856061,0.4086782829456403,0.926267898961927,0.9001562003897604,0.8787305472525723,0.9158498796541703,0.7746428304909834,0.9572011507488654,0.6133138369649708,0.6044217131136912,0.6265413254410475,0.5448188151503046,0.6628553775433524,0.729959233626181,0.9361931918229928,0.7072393160530069,0.5969574403456124,0.9808412586224187,0.8878356853345102,0.9480338193552813,0.90916459932836,0.9590454135218269,0.9449456660427578,0.5766561250510195,0.9245317218345654,0.8989631990501604,0.8150353413388918,0.935534042395944,0.6504748508296276,0.9992748269741919,0.6665868992699322,0.6862716266053164,0.6145109736846287,0.676586223051265,0.6237990809016247,0.7024436131963749,0.8605133674397691,0.8394989779041699,0.9708298503619099,0.9137531576269602,0.4947622600452487,0.9177845330762011,0.8796018407419175,0.896535235703315,0.9090556302771828,0.9548406035687362,0.9310708407064494,0.7500988778060339,0.9417040774499512,0.9184026729346768,0.6441367884829354,0.6363941122496738,0.7015361912774168,0.8891410413930292,0.7176806264668425,0.5850664957225613,0.9658824185986019,0.6581268399725917,0.9032246145161328,0.8750475602472105,0.9239993051868411,0.8558885390961687,0.9098421061161583,0.9475078791520715,0.9069180387044024,0.9324739274596608,0.9827523162028197,0.6748962467056514,0.8895940119752143,0.9149359257676426,0.8725129968864749,0.9351961974533229,0.7872793263238796,0.8935700970601523,0.9132834148540865,0.6228665509276652,0.949073359232516,0.9268490140929626,0.8981279767866908,0.6014419067186153,0.9076549183932004,0.8792503698264691,0.8994274626427586,0.9170143806163679,0.8651019993668496,0.9363876051608453,0.9472996820408734,0.9587995203941538,0.9369389200403896,0.9251946635113388,0.9139898227501715,0.9053552485606218,0.8965150033225846,0.929063453255582,0.9401732590099232,0.8848806771654484,0.9562982393534398,0.9045256523961719,0.9675328036862104,0.688690795834287,0.7212753260188247,0.6872306899139627,0.7406393110276931,0.9219223547583201,0.7041819762119532,0.736420868057379,0.7075420513213868,0.5652274626249567,0.611095919694432,0.8979838525046407,0.6802769892890806,0.6980380988171961,0.7134797432066202,0.6684827179497824,0.6525228828929484,0.6394206295107017,0.6844072641730907,0.6524339879088339,0.631545079292905,0.6946111846168417,0.6953926880088436,0.6974346081175804,0.6755480248894579,0.6715231741255484,0.6522053009433653,0.6831882005812279,0.6588323325368437,0.663093791645384,0.6847885335754653,0.684854750091449,0.7124569485697683,0.694795521077232,0.6724556788522392,0.6774666220874964,0.7057556160506733,0.7037163502531255,0.7229957451795003,0.6471225452182615,0.6889808883482373,0.7675190843628517,0.7053424990585399,0.6637309743250113,0.6191596158353199,0.6807092130034055,0.6317586542355493,0.9088794941203371,0.6911195506492755,0.9266864492984757,0.754778875837993,0.7986080232967202,0.7467206740343227,0.7147966225662766,0.7025740355546768,0.7301240109995167,0.7791644739284467,0.8872976290404333,0.9145974274037751,0.8143677961857356,0.6719518619727191,0.7605565503105377,0.6975424862408013,0.693114451690096,0.6807017430037117,0.7149845245907417,0.7193475560119071,0.7094776565445066,0.4320550493349507,0.7308527874434009,0.9018566987483643]},{\"label\":\"lambda_l1\",\"range\":[-7.865481777528598,0.9751958948412026],\"ticktext\":[\"1.36e-08\",\"1e-07\",\"1e-06\",\"1e-05\",\"0.0001\",\"0.001\",\"0.01\",\"0.1\",\"1\",\"9.44\"],\"tickvals\":[-7.865481777528598,-7,-6,-5,-4,-3,-2,-1,0,0.9751958948412026],\"values\":[-4.194297241957531,-5.445358988962297,-6.248686974881467,0.7114414291962804,-5.743557321677353,-4.6586043643545985,-4.15401360555248,-7.424905645906153,-5.293285514025266,-0.8589879786429618,-7.865481777528598,-1.5137651861925876,-2.0957583805362066,0.7147703878279796,-1.9108094603034305,-7.527184849766558,-3.0515758637425074,-2.8721787355112296,-6.738151117431601,-0.3391899110898584,-0.3114191728224845,-0.6200836910567049,-0.3766781687716817,-0.35224171283561934,0.08697312098345233,-1.1334289358235021,-2.457686309270565,0.02903044149299421,-0.9426930510818735,0.8837649808005036,-3.8927837747190606,-0.09488919507446922,0.32222081223443294,-0.6837447751110476,-1.4633450081595136,0.4700386092660139,-0.28935389620836716,-1.524089073711317,-1.398705025055973,-1.9842320601264416,-0.6839763408989711,0.18370274629337652,-0.31824028950122424,0.49065582359081455,-1.2317199951596416,-0.7035976530289602,-1.842912488529336,-4.955570897177501,-2.5099488650504753,0.9751958948412026,-3.5846707471233596,-3.278197790097462,-4.398663598662464,-3.6768717696973896,-2.4499637570306194,-0.06724556582820719,-6.1047660988747126,-1.686816737029529,-0.9467409641429877,-1.125141332157129,-2.8947481840117435,-0.4336652656140482,0.5596450438951158,-0.9092165288050795,-0.0003776026967141372,-2.2049764471427338,-1.6354143048589536,-1.509782527267332,-2.3306746906157683,-2.091757682985409,-1.7079507947415584,-3.3364365777788447,-1.1193823766686848,-0.6494311879914252,-0.5514729049688847,-0.8871320820764433,-1.2104101235108442,-1.3813371803590873,-0.6323797215958311,-0.21007555894719346,-2.2218625377914707,-2.6181806194879487,-3.9535434345962224,-0.8674760530339165,-1.7110882492356823,0.2712403237392787,-2.7018742977466483,-0.4220683469522633,-1.0241709191898556,-4.385124343992143,-5.308370988432262,-4.621089358388465,-4.227262823441666,-4.951370229761472,-3.7016032431573658,-1.2824332430291059,-3.1880148008775624,-0.7765835177142097,-3.4958888524039153,-1.9922371437633546,-5.612357416298934,-0.16241200838854308,0.17529807245518092,0.7408110688414739,0.0009861108863711487,-0.5445484108850418,-1.4980177849626524,-0.39477962169051,-6.985577570327193,-1.8295289262238188,-1.0851216033506779,-2.282173932655287,-2.1339437659604585,-1.6185514319947083,-3.0013066276312093,-0.759301001697247,-1.3085738876877648,0.36408467058412736,-1.3063822978995885,-0.21195002919406136,-0.5208975108338769,-0.5099507046607239,-0.9842894567867947,0.10668810148158832,-0.6799101826005877,-0.3275270659929493,-3.989891984047596,-0.9715197358121752,-1.31389010701937,-0.5847329577804902,-4.3813146389670585,-1.81194369837545,-1.9417621546111987,-1.5967790762849128,-2.787612763604685,-1.1681288303606436,-0.1134556833337943,-0.7664788963296452,-2.0528404903431867,-0.28928410341510524,-2.496416781427272,-7.652201453185347,-6.945174274705266,-1.383244169166918,-1.385290056596881,-1.0218163323329652,-4.765540660666586,-1.5450551359823226,-0.8336113842206898,-0.4741901569133623,-3.704552736465949,-1.7029779473097657,-0.042041048100016305,-1.5107216964694634,-1.1822301371068775,-5.745492892663615,-6.562441147285358,-6.094289199112853,-7.34665325506408,-0.8769213991950375,-0.6657387814754979,-0.9075378296815775,-0.4284073611468233,-1.2915549603598313,-2.184980716529845,-0.5868483154846619,-1.8108200656573115,-1.7889366016576942,-2.3562665523519,-1.0856584632982802,-1.395824985373763,-1.9271885517715908,-0.2388822597498772,-0.2760221353441284,0.11353456655282809,-0.8319943790741172,-0.15109624954135023,0.35131270492959377,-0.49194944314001204,-1.6126047754375163,-0.9793656901821949,-0.9872120473454424,-0.7143661132381407,-1.2340361582046553,-0.2779926253461871,-1.4058795397706492,-1.0762816012183103,-1.3715299526904954,-0.8468837831180378,-1.5166306140639534,-0.6316263808162272,-1.7699945041234404,-1.7978587738038414,-1.151516199696919,0.015009003363035019,-1.3999848170992064,-1.437793651585384,-1.6587308900866364,-1.9354859535752975,-1.278842796759249,-0.890017673402485,-0.9364435041009969,-0.9160557203346729,-3.43362461391707,-1.517281565282802,-0.6977216630239687,-1.1893834421390432,-0.5074046210253462,-1.7812604791160633,-1.061299288573688,-0.7917106148246963,-1.129084246339466,-1.2978298781631055,-1.4532805803082862,-0.4144447482824558,-1.6607062387085965,-1.6857997646178693,-0.8811961439040654,-1.991668163692622,-1.1120779661683777,-1.5857074367825292,-1.315784808909708,-0.6866886984397892,-1.0486180498918403,-1.4094139884233197,-3.4086799218342727,-1.7382466600351698,-0.3440717894316076,-5.140432216688586,-0.5633503317844447,-0.542825905138066,-0.6888560832725678,-4.123771724732815,-0.9907495484734722,-0.13198091023847713,-1.565295438177457,-2.0985828292271074,-0.4128184156216228,-0.8193532034359878,-3.0901583414710734,-1.1800931743734377,-1.011688204494096,-0.8828298387284687,-0.5775128498527238,-1.3806335839956554,-1.3498678713924859,-1.6445954427065013,-1.4211192415028722,-1.9266868192607567,-1.2255674819462479]},{\"label\":\"lambda_l2\",\"range\":[-7.9701166599364734,0.7740919995351427],\"ticktext\":[\"1.07e-08\",\"1e-07\",\"1e-06\",\"1e-05\",\"0.0001\",\"0.001\",\"0.01\",\"0.1\",\"1\",\"5.94\"],\"tickvals\":[-7.9701166599364734,-7,-6,-5,-4,-3,-2,-1,0,0.7740919995351427],\"values\":[-5.09468554123833,-5.943618732679984,-4.837187941964263,-1.3680466198684795,-7.050253055040405,-4.78876471587388,-7.592911623900658,-4.405953924109005,-6.550353821825297,-5.809259233276099,-1.82308959504652,-3.0947411639876328,0.7170731735604975,-3.4245924755897166,-5.686268909003025,-3.8554463920789757,-7.9701166599364734,0.7603470942523871,0.7740919995351427,-2.3220409891492553,-3.9666874360592113,-4.0643800288816365,-4.139173830195609,-0.6509166034961386,-2.608422735052698,-4.224316155181347,-3.0724869810371667,-3.8343717315523396,-1.0866319451381263,-5.596141876689176,-5.192843858658101,-3.9695249528691634,-3.543038210874503,-4.629991505113427,-2.349374588712379,-5.259856950929206,-6.447738707325733,-2.8345746234053446,-2.781910652513704,-1.9871642623701105,-4.864314128088696,-3.5687488995271144,-4.2053397929359,-4.436224381575008,-3.0690693403357714,-3.5352876474870167,-3.962705474952273,-4.789564059584274,-1.588636497917574,-2.690792905044782,-3.2582682251402884,-3.2625952099987185,-3.8652071670605674,-4.437202155382679,-2.278665028744941,-2.952156220139187,-3.706353548616599,-3.300666110403174,-5.008455165616666,-5.489097570657919,0.25571050890509667,-6.163522876720605,-4.988903827726541,-4.27817884820874,-4.053567095253209,-4.588117830849894,-5.421056274383945,-5.9527732485498275,-6.798458765050756,-5.294359783783955,-4.637559999405952,-5.07553484434796,-4.59708867581487,-5.430530622955163,-5.5503091533102165,-6.04148477496254,-5.444384124323579,-6.301147140350296,-5.83767637024776,-7.365702514804282,-4.881366344302638,-4.300637868810765,-3.677394789735148,-4.060010185090959,-5.124873477488392,-3.3793869412908215,-2.880309559796821,-5.71530570954551,-2.4224203630104677,-4.590397305746961,-4.642282781506356,-4.406607894726697,-5.337420637193472,-3.200830559588677,-3.7581646742989427,-4.109198798898245,-4.89062714112137,-4.638733288780219,-3.5161466101610204,-4.44491669051051,-2.5667529442967005,-3.8801522699719224,-2.0546707972980798,-3.080192809598272,-4.202721596506992,-3.803335304689555,-4.9367137135407795,-5.200106241684532,-3.5847498931443718,-4.5501019012514705,-4.715049633416011,-5.440977908198383,-5.756146169203588,-5.280597471006717,-4.045419119581636,-4.303587765121596,-5.016109568632552,-4.843057533598262,-3.9501181930258205,-3.418085626536978,-2.914227405946088,-2.7516913377407506,-3.1958611764165923,-5.009437302517578,-2.948208519519231,-4.431274366175386,-3.646041612421007,-4.193447717345785,-5.1019933806285085,-3.3304419137935186,-2.5291250613101846,-5.605574822610623,-5.353789684326507,-5.913297439604108,-4.718611173968425,-5.172596272959479,-2.195956635417834,-3.855200997856846,-5.0137159667204765,-5.531539332562947,-4.5376427557162815,-4.351808215980265,-4.798085002350198,-4.151131520122058,-4.164104158502531,-4.001194950523534,-3.6757733503533787,-3.075930338738319,-2.84617323455164,-0.4758386341475453,-6.151250522203962,-4.412063004672959,-4.5642118636258875,-4.800267086411844,-4.173568232121059,-3.4736498027726914,-3.9327480585766867,-5.340313868854098,-3.7199430072912825,-5.004491980557769,-5.119695402236588,-4.8901534511859746,-4.668919055487617,-5.683041812331214,-3.440387317984182,-5.248634145690423,-3.3153581404896446,-3.223454432588111,-2.9788509557483236,-2.6852605180095597,-5.471287656070617,-3.5447164853422732,-3.390881349364479,-3.809609309906517,-3.14014468052591,-3.2831784815083007,-4.316281760162126,-5.018300323345661,-3.9504824399060823,-4.125824429476264,-2.8388945233618794,-2.593484414098175,-2.8524567222818713,-3.4012964635357967,-2.410667923493759,-3.093632005972496,-3.0173258561166985,-2.8000893390491055,-3.2401646672469777,-3.700627292937242,-3.048119335410978,-5.299316907522061,-3.5919405018113695,-4.5053839360062735,-4.946658777282622,-2.708668473529781,-2.7260631739418444,-3.081208045278977,-2.6611794116166543,-2.514969591589833,-2.877043639909011,-2.8966166281830157,-2.2857776486701273,-3.306786131041618,-2.9624327509717014,-5.18847325888102,-3.2769958517767024,-2.866447778781923,-5.445057790121822,-4.735427588724584,-4.633105694382574,-4.806558050623943,-5.034904980290426,-5.285656656498435,-2.7376773257737788,-4.285970391901677,-4.39031377061755,-4.253355120181176,-3.3359430500803184,-3.1580535507510006,-4.700452327772085,-4.497794488921812,-4.06282388029292,-5.637939594419969,-4.778388438923068,-4.321568858362174,-5.111700923274299,-2.96140442999657,-3.473412837083328,-2.4866357509538926,-2.5008818051245534,-2.649291344471749,-1.7899927817309291,-2.1365538893787543,-4.882469181234063,-2.3221237482717814,-2.7472924865627064,-3.078889709021789,-2.4687762124323918,-5.352847978779684,-4.58171161687845,-2.885753591501685,-2.9190218687043936,-3.140538946708523,-2.596655030728623,-4.084338454723869,-2.6482546689615254,-2.52596301638206,-5.004640759028527,-4.255110142839985]},{\"label\":\"min_child_samples\",\"range\":[5,99],\"values\":[99,11,57,37,70,88,90,56,77,39,10,39,37,53,25,65,46,24,23,61,47,46,47,44,48,33,73,28,52,63,19,29,15,46,31,41,5,51,52,59,79,50,68,56,42,34,57,27,38,35,48,49,55,44,95,40,65,47,52,59,53,43,49,46,36,54,53,63,54,60,51,45,57,49,52,55,40,43,69,50,58,48,48,62,53,46,41,51,38,55,55,50,45,66,60,57,48,72,53,55,43,51,20,32,11,48,28,45,58,54,62,60,64,67,56,52,50,47,79,42,50,50,49,53,46,51,44,40,54,57,47,60,49,6,52,56,58,50,54,45,47,52,61,59,55,22,49,85,59,64,15,53,58,56,51,62,48,42,54,50,44,51,49,56,63,46,61,53,60,50,26,66,62,70,58,47,60,55,52,62,50,49,51,99,46,53,53,49,55,30,51,57,57,53,50,48,44,46,48,48,54,52,54,56,56,58,54,51,56,58,59,57,61,54,52,49,50,47,64,49,47,52,55,50,59,45,57,53,50,48,48,51,44,48,55,53,46,50,58,61,52,52,54,49,56,56,59,56,47,51]},{\"label\":\"num_leaves\",\"range\":[2,32],\"values\":[12,26,19,8,23,23,25,29,18,15,31,3,14,32,10,16,7,13,28,20,22,29,29,22,28,26,30,21,24,32,27,21,25,18,20,29,22,26,26,30,24,27,24,22,19,29,25,27,31,18,23,23,21,25,28,26,30,16,23,23,28,21,20,23,2,19,17,16,18,14,7,20,19,11,11,8,17,12,14,5,29,24,22,31,26,27,25,24,9,21,32,21,23,22,17,19,28,20,22,15,21,21,19,23,25,18,30,20,24,29,27,12,14,15,13,13,11,10,11,22,23,23,6,24,26,21,22,31,19,20,10,11,16,17,25,22,14,21,23,12,18,29,28,10,9,9,12,10,20,11,23,8,30,29,24,27,21,31,19,28,28,30,28,26,10,22,26,27,23,25,24,27,27,29,26,28,25,13,22,29,26,26,26,27,24,23,4,23,25,22,21,16,18,28,16,20,20,20,17,19,15,17,16,11,11,9,11,12,27,15,16,15,15,15,10,13,14,13,14,12,30,16,10,13,15,26,28,11,11,27,27,26,28,29,27,21,17,15,10,22,27,17,18,16,17,18,12,17,19,28]}],\"labelangle\":30,\"labelside\":\"bottom\",\"line\":{\"color\":[0.7991400414286611,0.8170296905404557,0.8114242671520934,0.8092147385600402,0.8148264390182662,0.8136965664427844,0.8159249262444291,0.8327663046889713,0.8159312033142928,0.8293955181721172,0.8125478626577113,0.8204444165463561,0.8293955181721172,0.8025045508756513,0.8181721172556651,0.8226664992781372,0.8215303496327915,0.8226476680685456,0.8293829640323895,0.8204193082669009,0.8361370912058252,0.8383654510074697,0.8361245370660975,0.8305065595380077,0.8237838177138912,0.8293955181721173,0.8215491808423827,0.833864791915134,0.8316427091833531,0.8092461239093591,0.8181595631159375,0.8316427091833531,0.8282593685267716,0.8181658401858012,0.8237775406440273,0.8294017952419811,0.8159186491745654,0.8350072186303434,0.8215366267026551,0.8293892411022536,0.819295712761283,0.8204193082669011,0.8249199673592367,0.8238026489234824,0.8282593685267716,0.8316301550436258,0.8271608813006089,0.821542903772519,0.8159123721047015,0.7879166405122089,0.8338836231247255,0.8305128366078716,0.8271483271608814,0.8248885820099178,0.8181721172556651,0.8271357730211537,0.8260561170045821,0.8293955181721172,0.8338961772644529,0.8293955181721172,0.8226664992781372,0.8282781997363632,0.8148389931579938,0.8204255853367648,0.811493314920595,0.8338899001945892,0.8338899001945892,0.829408072311845,0.8237775406440274,0.832772581758835,0.8215303496327915,0.8282781997363632,0.8316364321134895,0.8372481325717155,0.8316427091833531,0.8282719226664993,0.813684012303057,0.8271420500910175,0.8237900947837549,0.8148076078086749,0.8316427091833534,0.8249011361496453,0.8237775406440274,0.8293892411022534,0.8327537505492437,0.8271420500910175,0.8248948590797814,0.8282781997363632,0.8294017952419811,0.8350134957002071,0.828278199736363,0.8305128366078716,0.8271608813006088,0.8305191136777352,0.8215491808423827,0.8316489862532169,0.8271608813006089,0.8193082669010107,0.8282719226664993,0.8316364321134895,0.8316364321134895,0.8305128366078713,0.8226413909986817,0.8181972255351202,0.8271357730211537,0.8215303496327915,0.8215303496327915,0.8305191136777352,0.8316427091833531,0.8260372857949909,0.8316364321134895,0.8316427091833531,0.8283033080158184,0.812560416797439,0.8260498399347185,0.826037285794991,0.8338899001945892,0.8237838177138912,0.8226727763480008,0.8305002824681438,0.8350009415604795,0.8237775406440273,0.8260310087251271,0.8294080723118448,0.8305191136777352,0.8271420500910175,0.8316364321134895,0.8260184545853996,0.8181595631159375,0.8282719226664993,0.8293955181721172,0.8271671583704727,0.8260247316552635,0.8226476680685456,0.8305191136777352,0.8249199673592369,0.8305128366078713,0.8237775406440274,0.8305128366078713,0.8293892411022536,0.8226476680685456,0.827154604230745,0.8282719226664993,0.8338961772644529,0.830525390747599,0.8271357730211537,0.8282719226664993,0.8148076078086749,0.819295712761283,0.8249074132195092,0.8159186491745652,0.8316552633230808,0.826037285794991,0.8305191136777352,0.8305128366078713,0.8327663046889713,0.829408072311845,0.8305128366078713,0.8305128366078716,0.836137091205825,0.8237775406440273,0.8316489862532169,0.8271671583704727,0.8294080723118448,0.8293955181721172,0.8237775406440273,0.8372481325717155,0.831648986253217,0.830525390747599,0.8237775406440274,0.8237775406440274,0.8293955181721173,0.8350009415604795,0.8327663046889711,0.8249074132195091,0.8271483271608814,0.8327663046889713,0.8282907538760906,0.830525390747599,0.8327600276191076,0.8361308141359614,0.8293892411022534,0.8293955181721173,0.8137028435126483,0.8293892411022534,0.8372606867114432,0.8226790534178645,0.8327663046889713,0.8260247316552632,0.8316427091833531,0.8271483271608812,0.8350134957002073,0.8327600276191074,0.827154604230745,0.8260310087251271,0.8372544096415794,0.8305065595380077,0.8305191136777352,0.8271608813006088,0.824913690289373,0.8350072186303434,0.8338836231247255,0.8305128366078713,0.8338899001945892,0.8249011361496453,0.8249074132195091,0.8260184545853996,0.8282593685267716,0.8338773460548616,0.8350009415604797,0.8327663046889713,0.832772581758835,0.8305128366078716,0.8327663046889713,0.8282719226664994,0.8361308141359614,0.8316364321134895,0.8316301550436258,0.8294017952419811,0.8305065595380077,0.8249011361496453,0.8294017952419811,0.8327663046889711,0.8271483271608814,0.8327600276191074,0.8305128366078713,0.8305191136777352,0.8316427091833531,0.8192894356914191,0.8350072186303434,0.8316427091833531,0.8316364321134893,0.8271483271608814,0.8327600276191074,0.8294017952419811,0.8294017952419811,0.824913690289373,0.8271483271608814,0.8294080723118448,0.8249011361496453,0.8271608813006089,0.8316364321134895,0.8293892411022533,0.8327600276191074,0.8350009415604795,0.8282719226664993,0.8282656455966355,0.8271608813006088,0.8294017952419811,0.8293829640323898],\"colorbar\":{\"title\":{\"text\":\"Objective Value\"}},\"colorscale\":[[0.0,\"rgb(247,251,255)\"],[0.125,\"rgb(222,235,247)\"],[0.25,\"rgb(198,219,239)\"],[0.375,\"rgb(158,202,225)\"],[0.5,\"rgb(107,174,214)\"],[0.625,\"rgb(66,146,198)\"],[0.75,\"rgb(33,113,181)\"],[0.875,\"rgb(8,81,156)\"],[1.0,\"rgb(8,48,107)\"]],\"reversescale\":false,\"showscale\":true},\"type\":\"parcoords\"}],                        {\"title\":{\"text\":\"Parallel Coordinate Plot\"},\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('571ac649-bc10-4a15-b25a-c6925aca3258');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_parallel_coordinate(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "{'lambda_l1': 0.23983706945898253,\n",
    " 'lambda_l2': 8.622237296912371e-05,\n",
    " 'num_leaves': 29,\n",
    " 'feature_fraction': 0.9144574800999573,\n",
    " 'bagging_fraction': 0.9844533490969807,\n",
    " 'bagging_freq': 4,\n",
    " 'min_child_samples': 46}\n",
    " \n",
    " best_value = 0.8383654510074697\n",
    "'''\n",
    "\n",
    "best_params = {'lambda_l1': 0.23983706945898253,\n",
    " 'lambda_l2': 8.622237296912371e-05,\n",
    " 'num_leaves': 29,\n",
    " 'feature_fraction': 0.9144574800999573,\n",
    " 'bagging_fraction': 0.9844533490969807,\n",
    " 'bagging_freq': 4,\n",
    " 'min_child_samples': 46}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000195 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 668, number of used features: 21\n",
      "[LightGBM] [Info] Start training from score 0.386228\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000169 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 668, number of used features: 21\n",
      "[LightGBM] [Info] Start training from score 0.393713\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000145 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 668, number of used features: 21\n",
      "[LightGBM] [Info] Start training from score 0.383234\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Python\\Python37\\lib\\site-packages\\pandas\\core\\indexing.py:1637: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000144 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 222\n",
      "[LightGBM] [Info] Number of data points in the train set: 669, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.372197\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000190 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 891, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 0.383838\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    }
   ],
   "source": [
    "kf_stacking = KFold(4, shuffle = True, random_state = 0)\n",
    "kf_stacking.split(train)\n",
    "\n",
    "for train_ix, test_ix in kf_stacking.split(train):\n",
    "    lgbm = lgb.train(best_params, \n",
    "        lgb.Dataset(train.loc[train_ix, features], label = train.loc[train_ix, 'Survived']))\n",
    "    \n",
    "    train.loc[test_ix,'lv1_lgbm_preds'] = lgbm.predict(train.loc[test_ix, features])\n",
    "    \n",
    "\n",
    "lgbm = lgb.train(best_params, lgb.Dataset(train[features], label = train['Survived']))\n",
    "\n",
    "test['lv1_lgbm_preds'] = lgbm.predict(test[features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grandient Boosting Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-22 21:37:02,278]\u001b[0m A new study created in memory with name: no-name-9a018de0-d597-4605-bf0f-d6704a0fd68a\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 21:37:02,810]\u001b[0m Trial 0 finished with value: 0.7867114430983617 and parameters: {'learning_rate': 0.005296672154483834, 'n_estimators': 125, 'subsample': 0.9555220718330827, 'min_samples_split': 7, 'min_samples_leaf': 20, 'max_depth': 3, 'min_impurity_decrease': 0.9806330321044527, 'max_features': 11}. Best is trial 0 with value: 0.7867114430983617.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 21:37:03,476]\u001b[0m Trial 1 finished with value: 0.8024543343167408 and parameters: {'learning_rate': 0.005704183216093639, 'n_estimators': 173, 'subsample': 0.7887468022543601, 'min_samples_split': 19, 'min_samples_leaf': 6, 'max_depth': 6, 'min_impurity_decrease': 0.920120248785882, 'max_features': 5}. Best is trial 1 with value: 0.8024543343167408.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 21:37:04,198]\u001b[0m Trial 2 finished with value: 0.8148138848785388 and parameters: {'learning_rate': 0.009264509332578557, 'n_estimators': 186, 'subsample': 0.8988512109379343, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_depth': 6, 'min_impurity_decrease': 0.8711165503835694, 'max_features': 7}. Best is trial 2 with value: 0.8148138848785388.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 21:37:04,549]\u001b[0m Trial 3 finished with value: 0.6161634548992531 and parameters: {'learning_rate': 0.0011033178182282895, 'n_estimators': 63, 'subsample': 0.8323575932348654, 'min_samples_split': 2, 'min_samples_leaf': 7, 'max_depth': 5, 'min_impurity_decrease': 0.8263051433134839, 'max_features': 12}. Best is trial 2 with value: 0.8148138848785388.\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-111-45ea7c4ff6f2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[0mstudy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'maximize'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m \u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mF:\\Python\\Python37\\lib\\site-packages\\optuna\\study\\study.py\u001b[0m in \u001b[0;36moptimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    407\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    408\u001b[0m             \u001b[0mgc_after_trial\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgc_after_trial\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 409\u001b[1;33m             \u001b[0mshow_progress_bar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshow_progress_bar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    410\u001b[0m         )\n\u001b[0;32m    411\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Python\\Python37\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     74\u001b[0m                 \u001b[0mreseed_sampler_rng\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m                 \u001b[0mtime_start\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m                 \u001b[0mprogress_bar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprogress_bar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m             )\n\u001b[0;32m     78\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Python\\Python37\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m             \u001b[0mtrial\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m             \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Python\\Python37\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 213\u001b[1;33m         \u001b[0mvalue_or_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    214\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m         \u001b[1;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-111-45ea7c4ff6f2>\u001b[0m in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mtrain_ix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_ix\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m         \u001b[0mgbm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_ix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_ix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Survived'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m         \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgbm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_ix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Python\\Python37\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[0;32m    594\u001b[0m             \u001b[0msample_weight_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m             \u001b[0mbegin_at_stage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 596\u001b[1;33m             \u001b[0mmonitor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    597\u001b[0m         )\n\u001b[0;32m    598\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Python\\Python37\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\u001b[0m in \u001b[0;36m_fit_stages\u001b[1;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor)\u001b[0m\n\u001b[0;32m    670\u001b[0m                 \u001b[0mrandom_state\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    671\u001b[0m                 \u001b[0mX_csc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 672\u001b[1;33m                 \u001b[0mX_csr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    673\u001b[0m             )\n\u001b[0;32m    674\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Python\\Python37\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\u001b[0m in \u001b[0;36m_fit_stage\u001b[1;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_csc, X_csr)\u001b[0m\n\u001b[0;32m    244\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    245\u001b[0m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 246\u001b[1;33m             \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresidual\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    247\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    248\u001b[0m             \u001b[1;31m# update tree leaves\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Python\\Python37\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m   1318\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1319\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1320\u001b[1;33m             \u001b[0mX_idx_sorted\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_idx_sorted\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1321\u001b[0m         )\n\u001b[0;32m   1322\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Python\\Python37\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    418\u001b[0m             )\n\u001b[0;32m    419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 420\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    422\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier \n",
    "\n",
    "def objective(trial):\n",
    "    \n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-6, 1e-2)\n",
    "    n_estimators = trial.suggest_int('n_estimators', 20, 200)\n",
    "    subsample = trial.suggest_float('subsample', 0.75, 1)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 20)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 20)\n",
    "    max_depth = trial.suggest_int('max_depth', 3, 7)\n",
    "    min_impurity_decrease = trial.suggest_float('min_impurity_decrease', 0.75, 1)\n",
    "    max_features = trial.suggest_int('max_features', 3, 20)\n",
    "    \n",
    "    gbm = GradientBoostingClassifier(learning_rate = learning_rate,\n",
    "                                     n_estimators = n_estimators,\n",
    "                                     subsample = subsample,\n",
    "                                     min_samples_split = min_samples_split,\n",
    "                                     min_samples_leaf = min_samples_leaf,\n",
    "                                     max_depth = max_depth,\n",
    "                                     min_impurity_decrease = min_impurity_decrease,\n",
    "                                     random_state = 42,\n",
    "                                     max_features = max_features)\n",
    "    \n",
    "    kf = KFold(5, shuffle = True, random_state = 0)\n",
    "    kf.split(train)\n",
    "    \n",
    "    accuracy_scores = []\n",
    "    \n",
    "    for train_ix, test_ix in kf.split(train):\n",
    "        gbm.fit(train.loc[train_ix, features], train.loc[train_ix, 'Survived'])\n",
    "        preds = np.rint(gbm.predict(train.loc[test_ix, features]))\n",
    "        \n",
    "        accuracy_scores.append(metrics.accuracy_score(train.loc[test_ix, 'Survived'], preds))\n",
    "        \n",
    "    return np.mean(accuracy_scores)\n",
    "    \n",
    "\n",
    "# 3. Create a study object and optimize the objective function.\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "learning_rate = 0.009620110160365543,\n",
    "n_estimators = 135,\n",
    "subsample = 0.9699332268604093,\n",
    "min_samples_split = 12,\n",
    "min_samples_leaf = 2,\n",
    "max_depth = 7,\n",
    "min_impurity_decrease = 0.7763728807219239,\n",
    "max_features = 20,\n",
    "random_state = 42\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(learning_rate=0.009620110160365543, max_depth=7,\n",
       "                           max_features=20,\n",
       "                           min_impurity_decrease=0.7763728807219239,\n",
       "                           min_samples_leaf=2, min_samples_split=12,\n",
       "                           n_estimators=135, random_state=42,\n",
       "                           subsample=0.9699332268604093)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kf_stacking = KFold(4, shuffle = True, random_state = 0)\n",
    "\n",
    "train['lv1_gbm_preds'] = np.nan\n",
    "for train_ix, test_ix in kf_stacking.split(train):\n",
    "    gbm = GradientBoostingClassifier(\n",
    "        learning_rate = 0.009620110160365543,\n",
    "        n_estimators = 135,\n",
    "        subsample = 0.9699332268604093,\n",
    "        min_samples_split = 12,\n",
    "        min_samples_leaf = 2,\n",
    "        max_depth = 7,\n",
    "        min_impurity_decrease = 0.7763728807219239,\n",
    "        max_features = 20,\n",
    "        random_state = 42)\n",
    "    \n",
    "    gbm.fit(train.loc[train_ix, features], train.loc[train_ix, 'Survived'])\n",
    "    train.loc[test_ix,'lv1_gbm_preds'] = gbm.predict(train[features].iloc[test_ix])    \n",
    "    \n",
    "gbm.fit(train[features], train['Survived'])\n",
    "test['lv1_gbm_preds'] = gbm.predict(test[features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "def objective(trial):\n",
    "    \n",
    "    svc = SVC(C = trial.suggest_float('C', 1e-6, 10))\n",
    "    \n",
    "    kf = KFold(5, shuffle = True, random_state = 0)\n",
    "    kf.split(train)\n",
    "    \n",
    "    accuracy_scores = []\n",
    "    \n",
    "    for train_ix, test_ix in kf.split(train):\n",
    "        svc.fit(train.loc[train_ix,features], train.loc[train_ix, 'Survived'])\n",
    "        preds = svc.predict(train.loc[test_ix,features])\n",
    "        \n",
    "        accuracy_scores.append(metrics.accuracy_score(train.loc[test_ix, 'Survived'], preds))\n",
    "        \n",
    "    return np.mean(accuracy_scores)\n",
    "    \n",
    "\n",
    "# 3. Create a study object and optimize the objective function.\n",
    "# study = optuna.create_study(direction='maximize')\n",
    "# study.optimize(objective, n_trials=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "C = 0.4898842008006796\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf_stacking = KFold(4, shuffle = True, random_state = 0)\n",
    "\n",
    "for train_ix, test_ix in kf_stacking.split(train):\n",
    "    svc = SVC(C = 0.4898842008006796)\n",
    "    \n",
    "    svc.fit(train.loc[train_ix,features], train.loc[train_ix,'Survived'])\n",
    "    train.loc[test_ix,'lv1_svc_preds'] = svc.predict(train.loc[test_ix, features]) \n",
    "    \n",
    "svc.fit(train[features], train['Survived'])\n",
    "test['lv1_svc_preds'] = svc.predict(test[features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def objective(trial):\n",
    "    \n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators = trial.suggest_int('n_estimators', 10, 250),\n",
    "        criterion = trial.suggest_categorical('criterion', ['gini', 'entropy']),\n",
    "        max_depth = trial.suggest_int('max_depth', 3, 12),\n",
    "        min_samples_split = trial.suggest_float('min_samples_split', 0, 1),\n",
    "        min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 25), \n",
    "        max_features = trial.suggest_int('max_features', 1, 25),\n",
    "        max_leaf_nodes = trial.suggest_int('max_leaf_nodes', 10, 200),\n",
    "        random_state = 0\n",
    "    )\n",
    "    \n",
    "    \n",
    "    kf = KFold(5, shuffle = True, random_state = 0)\n",
    "    kf.split(train)\n",
    "    \n",
    "    accuracy_scores = []\n",
    "    \n",
    "    for train_ix, test_ix in kf.split(train):\n",
    "        rf.fit(train.loc[train_ix, features], train.loc[train_ix, 'Survived'])\n",
    "        preds = rf.predict(train.loc[test_idx, features])\n",
    "        \n",
    "        accuracy_scores.append(metrics.accuracy_score(train.loc[test_idx, 'Survived'], preds))\n",
    "        \n",
    "    return np.mean(accuracy_scores)\n",
    "    \n",
    "\n",
    "# 3. Create a study object and optimize the objective function.\n",
    "\n",
    "# study = optuna.create_study(direction='maximize')\n",
    "# study.optimize(objective, n_trials=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "{'n_estimators': 82,\n",
    "  'criterion': 'entropy',\n",
    "  'max_depth': 9,\n",
    "  'min_samples_split': 8.96842165215019e-05,\n",
    "  'min_samples_leaf': 1,\n",
    "  'max_features': 19,\n",
    "  'max_leaf_nodes': 192}\n",
    "''' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf_stacking = KFold(4, shuffle = True, random_state = 0)\n",
    "\n",
    "for train_ix, test_ix in kf_stacking.split(train):\n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators = 82,\n",
    "        criterion = 'entropy',\n",
    "        max_depth = 9,\n",
    "        min_samples_split = 8.96842165215019e-05,\n",
    "        min_samples_leaf = 1,\n",
    "        max_features = 19,\n",
    "        max_leaf_nodes = 192,\n",
    "        random_state = 0\n",
    "    )\n",
    "    \n",
    "    rf.fit(train.loc[train_ix,features], train.loc[train_ix,'Survived'])\n",
    "    train.loc[test_ix,'lv1_rf_preds'] = rf.predict(train.loc[test_ix, features]) \n",
    "    \n",
    "rf.fit(train[features], train['Survived'])\n",
    "test['lv1_rf_preds'] = rf.predict(test[features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-22 21:51:02,518]\u001b[0m A new study created in memory with name: no-name-1a5a963d-f0f6-4368-8209-d4d79ca77e07\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 21:51:04,122]\u001b[0m Trial 0 finished with value: 0.813709120582512 and parameters: {'C': 15.118174963261461, 'l1_ratio': 0.5854510710638687}. Best is trial 0 with value: 0.813709120582512.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 21:51:05,912]\u001b[0m Trial 1 finished with value: 0.8125855250768941 and parameters: {'C': 6.367143699118766, 'l1_ratio': 0.1992294398486285}. Best is trial 0 with value: 0.813709120582512.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 21:51:09,572]\u001b[0m Trial 2 finished with value: 0.813709120582512 and parameters: {'C': 98.88329774808986, 'l1_ratio': 0.14761603646854204}. Best is trial 0 with value: 0.813709120582512.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 21:51:11,427]\u001b[0m Trial 3 finished with value: 0.8125855250768941 and parameters: {'C': 8.830611022046414, 'l1_ratio': 0.17887043267848335}. Best is trial 0 with value: 0.813709120582512.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 21:51:14,552]\u001b[0m Trial 4 finished with value: 0.813709120582512 and parameters: {'C': 58.43349244040621, 'l1_ratio': 0.585788841689092}. Best is trial 0 with value: 0.813709120582512.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 21:51:16,019]\u001b[0m Trial 5 finished with value: 0.8125855250768941 and parameters: {'C': 2.49571370455924, 'l1_ratio': 0.5016957637033378}. Best is trial 0 with value: 0.813709120582512.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 21:51:17,794]\u001b[0m Trial 6 finished with value: 0.8125855250768941 and parameters: {'C': 9.823495834984257, 'l1_ratio': 0.8445135218480491}. Best is trial 0 with value: 0.813709120582512.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 21:51:19,610]\u001b[0m Trial 7 finished with value: 0.8125855250768941 and parameters: {'C': 7.793810140564545, 'l1_ratio': 0.7720954394773191}. Best is trial 0 with value: 0.813709120582512.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 21:51:21,352]\u001b[0m Trial 8 finished with value: 0.8125855250768941 and parameters: {'C': 10.990637637342886, 'l1_ratio': 0.8838608015943363}. Best is trial 0 with value: 0.813709120582512.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 21:51:23,946]\u001b[0m Trial 9 finished with value: 0.813709120582512 and parameters: {'C': 40.90664800696854, 'l1_ratio': 0.21036994470597048}. Best is trial 0 with value: 0.813709120582512.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 21:51:25,036]\u001b[0m Trial 10 finished with value: 0.813709120582512 and parameters: {'C': 1.270200589523544, 'l1_ratio': 0.6490286144513888}. Best is trial 0 with value: 0.813709120582512.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 21:51:28,649]\u001b[0m Trial 11 finished with value: 0.813709120582512 and parameters: {'C': 97.61264128893743, 'l1_ratio': 0.3770760975840388}. Best is trial 0 with value: 0.813709120582512.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 21:51:30,563]\u001b[0m Trial 12 finished with value: 0.813709120582512 and parameters: {'C': 23.65040847516019, 'l1_ratio': 0.3882203769035609}. Best is trial 0 with value: 0.813709120582512.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 21:51:32,646]\u001b[0m Trial 13 finished with value: 0.813709120582512 and parameters: {'C': 24.084861492493626, 'l1_ratio': 0.0350242653394329}. Best is trial 0 with value: 0.813709120582512.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 21:51:34,741]\u001b[0m Trial 14 finished with value: 0.813709120582512 and parameters: {'C': 3.7667039897967873, 'l1_ratio': 0.674564861302064}. Best is trial 0 with value: 0.813709120582512.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 21:51:36,894]\u001b[0m Trial 15 finished with value: 0.813709120582512 and parameters: {'C': 24.47025871060544, 'l1_ratio': 0.000979890607587186}. Best is trial 0 with value: 0.813709120582512.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 21:51:40,501]\u001b[0m Trial 16 finished with value: 0.813709120582512 and parameters: {'C': 98.48547588922266, 'l1_ratio': 0.31260019891816837}. Best is trial 0 with value: 0.813709120582512.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 21:51:41,688]\u001b[0m Trial 17 finished with value: 0.8125855250768941 and parameters: {'C': 3.3975982448540996, 'l1_ratio': 0.9811510567688603}. Best is trial 0 with value: 0.813709120582512.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 21:51:43,535]\u001b[0m Trial 18 finished with value: 0.813709120582512 and parameters: {'C': 18.167457839848716, 'l1_ratio': 0.031051097063915956}. Best is trial 0 with value: 0.813709120582512.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 21:51:46,440]\u001b[0m Trial 19 finished with value: 0.813709120582512 and parameters: {'C': 52.0522456286932, 'l1_ratio': 0.3398704094844271}. Best is trial 0 with value: 0.813709120582512.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 21:51:47,327]\u001b[0m Trial 20 finished with value: 0.8137028435126483 and parameters: {'C': 1.1320547846863298, 'l1_ratio': 0.47412532257178847}. Best is trial 0 with value: 0.813709120582512.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 21:51:49,112]\u001b[0m Trial 21 finished with value: 0.813709120582512 and parameters: {'C': 18.17817220325166, 'l1_ratio': 0.30388886557641454}. Best is trial 0 with value: 0.813709120582512.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 21:51:51,911]\u001b[0m Trial 22 finished with value: 0.813709120582512 and parameters: {'C': 45.57176634497336, 'l1_ratio': 0.5116735386887606}. Best is trial 0 with value: 0.813709120582512.\u001b[0m\n",
      "\u001b[32m[I 2021-12-22 21:51:53,651]\u001b[0m Trial 23 finished with value: 0.813709120582512 and parameters: {'C': 16.158156391559263, 'l1_ratio': 0.10667631732008269}. Best is trial 0 with value: 0.813709120582512.\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-114-93f2f8139464>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[0mstudy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'maximize'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m \u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mF:\\Python\\Python37\\lib\\site-packages\\optuna\\study\\study.py\u001b[0m in \u001b[0;36moptimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    407\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    408\u001b[0m             \u001b[0mgc_after_trial\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgc_after_trial\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 409\u001b[1;33m             \u001b[0mshow_progress_bar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshow_progress_bar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    410\u001b[0m         )\n\u001b[0;32m    411\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Python\\Python37\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     74\u001b[0m                 \u001b[0mreseed_sampler_rng\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m                 \u001b[0mtime_start\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m                 \u001b[0mprogress_bar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprogress_bar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m             )\n\u001b[0;32m     78\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Python\\Python37\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m             \u001b[0mtrial\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m             \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Python\\Python37\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 213\u001b[1;33m         \u001b[0mvalue_or_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    214\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m         \u001b[1;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-114-93f2f8139464>\u001b[0m in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mtrain_ix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_ix\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0mlogit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_ix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_ix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Survived'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m         \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_ix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1612\u001b[0m                 \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1613\u001b[0m             )\n\u001b[1;32m-> 1614\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mclass_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwarm_start_coef_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwarm_start_coef\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1615\u001b[0m         )\n\u001b[0;32m   1616\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Python\\Python37\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1041\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1043\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1045\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Python\\Python37\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    859\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    860\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 861\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    862\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    863\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Python\\Python37\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    777\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Python\\Python37\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Python\\Python37\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Python\\Python37\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 263\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Python\\Python37\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 263\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Python\\Python37\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 209\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    210\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\u001b[0m in \u001b[0;36m_logistic_regression_path\u001b[1;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio)\u001b[0m\n\u001b[0;32m    876\u001b[0m                 \u001b[0mmax_squared_sum\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    877\u001b[0m                 \u001b[0mwarm_start_sag\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 878\u001b[1;33m                 \u001b[0mis_saga\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msolver\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"saga\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    879\u001b[0m             )\n\u001b[0;32m    880\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_sag.py\u001b[0m in \u001b[0;36msag_solver\u001b[1;34m(X, y, sample_weight, loss, alpha, beta, max_iter, tol, verbose, random_state, check_input, max_squared_sum, warm_start_mem, is_saga)\u001b[0m\n\u001b[0;32m    346\u001b[0m         \u001b[0mintercept_decay\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m         \u001b[0mis_saga\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 348\u001b[1;33m         \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    349\u001b[0m     )\n\u001b[0;32m    350\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def objective(trial):\n",
    "    \n",
    "    logit = LogisticRegression(\n",
    "        penalty = 'elasticnet',\n",
    "        C = trial.suggest_float('C', 1, 100, log = True),\n",
    "        l1_ratio = trial.suggest_float('l1_ratio', 0, 1),\n",
    "        solver = 'saga',\n",
    "        max_iter = 10000,\n",
    "        random_state = 0\n",
    "    )\n",
    "    \n",
    "    \n",
    "    kf = KFold(5, shuffle = True, random_state = 0)\n",
    "    kf.split(train)\n",
    "    \n",
    "    accuracy_scores = []\n",
    "\n",
    "    for train_ix, test_ix in kf.split(train):\n",
    "        logit.fit(train.loc[train_ix, features], train.loc[train_ix, 'Survived'])\n",
    "        preds = logit.predict(train.loc[test_ix, features])\n",
    "        \n",
    "        \n",
    "        accuracy_scores.append(metrics.accuracy_score(train.loc[test_ix, 'Survived'], preds))\n",
    "        \n",
    "    return np.mean(accuracy_scores)\n",
    "    \n",
    "\n",
    "# 3. Create a study object and optimize the objective function.\n",
    "\n",
    "# study = optuna.create_study(direction='maximize')\n",
    "# study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''  \n",
    "best_score = \n",
    "''' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf_stacking = KFold(4, shuffle = True, random_state = 0)\n",
    "\n",
    "for train_ix, test_ix in kf_stacking.split(train):\n",
    "    logit = LogisticRegression()\n",
    "    \n",
    "    logit.fit(train.loc[train_ix,features], train.loc[train_ix,'Survived'])\n",
    "    train.loc[test_ix,'lv1_logit_preds'] = logit.predict(train.loc[test_ix, features]) \n",
    "    \n",
    "logit.fit(train[features], train['Survived'])\n",
    "test['lv1_logit_preds'] = logit.predict(test[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      1\n",
       "      ..\n",
       "413    0\n",
       "414    1\n",
       "415    0\n",
       "416    0\n",
       "417    0\n",
       "Name: Survived, Length: 418, dtype: int32"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "lv1_preds = [col for col in train.columns if col not in features if col not in ['Survived', 'PassengerId']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8350168350168349"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "logit = LogisticRegression()\n",
    "\n",
    "cv = cross_validate(logit, train[lv1_preds], train['Survived'], scoring = \"accuracy\", cv = 3)\n",
    "cv['test_score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('data/submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit.fit(train[lv1_preds], train['Survived'])\n",
    "\n",
    "submission['Survived'] = logit.predict(test[lv1_preds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [col for col in train.columns if col not in ['Survived', 'PassengerId']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_train_df = pd.concat([train['Survived'], pd.DataFrame(pca.fit_transform(train[features]))], axis = 1)\n",
    "new_test_df = pd.DataFrame(pca.transform(test[features]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_df.columns = ['Survived', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.fit(new_train_df.drop('Survived', axis = 1), new_train_df['Survived'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test_df.columns = ['f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['Survived'] = logit.predict(new_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"data/submission.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived\n",
       "0            892         0\n",
       "1            893         0\n",
       "2            894         0\n",
       "3            895         0\n",
       "4            896         1\n",
       "..           ...       ...\n",
       "413         1305         0\n",
       "414         1306         1\n",
       "415         1307         0\n",
       "416         1308         0\n",
       "417         1309         0\n",
       "\n",
       "[418 rows x 2 columns]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived\n",
       "0            892       0.0\n",
       "1            893       0.0\n",
       "2            894       0.0\n",
       "3            895       0.0\n",
       "4            896       1.0\n",
       "..           ...       ...\n",
       "413         1305       0.0\n",
       "414         1306       1.0\n",
       "415         1307       0.0\n",
       "416         1308       0.0\n",
       "417         1309       1.0\n",
       "\n",
       "[418 rows x 2 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000324 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 891, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 0.383838\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    }
   ],
   "source": [
    "lgbm = lgb.train({\n",
    "    'lambda_l1': 3.0382509030081943e-07,\n",
    "    'lambda_l2': 1.7528164440749284e-06,\n",
    "    'num_leaves': 28,\n",
    "    'feature_fraction': 0.7757503939389271,\n",
    "    'bagging_fraction': 0.6778524391467955,\n",
    "    'bagging_freq': 1,\n",
    "    'min_child_samples': 42}, \n",
    "    lgb.Dataset(train[features], label = train['Survived']))\n",
    "\n",
    "submission['Survived'] =  np.abs(np.rint(lgbm.predict(test[features])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"data/submission.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived\n",
       "0            892       0.0\n",
       "1            893       0.0\n",
       "2            894       0.0\n",
       "3            895       0.0\n",
       "4            896       1.0\n",
       "..           ...       ...\n",
       "413         1305       0.0\n",
       "414         1306       1.0\n",
       "415         1307       0.0\n",
       "416         1308       0.0\n",
       "417         1309       0.0\n",
       "\n",
       "[418 rows x 2 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
